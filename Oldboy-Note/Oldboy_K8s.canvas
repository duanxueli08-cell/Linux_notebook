{
	"nodes":[
		{"id":"ef97f55b5a2b95a1","type":"text","text":"- 昨日内容回顾:\n\t- harbor的自建证书https案例\n\t\t服务端：\n\t\t\t- 自建CA证书\n\t\t\t- harbor服务端生成证书签发请求\n\t\t\t- 基于自建CA证书签发证书请求\n\t\t\t- harbor的配置文件指定自定义域名证书\n\t\t\t- 启动harbor\n\t\t\n\t\t客户端:\n\t\t\t- 现在服务端生成客户端所需的证书\n\t\t\t- 将证书拷贝到客户端docker的指定目录，该目录下需要创建对应的域名目录\n\t\t\t\n\t\t\t\n\t- K8S架构：\n\t\tmaster:\n\t\t\tetcd:\n\t\t\t\t数据存储。\n\t\t\t\t\n\t\t\tapi-server:\n\t\t\t\tK8S集群的访问入口。\n\t\t\t\t\n\t\t\tscheduler:\n\t\t\t\t调度器，负责Pod调度。\n\t\t\t\t\n\t\t\tcontroller manager:\n\t\t\t\t控制器管理者，维护集群状态。\n\t\t\n\t\tslave:\n\t\t\tkubelet:\n\t\t\t\t管理Pod的生命周期，并监控容器和节点信息上报给api-server。\n\t\t\t\t\n\t\t\tkube-proxy:\n\t\t\t\t为Pod提供服务发现和负载均衡。\n\t\t\t\t\n\t\tCNI:\n\t\t\t为容器跨节点通信提供网络环境。\n\t\t\tflannel\n\t\t\tcalico\n\t\t\t...\n\t\t\t\t\n\t- kubeadm快速搭建单master集群\n\t\n\t\n今日内容预告:\n\t- K8S的学习方法\n\t- K8S常用的资源概览\n\t- K8S的资源管理增删改查\n\t- K8S声明式API和响应式API的区别对比\n\t- 标签管理\n\t- rc控制器\n\t- svc资源\n\t- Pod创建流程\n\t\n\t\n\n\n- K8S的学习方法 ---> 必读: 怎么学好K8S的心态\n\t1.摆正心态\n\t\t1.1 拒绝: 急于求成，好高骛远:\n有一定工作经验的人，不是技术小白，部署K8S网上随便找个文章搭建起来。\n\n没办法系统完成业务迁移。\n\t\t\n\t\t\n\t\t1.2 拒绝: 依赖辅助型，借助工具，过于安逸:\n使用saas产品，图形化工具管理K8S集群，对K8S底层一无所知。\n\t\n所有的部署都在K8S图形化界面完成，当集群出现故障时，搞不定，过度依赖工具，比如阿里云，京东云，亚马逊等云平台，kubesphere，kuboard，rancher等。\n\t\n\t\t1.3 拒绝: 未来方向选择其他\n想要走传统运维，数据库等方向，不想把精力放在K8S上。\n\t\t\n不要在下雨天修房顶，而要在晴天修房顶。\n\t\t\n技术呢？要提前学习，将来工作涨薪资提前准备。77学长14K入职容器方向，工作3个月跳槽21k。\n\t\t\n\t\t1.4 空杯心态: 踏踏实实，勤勤恳恳\n一般都是小白，知道自己不知道，踏踏实实系统学习，一次学不会，尝试2-3次。\n\n有一定工作经验的人能做到\"空杯心态\"的人太少了。\n\t\t\n\n\t2.学习方法\n\t\t2.1 纸上得来终觉浅，绝知此事要躬行\n每天都要完成课堂的所有练习并整理思维导图。 \n完成每日作业，时间精力允许的话，可以在选做一下扩展作业。\t\n\n\t\t2.2 不耻下问，不耻上问\n学习遇到问题要及时寻求帮助，可以网上查阅资料，也可以问同学。\n\n如果一个技术问题卡了你30分钟以上依旧没有解决，就必须问讲师来解决。\n\n\t\t2.3 适当性囫囵吞枣\n遇到一些技术难点，不要过于钻牛角尖，而是要跟进整个课程进度，拿下整个架构框架部分，有的问题在学习后面的内容就慢慢搞懂了。\n\n不要想着任何技术学一遍就会，如果真有，那么多半是这个技术过于简单，或者将来你学的这个东西压根就不怎么值钱，一学就会的学习成本过低，市场饱和量可想而知。\n\n第一次学习肯定有不懂的地方，将问题记下来，第二次和第三次学习的时候可能就豁然开朗。\n\n\t\t2.4 高阶学习方法\n听:\n\t上课听讲，不睡觉。\n\t上课睡觉10分钟，下课可能最少要100分钟才能找回补偿，得不偿失。\n\n做: \n\t主要是课堂的实验，上课的实验必须全部做一遍。\n\n写: \n\t整理课堂笔记，总结为自己的知识。\n\n画:\n\t要学会画思维导图，帮助自己整理知识点的脉络。\n\n讲:\n\t帮助同学解决问题，把问你问题的同学当成面试官。\n    你给同学讲明白了，将来面试你也问题。\n\n\n- K8S常用的资源概览\n\t- 1.Pod \n是一组容器，里面可以运行多个容器，一个Pod最少有一个容器运行。\n\n\t- 2.rc ---》 replicationcontrollers\n副本控制器，可以保证指定副本的Pod数量存活。\n\t\n\t- 3.svc ---》services\n为Pod提供服务代理。\n\n\t- 4.ep  ---》endpoints\n每个svc都会关联一个ep资源，ep就是后端的IP，这个IP可以是Pod地址，也可以是K8S集群外部的地址。\n \n\t- 5.rs  ---》replicasets\n副本控制器，可以保证指定副本的Pod数量存活。相比rc更加轻量级且功能更加丰富。\n\n\t- 6.deloy ---》 deployments\n用于部署无状态服务，比如nginx类。deploy底层调用的是rs实现Pod副本控制。\n\n\t- 7.ds ---》daemonsets\n让每个节点有且仅有一个Pod运行。\n\n\t- 8.sts ---》statefulsets\n用于部署有状态服务，每个Pod都有独立的存储，每个Pod可以基于名称进行访问。\n\n\t- 9.jobs\n用于部署一次性任务的控制器。做一个数据库的全量备份。\n\n\t- 10.cj ---》cronjobs\n用于部署周期性应用。做数据库里的增量备份。\n\n\t- 11.pv ---》persistentvolumes\n用于映射后端的存储设备类型。可以指定存储容器大小。\n\n\t- 12.pvc ---》persistentvolumeclaims\n自动关联pv，Pod将来讲数据写入pvc设备。\n\n\t- 13.sc ---》storageclasses\n动态存储类，可以动态创建pv。\n\n\t- 14.ns ---》namespaces\n实现K8S集群的资源隔离。\n\n\t- 15.quota ---》resourcequotas\n实现名称级别的资源限制。\n\n\t- 16.limits ---》limitranges\n实现Pod级别的资源限制。\n\n\t- 17.secrets\n存储铭感数据\n\n\t- 18.cm ---> configMaps\n存储应用的配置文件。\n\n\t- 19.cs ---> componentstatuses\n查看master组件信息。已经弃用。\n\n\t- 20.no ---> nodes\n查看集群节点的信息。\n\n\t- 21.hpa ---> horizontalpodautoscalers\n水平动态Pod伸缩。\n\n\t- 22.ing ---》ingresses\n实现7层代理，底层基于svc实现四层代理。\n\n\t- 23.sa ---> serviceaccounts\n服务账号，给Pod的应用程序使用。\n\n\t- 24.roles\n定义角色。\n\n\t- 25.rolebindings\n将角色和用户主体进行绑定。\n\n\t- 26.clusterroles\n集群角色。\n\n\t- 27.clusterrolebindings\n将集群角色和用户主体进行绑定。\n \n\t\n\t查看K8S集群的资源类型\n[root@master231 ~]# kubectl api-resources \nNAME                              SHORTNAMES   APIVERSION                             NAMESPACED   KIND\nbindings                                       v1                                     true         Binding\ncomponentstatuses                 cs           v1                                     false        ComponentStatus\nconfigmaps                        cm           v1                                     true         ConfigMap\nendpoints                         ep           v1                                     true         Endpoints\nevents                            ev           v1                                     true         Event\nlimitranges                       limits       v1                                     true         LimitRange\nnamespaces                        ns           v1                                     false        Namespace\nnodes                             no           v1                                     false        Node\npersistentvolumeclaims            pvc          v1                                     true         PersistentVolumeClaim\npersistentvolumes                 pv           v1                                     false        PersistentVolume\npods                              po           v1                                     true         Pod\npodtemplates                                   v1                                     true         PodTemplate\nreplicationcontrollers            rc           v1                                     true         ReplicationController\nresourcequotas                    quota        v1                                     true         ResourceQuota\nsecrets                                        v1                                     true         Secret\nserviceaccounts                   sa           v1                                     true         ServiceAccount\nservices                          svc          v1                                     true         Service\nmutatingwebhookconfigurations                  admissionregistration.k8s.io/v1        false        MutatingWebhookConfiguration\nvalidatingwebhookconfigurations                admissionregistration.k8s.io/v1        false        ValidatingWebhookConfiguration\ncustomresourcedefinitions         crd,crds     apiextensions.k8s.io/v1                false        CustomResourceDefinition\napiservices                                    apiregistration.k8s.io/v1              false        APIService\ncontrollerrevisions                            apps/v1                                true         ControllerRevision\ndaemonsets                        ds           apps/v1                                true         DaemonSet\ndeployments                       deploy       apps/v1                                true         Deployment\nreplicasets                       rs           apps/v1                                true         ReplicaSet\nstatefulsets                      sts          apps/v1                                true         StatefulSet\ntokenreviews                                   authentication.k8s.io/v1               false        TokenReview\nlocalsubjectaccessreviews                      authorization.k8s.io/v1                true         LocalSubjectAccessReview\nselfsubjectaccessreviews                       authorization.k8s.io/v1                false        SelfSubjectAccessReview\nselfsubjectrulesreviews                        authorization.k8s.io/v1                false        SelfSubjectRulesReview\nsubjectaccessreviews                           authorization.k8s.io/v1                false        SubjectAccessReview\nhorizontalpodautoscalers          hpa          autoscaling/v2                         true         HorizontalPodAutoscaler\ncronjobs                          cj           batch/v1                               true         CronJob\njobs                                           batch/v1                               true         Job\ncertificatesigningrequests        csr          certificates.k8s.io/v1                 false        CertificateSigningRequest\nleases                                         coordination.k8s.io/v1                 true         Lease\nendpointslices                                 discovery.k8s.io/v1                    true         EndpointSlice\nevents                            ev           events.k8s.io/v1                       true         Event\nflowschemas                                    flowcontrol.apiserver.k8s.io/v1beta2   false        FlowSchema\nprioritylevelconfigurations                    flowcontrol.apiserver.k8s.io/v1beta2   false        PriorityLevelConfiguration\ningressclasses                                 networking.k8s.io/v1                   false        IngressClass\ningresses                         ing          networking.k8s.io/v1                   true         Ingress\nnetworkpolicies                   netpol       networking.k8s.io/v1                   true         NetworkPolicy\nruntimeclasses                                 node.k8s.io/v1                         false        RuntimeClass\npoddisruptionbudgets              pdb          policy/v1                              true         PodDisruptionBudget\npodsecuritypolicies               psp          policy/v1beta1                         false        PodSecurityPolicy\nclusterrolebindings                            rbac.authorization.k8s.io/v1           false        ClusterRoleBinding\nclusterroles                                   rbac.authorization.k8s.io/v1           false        ClusterRole\nrolebindings                                   rbac.authorization.k8s.io/v1           true         RoleBinding\nroles                                          rbac.authorization.k8s.io/v1           true         Role\npriorityclasses                   pc           scheduling.k8s.io/v1                   false        PriorityClass\ncsidrivers                                     storage.k8s.io/v1                      false        CSIDriver\ncsinodes                                       storage.k8s.io/v1                      false        CSINode\ncsistoragecapacities                           storage.k8s.io/v1beta1                 true         CSIStorageCapacity\nstorageclasses                    sc           storage.k8s.io/v1                      false        StorageClass\nvolumeattachments                              storage.k8s.io/v1                      false        VolumeAttachment\n[root@master231 ~]#  \n[root@master231 ~]# \n\n\n\t- 入职接管K8S时，K8S日常基础巡检\n\t\t1.检查K8S集群的worker节点列表\n[root@master231 ~]# kubectl get nodes \nNAME        STATUS   ROLES                  AGE   VERSION\nmaster231   Ready    control-plane,master   17h   v1.23.17\nworker232   Ready    <none>                 17h   v1.23.17\nworker233   Ready    <none>                 17h   v1.23.17\n[root@master231 ~]# \n\t\t\n\t\t2.检查master组件\n[root@master231 ~]# kubectl get cs\nWarning: v1 ComponentStatus is deprecated in v1.19+\nNAME                 STATUS    MESSAGE                         ERROR\netcd-0               Healthy   {\"health\":\"true\",\"reason\":\"\"}   \nscheduler            Healthy   ok                              \ncontroller-manager   Healthy   ok                              \n[root@master231 ~]# \n[root@master231 ~]# \n\n\t\t3.检查Flannel网卡是否正常\n[root@master231 ~]# kubectl get pods -o wide -n kube-flannel \nNAME                    READY   STATUS    RESTARTS      AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nkube-flannel-ds-ckkbk   1/1     Running   1 (16h ago)   16h   10.0.0.233   worker233   <none>           <none>\nkube-flannel-ds-kst7g   1/1     Running   1 (16h ago)   16h   10.0.0.232   worker232   <none>           <none>\nkube-flannel-ds-ljktm   1/1     Running   1 (16h ago)   16h   10.0.0.231   master231   <none>           <none>\n[root@master231 ~]# \n\n\n\t\t4.检查各节点网络是否正常及网卡是否存在\n[root@master231 ~]# ifconfig \ncni0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.100.0.1  netmask 255.255.255.0  broadcast 10.100.0.255\n        inet6 fe80::e48a:3ff:fe16:626  prefixlen 64  scopeid 0x20<link>\n        ether e6:8a:03:16:06:26  txqueuelen 1000  (Ethernet)\n        RX packets 118967  bytes 9855656 (9.8 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 137513  bytes 12374863 (12.3 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n...\n\nflannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.100.0.0  netmask 255.255.255.255  broadcast 0.0.0.0\n        inet6 fe80::cd6:8dff:fe03:f8a6  prefixlen 64  scopeid 0x20<link>\n        ether 0e:d6:8d:03:f8:a6  txqueuelen 0  (Ethernet)\n        RX packets 10  bytes 1724 (1.7 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 14  bytes 892 (892.0 B)\n        TX errors 0  dropped 30 overruns 0  carrier 0  collisions 0\n\n\n\n[root@worker232 ~]# ifconfig \ncni0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.100.1.1  netmask 255.255.255.0  broadcast 10.100.1.255\n        inet6 fe80::2c66:d4ff:fea4:e11e  prefixlen 64  scopeid 0x20<link>\n        ether 2e:66:d4:a4:e1:1e  txqueuelen 1000  (Ethernet)\n        RX packets 7  bytes 919 (919.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 15  bytes 1208 (1.2 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n...\n\nflannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.100.1.0  netmask 255.255.255.255  broadcast 0.0.0.0\n        inet6 fe80::486d:7aff:fe84:46c2  prefixlen 64  scopeid 0x20<link>\n        ether 4a:6d:7a:84:46:c2  txqueuelen 0  (Ethernet)\n        RX packets 7  bytes 446 (446.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 5  bytes 863 (863.0 B)\n        TX errors 0  dropped 31 overruns 0  carrier 0  collisions 0\n\n\n\n[root@worker233 ~]# ifconfig \ncni0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.100.2.1  netmask 255.255.255.0  broadcast 10.100.2.255\n        inet6 fe80::f4fa:dbff:fef1:6332  prefixlen 64  scopeid 0x20<link>\n        ether f6:fa:db:f1:63:32  txqueuelen 1000  (Ethernet)\n        RX packets 7  bytes 917 (917.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 15  bytes 1208 (1.2 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n...\n\nflannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450\n        inet 10.100.2.0  netmask 255.255.255.255  broadcast 0.0.0.0\n        inet6 fe80::5c21:13ff:fee3:8224  prefixlen 64  scopeid 0x20<link>\n        ether 5e:21:13:e3:82:24  txqueuelen 0  (Ethernet)\n        RX packets 7  bytes 446 (446.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 5  bytes 861 (861.0 B)\n        TX errors 0  dropped 31 overruns 0  carrier 0  collisions 0\n\n\n\n可能会出现的问题：\n\t- 1.cni0和flannel.1网段不一致\n导致各节点Pod容器无法互通。\n\n\t- 2.不存在cni0设备\n可能会出现无法访问外网或者同节点Pod容器无法互相通信。\n\n\n\nflannel网络插件重启次数过多，或者不正常运行时:\n    1、删除资源清单\n[root@master231 ~]# kubectl delete -f kube-flannel.yml\n    \n    2、移除虚拟网卡设备\nifconfig cni0 down\nip link delete cni0\nifconfig flannel.1 down\nip link delete flannel.1\n\\rm -rf /var/lib/cni/flannel/* /var/lib/cni/networks/cbr0/*  /var/lib/cni/cache/* /etc/cni/net.d/*\nsystemctl restart kubelet docker\nchmod a+w /var/run/docker.sock\nsystemctl status kubelet docker\n\n    3、重新创建flannel网卡\n[root@master231 ~]# kubectl apply -f kube-flannel.yml \n\n\n- 如果有节点没有cni0网卡，建议大家手动创建相应的网桥设备，但是注意网段要一致:\n\t1.假设 master231的flannel.1是10.100.0.0网段。\nip link add cni0 type bridge\nip link set dev cni0 up\nip addr add 10.100.0.1/24 dev cni0\n\n\t2.假设 worker232的flannel.1是10.100.1.0网段。\nip link add cni0 type bridge\nip link set dev cni0 up\nip addr add 10.100.1.1/24 dev cni0\n\n\t3.假设 worker233的flannel.1是10.100.2.0网段。\nip link add cni0 type bridge\nip link set dev cni0 up\nip addr add 10.100.2.1/24 dev cni0\n\n\n温馨提示:\n\t将其设置在开机启动脚本中执行。\n\t\n\n\n\n- K8S的资源管理增查删\n\t1.创建资源清单的目录\n[root@master231 ~]# mkdir -pv /oldboyedu/manifests/pods\n[root@master231 ~]# \n[root@master231 ~]# cd /oldboyedu/manifests/pods\n[root@master231 pods]# \n\n\t\n\t2.编写资源清单规范\napiVersion:\n\t声明API的版本号，每个资源都有其对应的版本。\n\t\nkind:\n\t指定资源的类型。\n\t\nmetadata:\n\t指定资源的元数据信息，包括但不限于资源的名称，标签，名称空间，注解等。\n\t\nspec:\n\t资源的期望运行状态。\n\nstatus:\n\t资源的实际运行状态，有K8S组件维护。\n\t\n\t\n\t3.什么是Pod\n所谓的Pod其实就是一组容器，Pod翻译为中文是豌豆荚。\n\nPod和容器时什么关系呢？说白了，就是豌豆荚和豌豆的关系，一个Pod可以包含多个容器。\n\t \n在K8S中没有容器的概念，最小的调度单元是Pod。\n\n\t\n\t4.编写资源清单 \n[root@master231 pods]# cat 01-pods-xiuxian-single.yaml \n# 指定api的版本号 \napiVersion: v1\n# 指定资源的类型\nkind: Pod\n# 指定元数据信息\nmetadata:\n  # 声明资源的名称\n  name: xiuxian-v1\n# 定义资源的期望状态\nspec:\n  # 指定Pod调度到哪个节点\n  nodeName: worker232\n  # 指定Pod内的容器\n  containers:\n    # 指定容器的镜像\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    # 指定容器的名称\n    name: xiuxian\n\n\n\n\t5.创建资源\n[root@master231 pods]# kubectl create -f 01-pods-xiuxian-single.yaml \npod/xiuxian-v1 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl create -f 01-pods-xiuxian-single.yaml  # 使用create指令创建资源时，若资源已经存在则报错。\nError from server (AlreadyExists): error when creating \"01-pods-xiuxian-single.yaml\": pods \"xiuxian-v1\" already exists\n[root@master231 pods]# \n\n\n[root@master231 pods]# kubectl apply -f 01-pods-xiuxian-single.yaml   # 尽管多次执行apply应用，都不会报错。\npod/xiuxian-v1 unchanged\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 01-pods-xiuxian-single.yaml \npod/xiuxian-v1 unchanged\n[root@master231 pods]# \n\n\ncreate和apply命令的区别:\n\t相同点:\n\t\t当资源不存在时，都可以创建资源。\n\t\n\t不同点:\n\t\t当资源存在时，create指令创建会报错资源已经存在，而apply指令只会输出unchanged的变化。\n\t\t\n\t综上所述，生产环境中，我们想要更新资源就使用apply命令，为了避免报错，我们也同时会使用apply去创建资源。\n\t\n\n\t6.查看资源列表\n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          3s    10.100.1.5   worker232   <none>           <none>\n[root@master231 pods]# \n\n相关字段说明：\nNAME:\n\tPod的名称。\n\nREADY:\n\tPod内容器是否准备就绪。1/1 ，右边的1标识一个Pod内有一个容器，左边的1标识有一个容器准备就绪。\n\nSTATUS:\n\tPod的运行状态。  \n\nRESTARTS：\n\tPod的重启次数。这里的重启次数指的是删除原有的容器，重启创建新的容器次数。和docker的重启策略并不相同。\n\t\nAGE:\n\t代表的是资源的运行时间。\n\nIP: \n\t代表的是Pod的IP地址。\n\t\nNODE:\n\t代表的是Pod所在的节点。\n\t\n\t\n\t7.删除资源\n[root@master231 pods]# kubectl delete -f 01-pods-xiuxian-single.yaml \npod \"xiuxian-v1\" deleted\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNo resources found in default namespace.\n[root@master231 pods]# \n\n\n\n\n\t- Pod内运行多个容器案例\n\t\t1.环境准备\n[root@worker233 ~]# wget http://192.168.16.253/Image/Docker/Docker/Linux/alpine-v3.20.2.tar.gz\n[root@worker233 ~]# docker load -i alpine-v3.20.2.tar.gz \nLoaded image: alpine:3.20.2\n[root@worker233 ~]# \n[root@worker233 ~]# docker tag alpine:3.20.2  harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n[root@worker233 ~]# \n[root@worker233 ~]# docker push harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\nThe push refers to repository [harbor.oldboyedu.com/oldboyedu-linux/alpine]\n78561cef0761: Pushed \n3.20.2: digest: sha256:eddacbc7e24bf8799a4ed3cdcfa50d4b88a323695ad80f317b6629883b2c2a78 size: 528\n[root@worker233 ~]# \n[root@worker233 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2 harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n[root@worker233 ~]# \n[root@worker233 ~]# docker push harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\nThe push refers to repository [harbor.oldboyedu.com/oldboyedu-web/xiuxian]\n4beb452b2498: Pushed \n9d5b000ce7c7: Pushed \nb8dbe22b95f7: Pushed \nc39c1c35e3e8: Pushed \n5f66747c8a72: Pushed \n15d7cdc64789: Pushed \n7fcb75871b21: Pushed \nv2: digest: sha256:3ac38ee6161e11f2341eda32be95dcc6746f587880f923d2d24a54c3a525227e size: 1778\n[root@worker233 ~]# \n\n\n\t\t2.一个Pod部署两个容器\n[root@master231 pods]# cat 02-pods-xiuxian-alpine-multiple.yaml \n# 指定api的版本号 \napiVersion: v1\n# 指定资源的类型\nkind: Pod\n# 指定元数据信息\nmetadata:\n  # 声明资源的名称\n  name: xiuxian-v2\n# 定义资源的期望状态\nspec:\n  # 指定Pod调度到哪个节点\n  nodeName: worker232\n  # 指定Pod内的容器\n  containers:\n    # 指定第0（计算机是从0开始计数）个容器的镜像\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    # 指定第0个容器的名称\n    name: xiuxian\n    # 指定第1个容器\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    # 分配一个标准输入，让alpine的容器能够阻塞住，否则就会退出容器\n    stdin: true\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 02-pods-xiuxian-alpine-multiple.yaml \npod/xiuxian-v2 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v2   2/2     Running   0          21s   10.100.1.8   worker232   <none>           <none>\n[root@master231 pods]# \n\n\n- 使用kubectl exec在容器中执行命令\n\t1.查看Pod列表\n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE    IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          40s    10.100.1.9   worker232   <none>           <none>\nxiuxian-v2   2/2     Running   0          112s   10.100.1.8   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n\t\n\t2.在xiuxian-v1的Pod查看IP地址\n[root@master231 pods]# kubectl exec xiuxian-v1 -- ifconfig\neth0      Link encap:Ethernet  HWaddr 0E:DD:73:C9:60:A7  \n          inet addr:10.100.1.9  Bcast:10.100.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1\n          RX packets:5 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:446 (446.0 B)  TX bytes:42 (42.0 B)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n[root@master231 pods]# \n\n\n\t3.在xiuxian-v2的Pod查看IP地址\n[root@master231 pods]# kubectl exec xiuxian-v2 -- ifconfig  # 如果不指定容器，则默认使用第0个容器。\nDefaulted container \"xiuxian\" out of: xiuxian, alpine\neth0      Link encap:Ethernet  HWaddr 2A:A5:6C:D7:B4:E2  \n          inet addr:10.100.1.8  Bcast:10.100.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1\n          RX packets:7 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:666 (666.0 B)  TX bytes:42 (42.0 B)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-v2 -c xiuxian -- ifconfig  # 指定xiuxian容器名称\neth0      Link encap:Ethernet  HWaddr 2A:A5:6C:D7:B4:E2  \n          inet addr:10.100.1.8  Bcast:10.100.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1\n          RX packets:7 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:666 (666.0 B)  TX bytes:42 (42.0 B)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-v2 -c alpine -- ifconfig  # 指定alpine容器名称。\neth0      Link encap:Ethernet  HWaddr 2A:A5:6C:D7:B4:E2  \n          inet addr:10.100.1.8  Bcast:10.100.1.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1\n          RX packets:7 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:666 (666.0 B)  TX bytes:42 (42.0 B)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n[root@master231 pods]# \n\n\n\n综上所述，同一个Pod内的多个容器，共享网络名称空间。说白了，就是IP相同。\n\n\n\t\n\t4.链接到指定容器并执行相关的命令进行交互\n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE     IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          6m10s   10.100.1.9   worker232   <none>           <none>\nxiuxian-v2   2/2     Running   0          7m22s   10.100.1.8   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-v2 -it -c xiuxian -- sh\n/ # \n/ # hostname \nxiuxian-v2\n/ # \n/ # ps -ef \nPID   USER     TIME  COMMAND\n    1 root      0:00 nginx: master process nginx -g daemon off;\n   31 nginx     0:00 nginx: worker process\n   32 nginx     0:00 nginx: worker process\n   45 root      0:00 sh\n   52 root      0:00 ps -ef\n/ # \n/ # hostname -i\n10.100.1.8\n/ # \n/ # nginx -t\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n/ # \n/ # \n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-v2 -it -c alpine -- sh\n/ # \n/ # hostname \nxiuxian-v2\n/ # \n/ # ps -ef \nPID   USER     TIME  COMMAND\n    1 root      0:00 /bin/sh\n   13 root      0:00 sh\n   20 root      0:00 ps -ef\n/ # \n/ # hostname -i\n10.100.1.8\n/ # \n/ # nginx -t\nsh: nginx: not found\n/ # \n\n\n\n- K8S声明式API和响应式API的区别对比\n\t相同点:\n\t\t都可以对资源进行增删改查。\n\t\n\t不同点:\n\t\t声明式API需要编写资源清单(yaml配置文件)，而响应式API不需要编写资源清单，基于命令行方式管理即可。\n\t\t\n\n- 案例1： 资源查看\n\t1.声明式查看资源\n[root@master231 pods]# kubectl get -f 02-pods-xiuxian-alpine-multiple.yaml \nNAME         READY   STATUS    RESTARTS   AGE\nxiuxian-v2   2/2     Running   0          27m\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl get -f 01-pods-xiuxian-single.yaml \nNAME         READY   STATUS    RESTARTS   AGE\nxiuxian-v1   1/1     Running   0          26m\n[root@master231 pods]# \n[root@master231 pods]# kubectl get -f 01-pods-xiuxian-single.yaml  -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          26m   10.100.1.9   worker232   <none>           <none>\n[root@master231 pods]# \n\n\n\t2.响应式查看资源\n[root@master231 pods]# kubectl get pods \nNAME         READY   STATUS    RESTARTS   AGE\nxiuxian-v1   1/1     Running   0          25m\nxiuxian-v2   2/2     Running   0          27m\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          27m   10.100.1.9   worker232   <none>           <none>\nxiuxian-v2   2/2     Running   0          28m   10.100.1.8   worker232   <none>           <none>\n[root@master231 pods]# \n\n\n-  案例2： 创建资源\n\t1.声明式创建Pod\n[root@master231 pods]# cat 01-pods-xiuxian-single.yaml \n# 指定api的版本号 \napiVersion: v1\n# 指定资源的类型\nkind: Pod\n# 指定元数据信息\nmetadata:\n  # 声明资源的名称\n  name: xiuxian-v1\n# 定义资源的期望状态\nspec:\n  # 指定Pod调度到哪个节点\n  nodeName: worker232\n  # 指定Pod内的容器\n  containers:\n    # 指定容器的镜像\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    # 指定容器的名称\n    name: xiuxian\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 01-pods-xiuxian-single.yaml \npod/xiuxian-v1 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          5s    10.100.1.10   worker232   <none>           <none>\n[root@master231 pods]# \n\n\n\t2.响应式创建Pod\n[root@master231 pods]# kubectl run xixi --image=harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\npod/xixi created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE    IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          103s   10.100.1.10   worker232   <none>           <none>\nxixi         1/1     Running   0          10s    10.100.2.5    worker233   <none>           <none>\n[root@master231 pods]# \n\n\n总结:\n\t声明式特点:\n\t\t修改资源清单后，需要应用后才能生效。\n\t\t\n\t响应式特点:\n\t\t在命令行中直接操作，修改后立刻执行。\n\t\n\t\n\t\n- 标签管理\n\t1.什么是标签\nK8S一切皆资源，将来如果想要对某个资源进行管理时，我们可以基于标签进行过滤。\n\n标签的作用就是用来标识一个资源的。可以给资源打标签。\n\n\t2.查看资源的标签\n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          6m46s   10.100.1.10   worker232   <none>           <none>            <none>\nxixi         1/1     Running   0          5m13s   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n\n\t3.响应式添加标签\n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          7m42s   10.100.1.10   worker232   <none>           <none>            <none>\nxixi         1/1     Running   0          6m9s    10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl label -f 01-pods-xiuxian-single.yaml school=oldboyedu class=linux92\npod/xiuxian-v1 labeled\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          8m46s   10.100.1.10   worker232   <none>           <none>            class=linux92,school=oldboyedu\nxixi         1/1     Running   0          7m13s   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n[root@master231 pods]# kubectl label pods xiuxian-v1 address=ShaHe\npod/xiuxian-v1 labeled\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          9m13s   10.100.1.10   worker232   <none>           <none>            address=ShaHe,class=linux92,school=oldboyedu\nxixi         1/1     Running   0          7m40s   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n\n\t\n\t4.响应式删除标签\n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          9m31s   10.100.1.10   worker232   <none>           <none>            address=ShaHe,class=linux92,school=oldboyedu\nxixi         1/1     Running   0          7m58s   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n[root@master231 pods]# kubectl label pods xiuxian-v1 address-\npod/xiuxian-v1 unlabeled\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          10m     10.100.1.10   worker232   <none>           <none>            class=linux92,school=oldboyedu\nxixi         1/1     Running   0          8m31s   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n[root@master231 pods]# kubectl label -f 01-pods-xiuxian-single.yaml school-\npod/xiuxian-v1 unlabeled\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          10m     10.100.1.10   worker232   <none>           <none>            class=linux92\nxixi         1/1     Running   0          8m58s   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n\t\n\t\n\t5.响应式修改标签\n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          12m   10.100.1.10   worker232   <none>           <none>            class=linux92\nxixi         1/1     Running   0          10m   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl label -f 01-pods-xiuxian-single.yaml class=Linux92 --overwrite\npod/xiuxian-v1 labeled\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels \nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          12m   10.100.1.10   worker232   <none>           <none>            class=Linux92\nxixi         1/1     Running   0          10m   10.100.2.5    worker233   <none>           <none>            run=xixi\n[root@master231 pods]# \n[root@master231 pods]# kubectl label pods xixi run=haha --overwrite \npod/xixi labeled\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels \nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          12m   10.100.1.10   worker232   <none>           <none>            class=Linux92\nxixi         1/1     Running   0          11m   10.100.2.5    worker233   <none>           <none>            run=haha\n[root@master231 pods]# \n\n\n\t5.响应式标签管理是临时的\n[root@master231 pods]# kubectl get pods -o wide --show-labels \nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          13m   10.100.1.10   worker232   <none>           <none>            class=Linux92\nxixi         1/1     Running   0          11m   10.100.2.5    worker233   <none>           <none>            run=haha\n[root@master231 pods]# \n[root@master231 pods]# kubectl delete -f 01-pods-xiuxian-single.yaml \npod \"xiuxian-v1\" deleted\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 01-pods-xiuxian-single.yaml \npod/xiuxian-v1 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels \nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          2s    10.100.1.11   worker232   <none>           <none>            <none>\nxixi         1/1     Running   0          12m   10.100.2.5    worker233   <none>           <none>            run=haha\n[root@master231 pods]# \n \n\t\n\t6.声明式管理标签\n[root@master231 pods]# cat 03-pods-labels.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-labels\n  # 给资源添加标签\n  labels:\n    # 自定义该资源的标签键值对\n    school: oldboyedu\n    class: linux92\nspec:\n  nodeName: worker232\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    name: xiuxian\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    stdin: true\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f  03-pods-labels.yaml\npod/xiuxian-labels created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME             READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-labels   2/2     Running   0          9s      10.100.1.12   worker232   <none>           <none>            class=linux92,school=oldboyedu\n...\n[root@master231 pods]# \n\n\n温馨提示:\n\t可以修改或删除标签的键值对，但需要重新应用。\n\t\n\t\n- 基于标签过滤资源实战案例\n\t1.基于标签过滤Pod资源\n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME             READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-labels   2/2     Running   0          4m24s   10.100.1.12   worker232   <none>           <none>            class=linux92,school=oldboyedu\nxiuxian-v1       1/1     Running   0          6m51s   10.100.1.11   worker232   <none>           <none>            class=Linux92\nxixi             1/1     Running   0          18m     10.100.2.5    worker233   <none>           <none>            run=haha\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels -l class\nNAME             READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-labels   2/2     Running   0          4m43s   10.100.1.12   worker232   <none>           <none>            class=linux92,school=oldboyedu\nxiuxian-v1       1/1     Running   0          7m10s   10.100.1.11   worker232   <none>           <none>            class=Linux92\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels -l class=Linux92\nNAME         READY   STATUS    RESTARTS   AGE    IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          9m1s   10.100.1.11   worker232   <none>           <none>            class=Linux92\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide --show-labels -l class!=Linux92\nNAME             READY   STATUS    RESTARTS   AGE    IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-labels   2/2     Running   0          7m7s   10.100.1.12   worker232   <none>           <none>            class=linux92,school=oldboyedu\nxixi             1/1     Running   0          21m    10.100.2.5    worker233   <none>           <none>            run=haha\n[root@master231 pods]# \n\n\t2.基于标签过滤节点资源\n[root@master231 pods]# kubectl get nodes --show-labels\nNAME        STATUS   ROLES                  AGE   VERSION    LABELS\nmaster231   Ready    control-plane,master   19h   v1.23.17   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master231,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/exclude-from-external-load-balancers=\nworker232   Ready    <none>                 19h   v1.23.17   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker232,kubernetes.io/os=linux\nworker233   Ready    <none>                 19h   v1.23.17   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker233,kubernetes.io/os=linux\n[root@master231 pods]# \n[root@master231 pods]# kubectl get nodes -l kubernetes.io/hostname=worker232 --show-labels\nNAME        STATUS   ROLES    AGE   VERSION    LABELS\nworker232   Ready    <none>   19h   v1.23.17   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker232,kubernetes.io/os=linux\n[root@master231 pods]# \n\n\t3.基于标签删除Pod资源\n[root@master231 pods]# kubectl get pods --show-labels\nNAME             READY   STATUS    RESTARTS   AGE     LABELS\nxiuxian-labels   2/2     Running   0          9m12s   class=linux92,school=oldboyedu\nxiuxian-v1       1/1     Running   0          11m     class=Linux92\nxixi             1/1     Running   0          23m     run=haha\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -l class\nNAME             READY   STATUS    RESTARTS   AGE\nxiuxian-labels   2/2     Running   0          9m27s\nxiuxian-v1       1/1     Running   0          11m\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl delete pods -l class\npod \"xiuxian-labels\" deleted\npod \"xiuxian-v1\" deleted\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods --show-labels\nNAME   READY   STATUS    RESTARTS   AGE   LABELS\nxixi   1/1     Running   0          25m   run=haha\n[root@master231 pods]# \n\n\t\n\n- 查看资源的详细信息，类似于\"docker inspect\"命令\n\t\t1.查看Pod资源的详细信息\n[root@master231 pods]# kubectl describe pods xixi \nName:         xixi\nNamespace:    default\nPriority:     0\nNode:         worker233/10.0.0.233\nStart Time:   Tue, 30 Jul 2024 11:41:58 +0800\nLabels:       run=haha\nAnnotations:  <none>\nStatus:       Running\nIP:           10.100.2.5\nIPs:\n  IP:  10.100.2.5\nContainers:\n  xixi:\n    Container ID:   docker://488b484e4eedae22e105c7396acd3344889c4ab149dd47413398b06c8f8341ff\n    Image:          harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    Image ID:       docker-pullable://harbor.oldboyedu.com/oldboyedu-web/xiuxian@sha256:3ac38ee6161e11f2341eda32be95dcc6746f587880f923d2d24a54c3a525227e\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 30 Jul 2024 11:41:58 +0800\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none> \n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v4d77 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-v4d77:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  27m   default-scheduler  Successfully assigned default/xixi to worker233\n  Normal  Pulled     27m   kubelet            Container image \"harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\" already present on machine\n  Normal  Created    27m   kubelet            Created container xixi\n  Normal  Started    27m   kubelet            Started container xixi\n[root@master231 pods]# \n\n\t\t2.查看节点的详细信息\n[root@master231 pods]# kubectl describe nodes master231 \nName:               master231\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master231\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"0e:d6:8d:03:f8:a6\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.231\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 29 Jul 2024 16:38:14 +0800\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  master231\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 30 Jul 2024 12:11:54 +0800\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 29 Jul 2024 17:30:22 +0800   Mon, 29 Jul 2024 17:30:22 +0800   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 30 Jul 2024 12:08:08 +0800   Mon, 29 Jul 2024 16:38:10 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 30 Jul 2024 12:08:08 +0800   Mon, 29 Jul 2024 16:38:10 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 30 Jul 2024 12:08:08 +0800   Mon, 29 Jul 2024 16:38:10 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 30 Jul 2024 12:08:08 +0800   Mon, 29 Jul 2024 17:12:38 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.231\n  Hostname:    master231\nCapacity:\n  cpu:                2\n  ephemeral-storage:  101590008Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3969504Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  93625351218\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3867104Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 c258f9d8eb0c49488b9fd461aa25739c\n  System UUID:                8dd84d56-5c48-da60-df1c-9b854e5d1db4\n  Boot ID:                    abedd681-a844-4be9-8cd3-b2d0ba9073d2\n  Kernel Version:             5.15.0-91-generic\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.24\n  Kubelet Version:            v1.23.17\n  Kube-Proxy Version:         v1.23.17\nPodCIDR:                      10.100.0.0/24\nPodCIDRs:                     10.100.0.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                 ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-ljktm                100m (5%)     0 (0%)      50Mi (1%)        0 (0%)         18h\n  kube-system                 coredns-6d8c4cb4d-2l5jw              100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     19h\n  kube-system                 coredns-6d8c4cb4d-qs4pd              100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     19h\n  kube-system                 etcd-master231                       100m (5%)     0 (0%)      100Mi (2%)       0 (0%)         19h\n  kube-system                 kube-apiserver-master231             250m (12%)    0 (0%)      0 (0%)           0 (0%)         19h\n  kube-system                 kube-controller-manager-master231    200m (10%)    0 (0%)      0 (0%)           0 (0%)         19h\n  kube-system                 kube-proxy-2vxh9                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         19h\n  kube-system                 kube-scheduler-master231             100m (5%)     0 (0%)      0 (0%)           0 (0%)         19h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                950m (47%)  0 (0%)\n  memory             290Mi (7%)  340Mi (9%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n[root@master231 pods]# \n\n\t\t3.查看所有节点信息\n[root@master231 pods]# kubectl describe nodes \nName:               master231\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master231\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"0e:d6:8d:03:f8:a6\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.231\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 29 Jul 2024 16:38:14 +0800\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  master231\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 30 Jul 2024 12:13:46 +0800\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 29 Jul 2024 17:30:22 +0800   Mon, 29 Jul 2024 17:30:22 +0800   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 30 Jul 2024 12:13:15 +0800   Mon, 29 Jul 2024 16:38:10 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 30 Jul 2024 12:13:15 +0800   Mon, 29 Jul 2024 16:38:10 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 30 Jul 2024 12:13:15 +0800   Mon, 29 Jul 2024 16:38:10 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 30 Jul 2024 12:13:15 +0800   Mon, 29 Jul 2024 17:12:38 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.231\n  Hostname:    master231\nCapacity:\n  cpu:                2\n  ephemeral-storage:  101590008Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3969504Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  93625351218\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3867104Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 c258f9d8eb0c49488b9fd461aa25739c\n  System UUID:                8dd84d56-5c48-da60-df1c-9b854e5d1db4\n  Boot ID:                    abedd681-a844-4be9-8cd3-b2d0ba9073d2\n  Kernel Version:             5.15.0-91-generic\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.24\n  Kubelet Version:            v1.23.17\n  Kube-Proxy Version:         v1.23.17\nPodCIDR:                      10.100.0.0/24\nPodCIDRs:                     10.100.0.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                 ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-ljktm                100m (5%)     0 (0%)      50Mi (1%)        0 (0%)         19h\n  kube-system                 coredns-6d8c4cb4d-2l5jw              100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     19h\n  kube-system                 coredns-6d8c4cb4d-qs4pd              100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     19h\n  kube-system                 etcd-master231                       100m (5%)     0 (0%)      100Mi (2%)       0 (0%)         19h\n  kube-system                 kube-apiserver-master231             250m (12%)    0 (0%)      0 (0%)           0 (0%)         19h\n  kube-system                 kube-controller-manager-master231    200m (10%)    0 (0%)      0 (0%)           0 (0%)         19h\n  kube-system                 kube-proxy-2vxh9                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         19h\n  kube-system                 kube-scheduler-master231             100m (5%)     0 (0%)      0 (0%)           0 (0%)         19h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                950m (47%)  0 (0%)\n  memory             290Mi (7%)  340Mi (9%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n\n\nName:               worker232\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=worker232\n                    kubernetes.io/os=linux\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"4a:6d:7a:84:46:c2\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.232\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 29 Jul 2024 16:48:04 +0800\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  worker232\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 30 Jul 2024 12:13:45 +0800\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 29 Jul 2024 17:30:21 +0800   Mon, 29 Jul 2024 17:30:21 +0800   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 30 Jul 2024 12:12:52 +0800   Mon, 29 Jul 2024 16:48:04 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 30 Jul 2024 12:12:52 +0800   Mon, 29 Jul 2024 16:48:04 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 30 Jul 2024 12:12:52 +0800   Mon, 29 Jul 2024 16:48:04 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 30 Jul 2024 12:12:52 +0800   Mon, 29 Jul 2024 17:12:43 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.232\n  Hostname:    worker232\nCapacity:\n  cpu:                2\n  ephemeral-storage:  101590008Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3969460Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  93625351218\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3867060Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 c258f9d8eb0c49488b9fd461aa25739c\n  System UUID:                9bf84d56-fc02-7e3b-3a0d-65c8710f2803\n  Boot ID:                    407b7817-b949-4f96-a6ba-cd869077f638\n  Kernel Version:             5.15.0-91-generic\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.24\n  Kubelet Version:            v1.23.17\n  Kube-Proxy Version:         v1.23.17\nPodCIDR:                      10.100.1.0/24\nPodCIDRs:                     10.100.1.0/24\nNon-terminated Pods:          (2 in total)\n  Namespace                   Name                     CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                     ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-kst7g    100m (5%)     0 (0%)      50Mi (1%)        0 (0%)         19h\n  kube-system                 kube-proxy-65z9n         0 (0%)        0 (0%)      0 (0%)           0 (0%)         19h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (5%)  0 (0%)\n  memory             50Mi (1%)  0 (0%)\n  ephemeral-storage  0 (0%)     0 (0%)\n  hugepages-1Gi      0 (0%)     0 (0%)\n  hugepages-2Mi      0 (0%)     0 (0%)\nEvents:              <none>\n\n\nName:               worker233\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=worker233\n                    kubernetes.io/os=linux\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"5e:21:13:e3:82:24\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.233\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 29 Jul 2024 16:49:20 +0800\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  worker233\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 30 Jul 2024 12:13:43 +0800\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 29 Jul 2024 17:30:54 +0800   Mon, 29 Jul 2024 17:30:54 +0800   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 30 Jul 2024 12:13:29 +0800   Mon, 29 Jul 2024 16:49:20 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 30 Jul 2024 12:13:29 +0800   Mon, 29 Jul 2024 16:49:20 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 30 Jul 2024 12:13:29 +0800   Mon, 29 Jul 2024 16:49:20 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 30 Jul 2024 12:13:29 +0800   Mon, 29 Jul 2024 17:30:58 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.233\n  Hostname:    worker233\nCapacity:\n  cpu:                2\n  ephemeral-storage:  101590008Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3969524Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  93625351218\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3867124Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 c258f9d8eb0c49488b9fd461aa25739c\n  System UUID:                b9514d56-aa5b-e934-917c-8959b868dd14\n  Boot ID:                    06ba4271-e99f-43f4-8052-00175e55cd1c\n  Kernel Version:             5.15.0-91-generic\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.24\n  Kubelet Version:            v1.23.17\n  Kube-Proxy Version:         v1.23.17\nPodCIDR:                      10.100.2.0/24\nPodCIDRs:                     10.100.2.0/24\nNon-terminated Pods:          (3 in total)\n  Namespace                   Name                     CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                     ------------  ----------  ---------------  -------------  ---\n  default                     xixi                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         31m\n  kube-flannel                kube-flannel-ds-ckkbk    100m (5%)     0 (0%)      50Mi (1%)        0 (0%)         19h\n  kube-system                 kube-proxy-rmn84         0 (0%)        0 (0%)      0 (0%)           0 (0%)         19h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (5%)  0 (0%)\n  memory             50Mi (1%)  0 (0%)\n  ephemeral-storage  0 (0%)     0 (0%)\n  hugepages-1Gi      0 (0%)     0 (0%)\n  hugepages-2Mi      0 (0%)     0 (0%)\nEvents:              <none>\n[root@master231 pods]# \n\n\n\t4.查看所有Pod详细信息\n[root@master231 pods]# kubectl get pods -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          5s    10.100.1.13   worker232   <none>           <none>\nxixi         1/1     Running   0          32m   10.100.2.5    worker233   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl describe pods\nName:         xiuxian-v1\nNamespace:    default\nPriority:     0\nNode:         worker232/10.0.0.232\nStart Time:   Tue, 30 Jul 2024 12:14:35 +0800\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           10.100.1.13\nIPs:\n  IP:  10.100.1.13\nContainers:\n  xiuxian:\n    Container ID:   docker://de6b3cc3c759b7df123ae1119880a474ed6f52b59ff95580d3eee92d549393b6\n    Image:          registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    Image ID:       docker-pullable://registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps@sha256:3bee216f250cfd2dbda1744d6849e27118845b8f4d55dda3ca3c6c1227cc2e5c\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 30 Jul 2024 12:14:35 +0800\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lpchz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-lpchz:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason   Age   From     Message\n  ----    ------   ----  ----     -------\n  Normal  Pulled   9s    kubelet  Container image \"registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\" already present on machine\n  Normal  Created  9s    kubelet  Created container xiuxian\n  Normal  Started  9s    kubelet  Started container xiuxian\n\n\nName:         xixi\nNamespace:    default\nPriority:     0\nNode:         worker233/10.0.0.233\nStart Time:   Tue, 30 Jul 2024 11:41:58 +0800\nLabels:       run=haha\nAnnotations:  <none>\nStatus:       Running\nIP:           10.100.2.5\nIPs:\n  IP:  10.100.2.5\nContainers:\n  xixi:\n    Container ID:   docker://488b484e4eedae22e105c7396acd3344889c4ab149dd47413398b06c8f8341ff\n    Image:          harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    Image ID:       docker-pullable://harbor.oldboyedu.com/oldboyedu-web/xiuxian@sha256:3ac38ee6161e11f2341eda32be95dcc6746f587880f923d2d24a54c3a525227e\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 30 Jul 2024 11:41:58 +0800\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v4d77 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-v4d77:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  32m   default-scheduler  Successfully assigned default/xixi to worker233\n  Normal  Pulled     32m   kubelet            Container image \"harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\" already present on machine\n  Normal  Created    32m   kubelet            Created container xixi\n  Normal  Started    32m   kubelet            Started container xixi\n[root@master231 pods]# \n\n\n\t5.基于标签过滤查看指定的资源\n[root@master231 pods]# kubectl get pods -o wide --show-labels\nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-v1   1/1     Running   0          59s   10.100.1.13   worker232   <none>           <none>            <none>\nxixi         1/1     Running   0          33m   10.100.2.5    worker233   <none>           <none>            run=haha\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl describe pods -l run=haha\nName:         xixi\nNamespace:    default\nPriority:     0\nNode:         worker233/10.0.0.233\nStart Time:   Tue, 30 Jul 2024 11:41:58 +0800\nLabels:       run=haha\nAnnotations:  <none>\nStatus:       Running\nIP:           10.100.2.5\nIPs:\n  IP:  10.100.2.5\nContainers:\n  xixi:\n    Container ID:   docker://488b484e4eedae22e105c7396acd3344889c4ab149dd47413398b06c8f8341ff\n    Image:          harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    Image ID:       docker-pullable://harbor.oldboyedu.com/oldboyedu-web/xiuxian@sha256:3ac38ee6161e11f2341eda32be95dcc6746f587880f923d2d24a54c3a525227e\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 30 Jul 2024 11:41:58 +0800\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v4d77 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-v4d77:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  33m   default-scheduler  Successfully assigned default/xixi to worker233\n  Normal  Pulled     33m   kubelet            Container image \"harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\" already present on machine\n  Normal  Created    33m   kubelet            Created container xixi\n  Normal  Started    33m   kubelet            Started container xixi\n[root@master231 pods]# \n\n\n\n- 修改Pod的网络名称空间为宿主机模式\n[root@master231 pods]# cat 04-pods-hostNetwork.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-hostnetwork\n  labels:\n    apps: xiuxian\n    school: oldboyedu\n    class: linux92\nspec:\n  # 使用宿主机的网络\n  hostNetwork: true\n  nodeName: worker232\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f  04-pods-hostNetwork.yaml \npod/xiuxian-hostnetwork created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -l apps=xiuxian --show-labels\nNAME                  READY   STATUS    RESTARTS   AGE   LABELS\nxiuxian-hostnetwork   1/1     Running   0          16s   apps=xiuxian,class=linux92,school=oldboyedu\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -l apps=xiuxian -o wide\nNAME                  READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-hostnetwork   1/1     Running   0          24s   10.0.0.232   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# curl 10.0.0.232\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"utf-8\"/>\n    <title>yinzhengjie apps v1</title>\n    <style>\n       div img {\n          width: 900px;\n          height: 600px;\n          margin: 0;\n       }\n    </style>\n  </head>\n\n  <body>\n    <h1 style=\"color: green\">凡人修仙传 v1 </h1>\n    <div>\n      <img src=\"1.jpg\">\n    <div>\n  </body>\n\n</html>\n[root@master231 pods]# \n\n- 今日内容回顾:\n\t- 学习方法 \t\t\t*****\n\t- K8S常用的资源\n\t- K8S集群巡检\t\t*****\n\t- 资源清单的结构\n\t\tapiVersion\n\t\tkind \n\t\tmetadata\n\t\tspec\n\t\tstatus \n\t- 一个Pod运行单个容器 \n\t- 一个Pod运行多个容器 \n\t- 声明式和响应式的区别\n\t- 标签管理 \n\t- 资源的增删改查：\t\n\t\t- kubectl get \t\t\t*****\t\n\t\t- kubectl apply \t\t*****\n\t\t- kubectl create\t\t*****\n\t\t- kubectl delete\t\t*****\n\t其他命令:\t\n\t\t- kubectl labels \t\t*****\n\t\t- kubectl exec \t\t\t*****\n\t\t- kubectl run \t\t\t**\n\t\t- kubectl describe\t\t*****\n\t\t\n\t\t\n\n今日作业:\n\t- 完成课堂的所有练习并整理思维导图;\n\t- 将\"oldboyedu-games-v0.6.tar.gz\"游戏镜像，上传到harbor，并使用K8S部署;\n\t\n\t\n扩展作业:\n\t- 将\"oldboyedu-games-v0.6.tar.gz\"游戏镜像的任选游戏10个游戏镜像，使用docker-compose一键上传到harbor，要求端口号从81-90开始编号，并将其部署到K8S集群，要求windows能够访问。\n\t\n\t\n\t","x":-100,"y":-480,"width":940,"height":520},
		{"id":"454425a435250052","type":"text","text":"- 昨日内容回顾:\n\t- K8S日常巡检\n\t\t- master组件\n\t\t\tkubectl get cs\n\t\t\t\n\t\t- worker组件\n\t\t\tkubectl get no\n\t\t\n\t\t- CNI插件\n\t\t\tkubectl get pods -o wide -n kube-flannel \n\t\t\t\n\t\t\t查看cni0网卡和flannel.1网段是否一致\n\t\t\t\n\t\t\t在不同的worker节点上运行Pod，在第三个节点测试访问。\n\t\t\t\n\t\t\t\n\t\t\t\n\t- Pod内运行一个容器案例\n\t\n\t- Pod内运行多个容器案例\n\t\n\t- 资源管理\n\t\t- kubectl create \n\t\t- kubectl apply\n\t\t- kubectl get \n\t\t- kubectl delete\n\t\t- kubectl describe\n\t\t- kubectl label\n\t\t\n\t- Pod使用worker节点宿主机的网络名称空间。\n\n\n今日内容预告:\n\t- Pod的状态\n\t\n\t- Pod的故障排查技巧\n\t\n\t- Pod容器的类型\n\t\n\t- rc控制器 \n\t\n\t- svc实现四层代理\n\t\n\t- Pod创建流程 \n\t\n\t\n\t\n\t\n\t\n\t产品文档：https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/\n- Pod的状态\n一旦调度器将Pod分派给某个节点，kubelet就通过容器运行(CRI接口)时开始为Pod 创建容器。容器的状态有三种：Waiting（等待）、Running（运行中）和 Terminated（已终止）。\n\n每种状态都有特定的含义：\n\t1.Running（运行中）\nRunning态表明容器正在执行状态并且没有问题发生。  \n\n\t2.Terminated（已终止）\n处于Terminated状态的容器，说明该容器正在终止。 \n\n\t3.Waiting （等待）\n如果容器并不处在Running或Terminated状态之一，它就处在Waiting状态。 \n处于 Waiting 状态的容器仍在运行它完成启动所需要的操作：例如， 从某个容器镜像仓库拉取容器镜像。 \n\n当你使用kubectl来查询包含Waiting状态的容器的Pod时，你也会看到一个Reason字段，其中给出了容器处于等待状态的原因。\n\n\n\n- Pod的阶段\n\tPending（悬决）\t\nPod已被 Kubernetes系统接受，但有一个或者多个容器尚未创建亦未运行。\n此阶段包括等待Pod被调度的时间和通过网络下载镜像的时间。\n\n\n\tRunning（运行中）\t\nPod已经绑定到了某个节点，Pod中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。\n\n\tSucceeded（成功）\t\nPod中的所有容器都已成功终止，并且不会再重启。\n\n\tFailed（失败）\t\nPod中的所有容器都已终止，并且至少有一个容器是因为失败终止。\n也就是说，容器以非0状态退出或者被系统终止，且未被设置为自动重启。\n \n\tUnknown（未知）\t\n因为某些原因无法取得Pod的状态。这种情况通常是因为与Pod所在主机通信失败。\n\n\n\n\n- Pod使用中会遇到的各种状态及拍错技巧\n\t1.ImagePullBackOff\n问题原因:\n\t镜像拉取失败。\n\n可能原因：\n\t1.可能是网络问题导致，检查Pod所在节点是否能够正常访问网络;\n\t2.镜像名称写错，也可能会导致这个错误;\n\t3.镜像是私有仓库，镜像无权限拉取;\n\n\n\t2.ContainerCreating\n问题分析:\n\t容器正在创建阶段，等待容器创建，该过程包含拉取镜像的时间。\n\n\t3.Pending\n问题分析:\n\t任务已经被K8S集群接受，但是未调度到指定节点。\n\n可能原因:\n\t1.当前集群不正常工作，请检查集群状态，比如CNI组件未安装;\n\t2.指定的调度的节点不存在时也会出现这样的问题;\n    3.端口冲突，无法完成调度;\n    4.所有节点都被打上污点，且pod没有配置污点容忍也会导致该状态;\n\n\n\t4.CrashLoopBackOff\n问题分析:\n\t处于该状态，说明Pod内至少有一个容器正在重启。\n\n\n可能原因:\n\t1.可能是容器的守护进程运行命令结束导致的;\n\n\t5.Completed\n问题分析:\n\t容器正常退出，容器没有被强制中断。\n\n\t\n\t6.Running\n问题分析:\n\t至少有一个容器处于正常运行状态。\n\n\n\t7.Init:1/2 \n问题分析:\n\t当前的Pod处于初始化容器阶段，目前已经完成一个初始化容器，正在进行第二个容器初始化。\n\n\n\t8.PodInitializing\n问题分析:\n\tPod正处于初始化阶段。\n\n\n\t9.ErrImageNeverPull\n问题分析:\n\t将镜像下载策略设置为Never，且本地也没有缓存镜像，因此启动容器失败。\n\n\n\t10.OutOfcpu\n问题分析:\n\t一般情况下是由于CPU资源不足导致的。\n\n\n\t11.OutOfmemory\n问题分析:\n\t一般情况下是由于内存不足无法分配导致的。\n\n\t12.NodePorts\n问题分析:\n\t当前的worker节点的端口可能存在冲突。\n\n\t13.RunContainerError\n问题分析:\n\t运行容器时出错，可以通过kubectl describe pods <POD_NAME>查看详细的信息。\n\n\t14.ErrImagePull\n问题分析:\n\t拉取镜像是失败。\n\n可能原因:\n\t1.镜像名称写错了;\n\t2.没有访问权限;\n\n\n\t15.Terminating\n问题分析:\nPod的容器正在删除，此过程可能需要等待一段时间，一般情况下不会超过60s。\n\n\n\t16.CreateContainerConfigError\n问题分析:\n\t运行容器出错，一般情下，是配置出错。\n\n\t17.ContainerStatusUnknown\n问题分析:\n\t容器重启策略为Nerver，且我们测试时将工作节点的容器直接删除啦。无法获取状态导致的。\n\n \n- Pod的故障排查技巧\t\n\t1.准备Dockerfile测试\n[root@worker233 dockerfile]# cat Dockerfile\nFROM harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n\nRUN mkdir /oldboyedu-xixi\n\nCMD [\"ls\",\"-l\",\"/oldboyedu-xixi\"]\n[root@worker233 dockerfile]# \n[root@worker233 dockerfile]# docker build -t harbor.oldboyedu.com/oldboyedu-troubleshooting/oldboyedu-xixi:v0.1 .\n[root@worker233 dockerfile]# \n[root@worker233 dockerfile]# docker push harbor.oldboyedu.com/oldboyedu-troubleshooting/oldboyedu-xixi:v0.1\n[root@worker233 dockerfile]# \n\n\n\t2.编写资源清单\n[root@master231 pods]# cat 05-pods-Troubleshooting.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  # 资源名称不能大写，有效范围是: \".\",\"-\",\"[0-9]\",[a-z]\n  name: www.oldboyedu.com-linux92-002\nspec:\n  # 指定节点调度时，节点的名称必须和etcd中存储保持一致.\n  nodeName: worker232\n  # nodeName: 10.0.0.232\n  containers:\n  # - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n  - image: harbor.oldboyedu.com/oldboyedu-troubleshooting/oldboyedu-xixi:v0.1\n    name: mylinux\n    # 分配一个标准输入给容器，让其能够阻塞住，这对于一些交互式的启动命令很有效\n    # stdin: true\n    # 相当于修改了Dockefile的ENTRYPOINT指令\n    #command: [\"tail\",\"-f\",\"/etc/hosts\"]\n    # 相当于修改了Dockerfile的CMD指令\n    #args: [\"sleep\",\"3600\"]\n    #command和args可以一起使用，args将作为参数传递给command，这一点和Dockerfile的CMD和ENTRYPOINT类似。\n    command:\n    - tail\n    - -f\n    args:\n    - /etc/hosts\n[root@master231 pods]# \n\n\n\n\n- Pod的故障排查之explain文件查看\n\t1.kubectl explain\n可以查看文档字段的信息\n\n\n\t2.常见的数据类型\n<string>\n\t表示字符串类型，可以直接写一个字符串，使用双引号引起来。\n\t大多数情况下，双引号可以省略，但是如果值时一个数字，布尔值建议使用双引号。\n\t\n<Object>\n\t对象类型，指的是该字段有下级字段，各个下级字段都是平级关系，顺序可以随时变动。\n\t\n<map[string]string>\n\t和<Object>很相似，有下级字段，对应的是Go语言中关于map数据类型的定义，是一个键值对。\n\t比较特殊之处是key是string类型，value也是字符串类型。\n\t\n<boolean>\n\t指定布尔值，有效值为true和false。\n\n<[]Object> \n\t数据对象，将下个各个字段进行分组，每个分组的字段顺序可以随机，各组使用\"-\"进行区分。\n\n<integer>\n\t代表的是一个整型数字。\n\n-required-\n\t该属性 可以对上面的6种类型进行修饰，凡是加了该字段，表示该字段不能被省略。说白了，该字段必须写。\n\n\t\n\t3.查看文档的方式\n[root@master231 pods]# kubectl explain pods\n[root@master231 pods]# kubectl explain po.metadata\n\n\n\t4.测试练习，查看个字段的含义\n[root@master231 pods]# yy 03-pods-labels.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-labels\n  labels:\n    school: oldboyedu\n    class: linux92\nspec:\n  nodeName: worker232\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    name: xiuxian\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    stdin: true\n[root@master231 pods]# \n\n\n- Pod的故障排查之文件拷贝\n\t1.作用\n实现宿主机和Pod之间进行数据拷贝\n\n\t2.案例\n\t\t2.1 将Pod容器的目录拷贝到宿主机的\"./xixi\"\n[root@master231 ~]# kubectl cp www.oldboyedu.com-linux92-002:/oldboyedu-xixi/ ./xixi\ntar: removing leading '/' from member names\n[root@master231 ~]# \n\n\t\t2.2 将Pod容器的文件拷贝到宿主机的路径并更名\n[root@master231 ~]# kubectl cp www.oldboyedu.com-linux92-002:/oldboyedu-xixi/os-release ./xixi\n\n\t\t2.3 将宿主机的文件拷贝到容器的指的目录\n[root@master231 ~]# kubectl cp kube-flannel.yml www.oldboyedu.com-linux92-002:/\n\n\t\t2.4 将宿主机的目录拷贝到容器的指的目录\n[root@master231 ~]# kubectl cp download www.oldboyedu.com-linux92-002:/\n\n\t\t2.5 将宿主机的目录拷贝到指定容器的指的目录并更名\n[root@master231 ~]# kubectl cp -c mylinux download www.oldboyedu.com-linux92-002:/haha-download\n\n\n技巧:\n\t1.源数据是目录则拷贝到容器内就是目录，源数据是文件，则拷贝到容器就是文件。\n\t2.如果有多个容器，可以使用-c选项指定容器\n\t\n\t\n\t\t\n- Pod的故障排查之日志查看\n\t1.Pod容器日志查看\n查看Pod容器的日志信息。\n\n\t2.常用的案例\n\t\t2.1 实时查看当前容器的日志\n[root@master231 pods]# kubectl get pods -o wide\nNAME                            READY   STATUS        RESTARTS      AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1                      1/1     Running       0             6s    10.100.1.23   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# kubectl logs -f xiuxian-v1 \n\n\t\t2.2 查看Pod重启之前上一个日志信息【前提是容器存在】\n[root@master231 pods]# kubectl logs -f xiuxian-v1 -p\n\n\n\t\t2.3 查看指定时间之后的并显示时间戳\n[root@master231 pods]# kubectl logs -f xiuxian-v1 --since-time=2024-07-31T03:45:41.070228614Z\n10.100.0.0 - - [31/Jul/2024:03:45:41 +0000] \"GET / HTTP/1.1\" 200 357 \"-\" \"curl/7.81.0\" \"-\"\n10.100.0.0 - - [31/Jul/2024:03:45:44 +0000] \"GET / HTTP/1.1\" 200 357 \"-\" \"curl/7.81.0\" \"-\"\n^C\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl logs -f xiuxian-v1 --since-time=2024-07-31T03:45:41.070228614Z --timestamps\n2024-07-31T03:45:41.070228614Z 10.100.0.0 - - [31/Jul/2024:03:45:41 +0000] \"GET / HTTP/1.1\" 200 357 \"-\" \"curl/7.81.0\" \"-\"\n2024-07-31T03:45:44.685178096Z 10.100.0.0 - - [31/Jul/2024:03:45:44 +0000] \"GET / HTTP/1.1\" 200 357 \"-\" \"curl/7.81.0\" \"-\"\n\n\t\t\n\t\t\n\t温馨提示:\n\t\t如果容器重启之前的容器被删除，则无法查看之前的日志信息。\n[root@master231 pods]# kubectl logs -f xiuxian-v1 -p\nError from server (BadRequest): previous terminated container \"xiuxian\" in pod \"xiuxian-v1\" not found\n[root@master231 pods]# \n[root@master231 pods]# \n\n\n\n- 同一个Pod内多个容器实现数据共享\n\t1.编写资源清单\n[root@master231 pods]# cat 06-pods-volume-emptyDir.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-emptydir-002\nspec:\n  nodeName: worker232\n  # 定义存储卷\n  volumes:\n    # 指定存储卷的名称\n  - name: oldboyedu-linux92\n    # 指定存储的类型为emptyDir\n    emptyDir: {}\n  - name: oldboyedu-xixi\n    emptyDir: {}\n  - name: oldboyedu-haha\n    emptyDir: {}\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    name: xiuxian\n    # 配置存储卷挂载点\n    volumeMounts:\n      # 要挂载的存储卷名称\n    - name: oldboyedu-linux92\n      # 指定容器的挂载路径\n      mountPath: /xixi\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    stdin: true\n    volumeMounts:\n    - name: oldboyedu-linux92\n      mountPath: /haha\n[root@master231 pods]# \n\n\t\n\t2.测试案例\n[root@master231 pods]# kubectl apply -f 06-pods-volume-emptyDir.yaml\npod/xiuxian-emptydir-002 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME                   READY   STATUS    RESTARTS      AGE     IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-emptydir-001   2/2     Running   0             9m46s   10.100.1.24   worker232   <none>           <none>\nxiuxian-emptydir-002   2/2     Running   0             4s      10.100.1.25   worker232   <none>           <none>\nxiuxian-v1             1/1     Running   2 (18m ago)   23m     10.100.1.23   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl cp /etc/os-release xiuxian-emptydir-002 -c xiuxian /xixi\nerror: source and destination are required\n[root@master231 pods]# \n[root@master231 pods]# kubectl cp /etc/os-release  -c xiuxian xiuxian-emptydir-002:/xixi\n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-emptydir-002 -c xiuxian -- ls -l /xixi\ntotal 0\nlrwxrwxrwx    1 root     root            21 Jul 31 04:01 os-release -> ../usr/lib/os-release\n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-emptydir-002 -c alpine -- ls -l /haha\ntotal 0\nlrwxrwxrwx    1 root     root            21 Jul 31 04:01 os-release -> ../usr/lib/os-release\n[root@master231 pods]# \n\n\n\t3.测试案例2 \n[root@master231 pods]# kubectl exec xiuxian-emptydir-002 -c alpine -it -- sh\n/ # ls /haha/\nhosts       os-release\n/ # \n/ # cat /haha/hosts \n127.0.0.1 localhost\n127.0.1.1 yinzhengjie\n\n# The following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n10.0.0.250 harbor.oldboyedu.com \n10.0.0.231 master231\n10.0.0.232 worker232\n10.0.0.233 worker233\n/ # \n/ # \n[root@master231 pods]# \n[root@master231 pods]# kubectl exec xiuxian-emptydir-002 -c xiuxian -it -- sh\n/ # ls /xixi/\nhosts       os-release\n/ # \n/ # cat /xixi/hosts \n127.0.0.1 localhost\n127.0.1.1 yinzhengjie\n\n# The following lines are desirable for IPv6 capable hosts\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n10.0.0.250 harbor.oldboyedu.com \n10.0.0.231 master231\n10.0.0.232 worker232\n10.0.0.233 worker233\n/ # \n\n\n\n- 容器访问宿主机的某个路径实现数据存储及环境变量案例\n\t1.上传镜像\n[root@worker232 ~]# wget http://192.168.16.253/Image/Docker/Docker/ElasticStack/7.17.16/oldboyedu-elasticsearch-7.17.16.tar.gz\n[root@worker232 ~]# docker load -i oldboyedu-elasticsearch-7.17.16.tar.gz \n\n\n\t2.导入镜像到harbor\n[root@worker232 ~]# docker tag harbor.oldboyedu.com/elasticstack-project/elasticsearch:7.17.16 harbor.oldboyedu.com/oldboyedu-elasticstack/elasticsearch:7.17.16\n[root@worker232 ~]# \n[root@worker232 ~]# docker push harbor.oldboyedu.com/oldboyedu-elasticstack/elasticsearch:7.17.16\n\n\n\t3.工作节点创建目录并授权\n[root@worker232 ~]# mkdir -pv /oldboyedu/data/elasticsearch && chmod +777 /oldboyedu/data/elasticsearch\n\n\t\n\t4.编写资源清单 \n[root@master231 pods]# cat 07-pods-volume-hostPath.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-hostpath-es\n  labels:\n    apps: es7\nspec:\n  nodeName: worker232\n  volumes:\n  - name: data\n    # 声明后端存储类型是hostPath\n    hostPath:\n      # 指定worker节点的宿主机路径\n      path: /oldboyedu/data/elasticsearch\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-elasticstack/elasticsearch:7.17.16\n    name: xiuxian\n    # 向容器传递环境变量\n    env:\n      # 指定变量的名称\n    - name: discovery.type\n      # 指定变量的值\n      value: single-node\n    - name: SCHOOL\n      value: oldboyedu\n    - name: Class\n      value: Linux92\n    volumeMounts:\n    - name: data\n      # 指定数据目录\n      mountPath: /usr/share/elasticsearch/data\n[root@master231 pods]# \n[root@master231 pods]# \n\n\n\n\t5.查看服务是否部署成功\n[root@master231 pods]# kubectl apply -f 07-pods-volume-hostPath.yaml \npod/xiuxian-hostpath-es created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide -l apps=es7 --show-labels\nNAME                  READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-hostpath-es   1/1     Running   0          31s   10.100.1.28   worker232   <none>           <none>            apps=es7\n[root@master231 pods]# \n\n\n\t6.访问服务测试\n[root@master231 pods]# curl 10.100.1.28:9200\n{\n  \"name\" : \"xiuxian-hostpath-es\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"cluster_uuid\" : \"uC6f1Jz9Q4iwj8eCbZRD7g\",\n  \"version\" : {\n    \"number\" : \"7.17.16\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"docker\",\n    \"build_hash\" : \"2b23fa076334f8d4651aeebe458a955a2ae23218\",\n    \"build_date\" : \"2023-12-08T10:06:54.672540567Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.11.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n[root@master231 pods]# \n\n\n\t7.测试创建索引\n[root@master231 pods]# curl -X PUT 10.100.1.28:9200/oldboyedu-linux92\n[root@master231 pods]# \n[root@master231 pods]# curl -X PUT 10.100.1.28:9200/oldboyedu-xixi\n[root@master231 pods]# \n[root@master231 pods]# curl -X PUT 10.100.1.28:9200/oldboyedu-haha\n\n\t8.删除Pod并重新创建\n[root@master231 pods]# kubectl delete -f 07-pods-volume-hostPath.yaml \npod \"xiuxian-hostpath-es\" deleted\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 07-pods-volume-hostPath.yaml\npod/xiuxian-hostpath-es created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide -l apps\nNAME                  READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-hostpath-es   1/1     Running   0          52s   10.100.1.30   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# curl  10.100.1.30:9200/_cat/indices\ngreen  open .geoip_databases  g8pppbKVThqD5XcNT8pRBQ 1 0 24 0 23.2mb 23.2mb\nyellow open oldboyedu-haha    AiAdNgYFSbGLk5uMH69M0g 1 1  0 0   227b   227b\nyellow open oldboyedu-linux92 yNc37seMSxK79jLnkuyalQ 1 1  0 0   227b   227b\nyellow open oldboyedu-xixi    JA-tLpkTSjqLKWcSZodQtQ 1 1  0 0   227b   227b\n[root@master231 pods]# \n\n\n\n\n- 上午内容回顾:\n\t- 故障排查技巧\n\t\t- kubectl describe ---> event(由kubelet上报，有这个前提是Pod已经成功调度)\n\t\t- kubectl logs : 根据日志判断无法的运行状态\n\t\t- kubectl exec \n\t\t- 若容器启动失败，我们可以将容器暂时启动，修改command或者args字段，将容器强行启动，启动后再进入到容器进行排查;\n\t\t- kubect cp \n\t\t- 字段写错，尤其是元数据的名称，只能是小写字母，包括特殊字符: \"-\",\".\"。\n\t\t- kubectl explain: 查看文档的信息 \n\t\t- 环境变量传递： env\n\t\t\n\t\t\n\t- Pod的数据持久化\n\t\t- emptyDir:\n\t\t\t应用场景：\n\t\t\t\t可以对Pod内多个容器进行数据持久化。典型应用： web日志，日志采集。\n\t\t\n\t\t\t特点:\n\t\t\t\t1.删除Pod内指定的容器时，数据并不丢失。\n\t\t\t\t2.当删除Pod时，数据就丢失了，因此我们说emptyDir的生命周期随着Pod。\n\t\t\t\t3.可以实现同一个Pod不同容器的数据共享。\n\t\t\t\t\n\t\t- hostPath\n\t\t\t应用场景:\n\t\t\t\tPod内的容器需要访问worker节点的指定目录。\n\t\t\t\t\n\t\t\t特点:\n\t\t\t\t1.无论是删除Pod还是容器，数据始终不丢失。\n\t\t\t\t2.可以实现同一个节点不同Pod的数据共享。\n\t\t\t\t\n\n\n\n- emptyDir存储卷类型如何找到Pod对应存储的数据路径。\n\t1.查看Pod调度到哪个节点\n\t2.根据pod名称去对应节点过滤Pod的ID\n\t3.查看对应节点的数据\nll /var/lib/kubelet/pods/<Pod的ID>/volumes/kubernetes.io~empty-dir/<存储卷的名称>/\n\n\n- hostPath存储卷类型如何找到Pod对应存储的数据路径。\n\t使用kubectl describe查看\n...\nVolumes:\n  data:\n    Type:          HostPath (bare host directory volume)\n    Path:          /oldboyedu/data/elasticsearch\n    HostPathType:  \n\n\n\n\n- emptyDir无法实现同一节点不同Pod的数据共享\n[root@master231 pods]# cat 08-pods-emptyDir-hostPath.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-emptydir-001\nspec:\n  nodeName: worker232\n  volumes:\n  - name: data\n    emptyDir: {}\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    name: xiuxian\n    volumeMounts:\n    - name: data\n      mountPath: /xixi\n\n---\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-emptydir-002\nspec:\n  nodeName: worker232\n  volumes:\n  - name: data\n    emptyDir: {}\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    stdin: true\n    volumeMounts:\n    - name: data\n      mountPath: /haha\n[root@master231 pods]# \n\n\n\n- hostPath无法实现不同节点Pod的数据共享\n[root@master231 pods]# cat 08-pods-emptyDir-hostPath.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-emptydir-hostpath-001\nspec:\n  nodeName: worker232\n  volumes:\n  - name: data\n    #emptyDir: {}\n    hostPath:\n      path: /oldboyedu/data/elasticsearch\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    name: xiuxian\n    volumeMounts:\n    - name: data\n      mountPath: /xixi\n\n---\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-emptydir-hostpath-002\nspec:\n  nodeName: worker233\n  volumes:\n  - name: data\n    #emptyDir: {}\n    hostPath:\n      path: /oldboyedu/data/elasticsearch\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    stdin: true\n    volumeMounts:\n    - name: data\n      mountPath: /haha\n[root@master231 pods]# \n \n\n- Pod数据持久化之nfs\n\t1.K8S各节点部署nfs工具\n[root@master231 ~]# apt -y install nfs-kernel-server\n\n[root@worker232 ~]# apt -y install nfs-kernel-server\n\n[root@worker233 ~]# apt -y install nfs-kernel-server\n\n\n\t2.配置nfs服务端\n[root@master231 ~]# mkdir -pv /oldboyedu/data/nfs-server\nmkdir: created directory '/oldboyedu/data'\nmkdir: created directory '/oldboyedu/data/nfs-server'\n[root@master231 ~]# \n[root@master231 ~]# tail -1 /etc/exports\n/oldboyedu/data/nfs-server         *(rw,no_root_squash)\n[root@master231 ~]# \n[root@master231 ~]# systemctl restart nfs-server\n[root@master231 ~]# \n[root@master231 ~]# exportfs\n/oldboyedu/data/nfs-server\n\t\t<world>\n[root@master231 ~]# \n\n\n\t3.编写资源清单\n[root@master231 pods]# cat 09-pods-volumes-nfs.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-nfs-001\nspec:\n  nodeName: worker232\n  volumes:\n  - name: data\n    # 配置后端存储是nfs\n    nfs:\n      # 指定nfs server的地址，可以是主机名，前提是hosts文件有解析。\n      server: master231\n      # 指定nfs的共享目录\n      path: /oldboyedu/data/nfs-server\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-web/xiuxian:v2\n    name: xiuxian\n    volumeMounts:\n    - name: data\n      mountPath: /xixi\n\n---\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-nfs-002\nspec:\n  nodeName: worker233\n  volumes:\n  - name: data\n    nfs:\n      server: master231\n      path: /oldboyedu/data/nfs-server\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2\n    name: alpine\n    stdin: true\n    volumeMounts:\n    - name: data\n      mountPath: /haha\n[root@master231 pods]# \n\n\n\t4.测试验证 \n略。\n\n\n\n\n课堂练习:\n\t部署MySQL到K8S集群，要求如下：\n\t\t1.删除MySQL的Pod，数据不丢失;\n\t\t2.删除MySQL的Pod后，将Pod调度到另外一个节点验证数据是否正确;\n\t\t\n\t\t\n\t问题分析 :\n\t\t1.启动MySQL数据库传递环境变量;\n\t\t2.镜像要推送到harbor仓库;\n\t\t3.nfs作为后端存储;\n\n\n\t0.创建nfs的存储目录\n[root@master231 ~]# mkdir -pv /oldboyedu/data/nfs-server/mysql80/\nmkdir: created directory '/oldboyedu/data/nfs-server/mysql80/'\n[root@master231 ~]# \n[root@master231 ~]# chmod +777 /oldboyedu/data/nfs-server/mysql80/\n[root@master231 ~]# \n\n\n\t1.编写资源清单 \n[root@master231 pods]# cat 10-pods-volume-nfs-env-mysql.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-002\n  labels:\n    apps: mysql80\nspec:\n  nodeName: worker232\n  volumes:\n  - name: db\n    nfs:\n      server: 10.0.0.231\n      path: /oldboyedu/data/nfs-server/mysql80\n  containers:\n  - image: harbor.oldboyedu.com/oldboyedu-db/mysql:8.3.0-oracle\n    name: mysql\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: oldboyedu\n    - name: MYSQL_DATABASE\n      value: wordpress\n    - name: MYSQL_USER\n      value: linux92\n    - name: MYSQL_PASSWORD\n      value: \"123\"\n    volumeMounts:\n    - name: db\n      mountPath: /var/lib/mysql\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME        READY   STATUS        RESTARTS      AGE    IP            NODE        NOMINATED NODE   READINESS GATES\nmysql-002   1/1     Running       1 (26s ago)   42s    10.100.1.39   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# kubectl exec mysql-002  -- env \n...\nMYSQL_ROOT_PASSWORD=oldboyedu\nMYSQL_DATABASE=wordpress\nMYSQL_USER=linux92\nMYSQL_PASSWORD=123\n...\n[root@master231 pods]# \n\n\n\t2.测试数据验证\n[root@master231 pods]# kubectl exec -it mysql-002  -- mysql -poldboyedu\nmysql: [Warning] Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 10\nServer version: 8.3.0 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2024, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n| wordpress          |\n+--------------------+\n5 rows in set (0.00 sec)\n\nmysql> \nmysql> \nmysql> SELECT user,host FROM mysql.user;\n+------------------+-----------+\n| user             | host      |\n+------------------+-----------+\n| linux92          | %         |\n| root             | %         |\n| mysql.infoschema | localhost |\n| mysql.session    | localhost |\n| mysql.sys        | localhost |\n| root             | localhost |\n+------------------+-----------+\n6 rows in set (0.00 sec)\n\nmysql> \nmysql> \nmysql> use wordpress;\nDatabase changed\nmysql> \nmysql> SHOW TABLES;\nEmpty set (0.00 sec)\n\nmysql> \nmysql> \nmysql> CREATE TABLE student(id INT PRIMARY KEY AUTO_INCREMENT,name VARCHAR(255) NOT NULL,hobby VARCHAR(255) NOT NULL);\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> \nmysql> \nmysql> DESC student;\n+-------+--------------+------+-----+---------+----------------+\n| Field | Type         | Null | Key | Default | Extra          |\n+-------+--------------+------+-----+---------+----------------+\n| id    | int          | NO   | PRI | NULL    | auto_increment |\n| name  | varchar(255) | NO   |     | NULL    |                |\n| hobby | varchar(255) | NO   |     | NULL    |                |\n+-------+--------------+------+-----+---------+----------------+\n3 rows in set (0.00 sec)\n\nmysql> INSERT INTO student(name,hobby) VALUE ('HanWenTong','Sleep 10');\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> \nmysql> SELECT * FROM student;\n+----+------------+----------+\n| id | name       | hobby    |\n+----+------------+----------+\n|  1 | HanWenTong | Sleep 10 |\n+----+------------+----------+\n1 row in set (0.00 sec)\n\nmysql> \n\n\n\t3.删除Pod调度到另外一个worker节点\n[root@master231 pods]# vim 10-pods-volume-nfs-env-mysql.yaml \n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 10-pods-volume-nfs-env-mysql.yaml\npod/mysql-002 created\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME        READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nmysql-002   1/1     Running   0          7s    10.100.2.9   worker233   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# kubectl exec -it mysql-002 -- mysql -poldboyedu\nmysql: [Warning] Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 9\nServer version: 8.3.0 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2024, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n| wordpress          |\n+--------------------+\n5 rows in set (0.00 sec)\n\nmysql> SHOW TABLES FROM wordpress;\n+---------------------+\n| Tables_in_wordpress |\n+---------------------+\n| student             |\n+---------------------+\n1 row in set (0.00 sec)\n\nmysql> \nmysql> SELECT * FROM wordpress.student;\n+----+------------+----------+\n| id | name       | hobby    |\n+----+------------+----------+\n|  1 | HanWenTong | Sleep 10 |\n+----+------------+----------+\n1 row in set (0.00 sec)\n\nmysql> \n \n\n\n\n\n- Pod容器的三种类型\n\t1.Pod容器的类型有三种\n基础架构容器:\n\t最先启动的容器，由K8S组件自身维护，无需运维人员介入。\n\t作用: 为初始化容器和业务容器提供网络名称空间。\n\n初始化容器:\n\t就是做一些初始化的工作，优先于业务容器启动。\n\t\n\t我们可以定义多个初始化容器，当所有的初始化容器执行完毕后，才会执行业务容器。\n\n业务容器:\n\t实际的业务容器，这个是运行的实际业务。\n\t\n\n\n\t2.实战案例\n\t\t2.1 编写资源清单\n[root@master231 pods]# cat 11-pods-initContainers.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: pause-initcontainers-containers-001\nspec:\n  nodeName: worker232\n  initContainers:\n  - name: init01\n    image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    command: [\"sleep\",\"30\"]\n  - command:\n    - /bin/sh\n    - -c\n    - \"touch /haha\"\n    image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    name: init02\n  # 注意，所有的初始化容器执行完成后，才会去执行业务容器\n  #- image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n  #  name: init03\n  #  args:\n  #  - tail\n  #  - -f\n  #  - /etc/hosts\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n[root@master231 pods]# \n\n\n\t\t2.2 查看容器的信息\n[root@worker232 ~]# docker ps -a --no-trunc | grep pause-initcontainers-containers-001 \n\n\n\n\n- 初始化容器和业务容器实现数据共享\n\t1.初始化容器的作用:\n一般都是为了给业务容器提供初始化相关工作的。\n\n\n\t2.创建资源清单\n[root@master231 pods]# cat 12-pods-initContainers-volumes.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: initcontainers-containers-volumes-001\nspec:\n  nodeName: worker232\n  volumes:\n  - name: data\n    emptyDir: {}\n  initContainers:\n  - name: init01\n    image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    volumeMounts:\n    - name: data\n      mountPath: /xixi\n    command:\n    - /bin/sh\n    - -c \n    - \"date >> /xixi/init01.log\"\n  - command:\n    - /bin/sh\n    - -c\n    - \"echo www.oldboyedu.com >> /haha/init02.log\"\n    volumeMounts:\n    - name: data\n      mountPath: /haha\n    image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    name: init02\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n    volumeMounts:\n    - name: data\n      mountPath: /data\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 12-pods-initContainers-volumes.yaml\npod/initcontainers-containers-volumes-001 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME                                    READY   STATUS            RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\ninitcontainers-containers-volumes-001   0/1     PodInitializing   0          3s    10.100.1.47   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide\nNAME                                    READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\ninitcontainers-containers-volumes-001   1/1     Running   0          5s    10.100.1.47   worker232   <none>           <none>\n[root@master231 pods]# \n\n\n\t3.worker查看容器的运行状态\n[root@worker232 ~]# docker ps -a  | grep initcontainers-containers-volumes-001\nb725be35661e   f28fd43be4ad                                         \"/docker-entrypoint.…\"   11 seconds ago   Up 10 seconds                         k8s_xiuxian_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\nc03f2010b3a8   f28fd43be4ad                                         \"/bin/sh -c 'echo ww…\"   12 seconds ago   Exited (0) 11 seconds ago             k8s_init02_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n968d92e07601   f28fd43be4ad                                         \"/bin/sh -c 'date >>…\"   12 seconds ago   Exited (0) 11 seconds ago             k8s_init01_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n9841997b48a5   registry.aliyuncs.com/google_containers/pause:3.6    \"/pause\"                 13 seconds ago   Up 12 seconds                         k8s_POD_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n[root@worker232 ~]# \n\n\n\n\t4.查看业务容器的数据\n[root@master231 pods]# kubectl exec -it initcontainers-containers-volumes-001 -- sh\nDefaulted container \"xiuxian\" out of: xiuxian, init01 (init), init02 (init)\n/ # ls /data/\ninit01.log  init02.log\n/ # \n/ # \n/ # cat /data/init01.log \nWed Jul 31 08:42:24 UTC 2024\n/ # \n/ # cat /data/init02.log \nwww.oldboyedu.com\n/ # \n\n\n\t5.尝试kill掉业务容器，观察初始化容器是否重启\n[root@worker232 ~]# docker ps -a  | grep initcontainers-containers-volumes-001\nb725be35661e   f28fd43be4ad                                         \"/docker-entrypoint.…\"   11 seconds ago   Up 10 seconds                         k8s_xiuxian_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\nc03f2010b3a8   f28fd43be4ad                                         \"/bin/sh -c 'echo ww…\"   12 seconds ago   Exited (0) 11 seconds ago             k8s_init02_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n968d92e07601   f28fd43be4ad                                         \"/bin/sh -c 'date >>…\"   12 seconds ago   Exited (0) 11 seconds ago             k8s_init01_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n9841997b48a5   registry.aliyuncs.com/google_containers/pause:3.6    \"/pause\"                 13 seconds ago   Up 12 seconds                         k8s_POD_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n[root@worker232 ~]# \n[root@worker232 ~]# \n[root@worker232 ~]# docker kill b725be35661e\nb725be35661e\n[root@worker232 ~]# \n[root@worker232 ~]# docker ps -a  | grep initcontainers-containers-volumes-001\n992d937d6105   f28fd43be4ad                                         \"/docker-entrypoint.…\"   1 second ago         Up 1 second                               k8s_xiuxian_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_1\nb725be35661e   f28fd43be4ad                                         \"/docker-entrypoint.…\"   About a minute ago   Exited (137) 2 seconds ago                k8s_xiuxian_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\nc03f2010b3a8   f28fd43be4ad                                         \"/bin/sh -c 'echo ww…\"   About a minute ago   Exited (0) About a minute ago             k8s_init02_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n968d92e07601   f28fd43be4ad                                         \"/bin/sh -c 'date >>…\"   About a minute ago   Exited (0) About a minute ago             k8s_init01_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n9841997b48a5   registry.aliyuncs.com/google_containers/pause:3.6    \"/pause\"                 About a minute ago   Up About a minute                         k8s_POD_initcontainers-containers-volumes-001_default_95f0b7d8-4991-465c-bcd3-1063e085f872_0\n[root@worker232 ~]# \n\n\n\n温馨提示:\n\t从结果上看，业务容器重启时，初始化容器并不会重启，也就是说，Pod初始化容器是一次性的。\n\t\n\t换句话说，Pod启动过程中，初始化容器只能被执行一次。\n\t\n\t\n\t \n\n- rc控制器 ---》replicationcontrollers\n\t1.作用 \n保证指定Pod数量副本始终存活。底层基于标签管理Pod\n\n\n\t2.案例\n[root@master231 rc]# cat 01-rc-xiuxian.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: xiuxian-rc\nspec:\n  # 表示rc启动的Pod副本数量\n  replicas: 3\n  # 定义标签选择器，用于管理Pod\n  selector:\n    apps: xiuxian\n  # 定义Pod的模板\n  template:\n    metadata:\n      labels:\n        apps: xiuxian\n        school: oldboyedu\n        class: linux92\n    spec:   \n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n        name: xiuxian\n[root@master231 rc]# \n\n\n\t3.删除rc时会自动删除其创建的Pod\n[root@master231 ~]# kubectl get pods --show-labels -o wide\nNAME               READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES   LABELS\nxiuxian-rc-9xsx2   1/1     Running   0          35s     10.100.1.50   worker232   <none>           <none>            apps=xiuxian,class=linux92,school=oldboyedu\nxiuxian-rc-dkjd7   1/1     Running   0          2m10s   10.100.2.12   worker233   <none>           <none>            apps=xiuxian,class=linux92,school=oldboyedu\nxiuxian-rc-kzq2f   1/1     Running   0          2m10s   10.100.1.49   worker232   <none>           <none>            apps=xiuxian,class=linux92,school=oldboyedu\n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# kubectl get rc\nNAME         DESIRED   CURRENT   READY   AGE\nxiuxian-rc   3         3         3       3m4s\n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# kubectl delete rc xiuxian-rc \nreplicationcontroller \"xiuxian-rc\" deleted\n[root@master231 ~]# \n[root@master231 ~]# kubectl get pods --show-labels -o wide\nNo resources found in default namespace.\n[root@master231 ~]# \n\n \n- svc实现四层代理\n\t1.svc的作用\n基于标签关联后端的Pod。为Pod提供了负载均衡和服务发现功能，为客户端提供了统一的访问入口。\n\n\n\t2.clusterIP案例\n[root@master231 svc]# cat 01-clusterIP-xiuxian.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc-clusterip\nspec:\n  # 指定svc的类型，有效值为ExternalName, ClusterIP, NodePort, LoadBalancer，默认值为: \"ClusterIP\"\n  #    ClusterIP:\n  #       提供的svc的VIP地址，基于该VIP地址可以访问后端的Pod。\n  #    NodePort:\n  #       在ClusterIP基础之上，在所有的worker node节点添加了iptables端口映射，可以基于任意worker节点的端口映射访问Pod\n  type: ClusterIP\n  # 基于标签关联Pod，标签的键值对要和Pod关联上\n  selector:\n    school: oldboyedu\n    apps: xiuxian\n  # 配置端口映射\n  ports:\n    # 对应的是SVC的port端口\n  - port: 88\n    # 对应的是Pod的端口\n    targetPort: 80\n[root@master231 svc]# \n\n\n\n- svc的负载均衡验证\n[root@master231 svc]# kubectl get pods -o wide\nNAME               READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-rc-77vw8   1/1     Running   0          11m   10.100.1.53   worker232   <none>           <none>\nxiuxian-rc-rzs5w   1/1     Running   0          11m   10.100.2.15   worker233   <none>           <none>\nxiuxian-rc-tsqk9   1/1     Running   0          11m   10.100.2.14   worker233   <none>           <none>\n[root@master231 svc]# \n[root@master231 svc]# kubectl exec -it xiuxian-rc-77vw8 -- sh\n/ # echo 1111111111111 > /usr/share/nginx/html/index.html \n/ # \n/ # \n[root@master231 svc]# \n[root@master231 svc]# kubectl exec -it xiuxian-rc-rzs5w -- sh\n/ # \n/ # echo 22222222222 > /usr/share/nginx/html/index.html \n/ # \n/ # \n[root@master231 svc]# \n[root@master231 svc]# kubectl exec -it xiuxian-rc-tsqk9 -- sh\n/ # echo 33333333333 > /usr/share/nginx/html/index.html \n/ # \n[root@master231 svc]# \n[root@master231 svc]# for i in `seq 10`; do curl 10.200.236.32:88;done\n33333333333\n22222222222\n22222222222\n1111111111111\n1111111111111\n33333333333\n33333333333\n1111111111111\n1111111111111\n33333333333\n[root@master231 svc]#  \n\n\n- 响应式修改rc及svc的服务发现验证\n[root@master231 ~]# kubectl get pods -o wide\nNAME               READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-rc-689fc   1/1     Running   0          3s    10.100.1.56   worker232   <none>           <none>\nxiuxian-rc-hrmhx   1/1     Running   0          3s    10.100.2.18   worker233   <none>           <none>\nxiuxian-rc-s4pgq   1/1     Running   0          3s    10.100.2.17   worker233   <none>           <none>\n[root@master231 ~]# \n[root@master231 ~]# kubectl describe svc xiuxian-svc-clusterip \nName:              xiuxian-svc-clusterip\nNamespace:         default\nLabels:            <none>\nAnnotations:       <none>\nSelector:          apps=xiuxian,school=oldboyedu\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.200.236.32\nIPs:               10.200.236.32\nPort:              <unset>  88/TCP\nTargetPort:        80/TCP\nEndpoints:         10.100.1.56:80,10.100.2.17:80,10.100.2.18:80\nSession Affinity:  None\nEvents:            <none>\n[root@master231 ~]# \n[root@master231 ~]# kubectl edit rc xiuxian-rc  # 找到\"replicas\"字段修改后，使用\"wq\"退出，和vim命令类似。\nreplicationcontroller/xiuxian-rc edited\n[root@master231 ~]# \n[root@master231 ~]# kubectl get pods -o wide\nNAME               READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-rc-s4pgq   1/1     Running   0          47s   10.100.2.17   worker233   <none>           <none>\n[root@master231 ~]# \n[root@master231 ~]# kubectl describe svc xiuxian-svc-clusterip \nName:              xiuxian-svc-clusterip\nNamespace:         default\nLabels:            <none>\nAnnotations:       <none>\nSelector:          apps=xiuxian,school=oldboyedu\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.200.236.32\nIPs:               10.200.236.32\nPort:              <unset>  88/TCP\nTargetPort:        80/TCP\nEndpoints:         10.100.2.17:80\nSession Affinity:  None\nEvents:            <none>\n[root@master231 ~]# \n\n\n\n\n- svc的NodePort类型案例\n\t1.编写资源清单\n[root@master231 svc]# cat 02-nodePort-xiuxian.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc-nodeport\nspec:\n  # 指定svc的类型，有效值为ExternalName, ClusterIP, NodePort, LoadBalancer，默认值为: \"ClusterIP\"\n  #    ClusterIP:\n  #       提供的svc的VIP地址，基于该VIP地址可以访问后端的Pod。\n  #    NodePort:\n  #       在ClusterIP基础之上，在所有的worker node节点添加了iptables端口映射，可以基于任意worker节点的端口映射访问Pod\n  type: NodePort\n  # 基于标签关联Pod，标签的键值对要和Pod关联上\n  selector:\n    school: oldboyedu\n    apps: xiuxian\n  # 配置端口映射\n  ports:\n    # 对应的是SVC的port端口\n  - port: 88\n    # 对应的是Pod的端口\n    targetPort: 80\n    # 指定worker节点的端口映射，若不指定，则默认在\"30000-32767\"端口范围内随机生成\n    nodePort: 30080\n[root@master231 svc]# \n[root@master231 svc]# kubectl apply -f 02-nodePort-xiuxian.yaml \nservice/xiuxian-svc-nodeport created\n[root@master231 svc]# \n[root@master231 svc]# kubectl get -f 02-nodePort-xiuxian.yaml\nNAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\nxiuxian-svc-nodeport   NodePort   10.200.40.89   <none>        88:30080/TCP   4s\n[root@master231 svc]# \n\n\t2.修改Pod数据并验证\n[root@master231 ~]# kubectl get pods -o wide\nNAME               READY   STATUS        RESTARTS   AGE    IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-rc-2hkzv   1/1     Running       0          9m1s   10.100.1.58   worker232   <none>           <none>\nxiuxian-rc-s4pgq   1/1     Running       0          10m    10.100.2.17   worker233   <none>           <none>\n[root@master231 ~]# \n[root@master231 ~]# kubectl exec -it xiuxian-rc-2hkzv -- sh\n/ #\n/ # echo 111111111111111111 > /usr/share/nginx/html/index.html \n/ # \n/ # \n/ # \n[root@master231 ~]# \n[root@master231 ~]# kubectl exec -it xiuxian-rc-s4pgq -- sh\n/ # \n/ # echo 2222222222222222222 > /usr/share/nginx/html/index.html \n/ # \n/ # \n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# for i in `seq 10`; do curl http://10.0.0.233:30080/;done\n111111111111111111\n111111111111111111\n111111111111111111\n2222222222222222222\n111111111111111111\n2222222222222222222\n111111111111111111\n2222222222222222222\n111111111111111111\n111111111111111111\n[root@master231 ~]# \n[root@master231 ~]# for i in `seq 10`; do curl http://10.0.0.232:30080/;done\n111111111111111111\n2222222222222222222\n2222222222222222222\n111111111111111111\n2222222222222222222\n111111111111111111\n2222222222222222222\n111111111111111111\n111111111111111111\n111111111111111111\n[root@master231 ~]# \n[root@master231 ~]# for i in `seq 10`; do curl http://10.0.0.231:30080/;done\n111111111111111111\n2222222222222222222\n111111111111111111\n111111111111111111\n2222222222222222222\n2222222222222222222\n2222222222222222222\n2222222222222222222\n2222222222222222222\n111111111111111111\n[root@master231 ~]# \n\n\n\n温馨提示:\n\tNodePort本质上都添加了iptables的DNAT的映射规则。\n\t\n\t\n\t\n今日内容回顾:\n\t- 故障排查技巧\t\t*****\n\t\t- kubectl logs \n\t\t- kubectl describe\n\t\t- kubectl cp \n\t\t- kubectl explain\n\t\t- po.spec.container:\n\t\t\tcommond\n\t\t\targs \n\t\n\t- rc控制器:\t**\n\t\t基于标签控制指定Pod的副本数量存活。\n\t\t\n\t- svc\n\t\t1.为客户端提供了统一的访问入口;\n\t\t2.为Pod提供流量的负载均衡;\n\t\t3.为Pod提供服务发现;\n\t\n\t\t- svc常用的两个类型:\t*****\n\t\t\t- ClusterIP:\n\t\t\t- NodePort:\n\n\t- 存储卷:\t\t*****\n\t\t- emptyDir \n\t\t- hostPath \n\t\t- nfs \n\t\t\n今日作业:\n\t- 1.完成课堂的所有练习并整理思维导图;\n\t- 2.将wordpress部署到K8S集群，并能够访问，要求如下 \n\t\t1.使用rc部署MySQL，要求数据不丢失;\n\t\t2.使用svc的ClusterIP类型暴露MySQL服务\n\t\t3.使用wordpress基于svc访问数据库;\n\t\t4.要求wordpress的副本数量是3个，wordpress的svc是NodePort类型\n\t\t5.要求上传到wordpress的数据不丢失，删除Pod数据不丢失!\n\t\t\n\t\t\n扩展作业:\n\t- 调研使用kind部署K8S集群。 \n\t\n\t\n\t","x":-100,"y":180,"width":940,"height":540},
		{"id":"bc85b2ffc4279153","type":"text","text":"- 昨日内容回顾:\n\t- 故障排查技巧  ✨\n\t\t- kubectl describe:\n\t\t\t查看events信息。\n\t\t- kubectl logs:\n\t\t\t查看Pod的日志信息。\n\t\t- 容器无法启动:\n\t\t\tcommand\n\t\t\targs\n\t\t\t\n\t\t- kubectl cp \n\t\t- kubectl exec\n\t\t- kubectl explain\n\t\t- ...\n\t\t\n\t- 存储卷 \n\t\t- emptyDir：\n\t\t\t本质上是一个临时目录，随着Pod的生命周期存在而存在。\n\t\t\t应用场景:\n\t\t\t\t- 1.同一个Pod不同容器实现数据共享: filebeat + nginx，zabbix-agent + 业务容器\n\t\t\t\t- 2.临时数据缓存，比如MySQL等数据库在查询时，需要将一些结果缓存到本地;\n\t\t\t\t\n\t\t\t\t\n\t\t- hostPath:\n\t\t\t本质上就是用于Pod的容器访问宿主机目录的场景。\n\t\t\t应用场景：\n\t\t\t\t将宿主机的某个路径挂载到容器，当容器删除时，宿主机数据并不丢失。\n\t\t\t\t\n\t\t\n\t\t- nfs:\n\t\t\t实现多个不同节点Pod的数据共享。\n\t\t\t\n  \n\t- rc控制器\n\t\t副本控制器，基于标签关联Pod，控制指定副本数量的Pod始终存活。\n\t\n\t\n\t- svc实现Pod的四层代理\n\t\t服务代理，基于标签关联Pod，访问svc的端口会转发到关联Pod的后端Pod端口。\n\t\t有两种常用的类型： \n\t\t\t- ClusterIP:\n\t\t\t\tK8S集群内部访问使用。\n\t\n\t\t\t- NodePort:\n\t\t\t\tK8S集群外部需要访问时才会使用。\n\t\t有三个作用：\n\t\t\t- 1.为Pod提供流量的负载均衡;\n\t\t\t- 2.为Pod提供服务发现;\n\t\t\t- 3.为客户端提供统一的访问入口;\n\n\n\n\n今日内容预告:\n\t- K8S部署wordpress案例\n\t- coreDNS附加组件\n\t- Pod的创建流程\n\t- Pod的端口暴露实现服务访问\n\t- K8s实现蓝绿部署\n\t- K8S实现灰度发布|金丝雀发布\n\t- rs控制器\n\t- deploy控制器\n\t\n\t\n- 将wordpress部署到K8S集群，并能够访问，要求如下 \n\t\t1.使用rc部署MySQL，要求数据不丢失;\n\t\t2.使用svc的ClusterIP类型暴露MySQL服务\n\t\t3.使用wordpress基于svc访问数据库;\n\t\t4.要求wordpress的副本数量是3个，wordpress的svc是NodePort类型\n\t\t5.要求上传到wordpress的数据不丢失，删除Pod数据不丢失!\n\t\t\n\t\n\n- 将wordpress部署到K8S集群 [没有持久化]\n\t1.编写资源清单部署\n[root@master231 v1]# ll\ntotal 24\ndrwxr-xr-x 2 root root 4096 Aug  1 09:55 ./\ndrwxr-xr-x 3 root root 4096 Aug  1 09:34 ../\n-rw-r--r-- 1 root root  538 Aug  1 09:38 01-rc-mysql.yaml\n-rw-r--r-- 1 root root  294 Aug  1 09:53 02-svc-db.yaml\n-rw-r--r-- 1 root root  738 Aug  1 09:55 03-rc-wordpress.yaml\n-rw-r--r-- 1 root root  163 Aug  1 09:45 04-svc-wordpress.yaml\n[root@master231 v1]# \n[root@master231 v1]# \n[root@master231 v1]# \n[root@master231 v1]# \n[root@master231 v1]# cat 01-rc-mysql.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-mysql\nspec:\n  replicas: 1\n  selector:\n    apps: mysql80\n  template:\n    metadata:\n      labels:\n        apps: mysql80\n    spec:   \n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-db/mysql:8.3.0-oracle\n        name: db\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: oldboyedu\n        - name: MYSQL_DATABASE\n          value: wordpress\n        - name: MYSQL_USER\n          value: linux92\n        - name: MYSQL_PASSWORD\n          value: \"123\"\n[root@master231 v1]# \n[root@master231 v1]# cat 02-svc-db.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: db-svc\nspec:\n  type: ClusterIP\n  # 指定ClusterIP的VIP地址，指定svc的网段即可，我们集群部署采用的svc网段为\"10.200.0.0/16\"\n  clusterIP: 10.200.0.36\n  selector:\n    apps: mysql80\n  ports:\n  - port: 3306\n    targetPort: 3306\n[root@master231 v1]# \n[root@master231 v1]# \n[root@master231 v1]# cat 03-rc-wordpress.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-wordpress\nspec:\n  replicas: 1\n  selector:\n    apps: wp\n  template:\n    metadata:\n      labels:\n        apps: wp\n    spec:   \n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-web/wordpress\n        name: wp\n        env:\n        - name: WORDPRESS_DB_HOST\n          # 指定的是Pod的地址当Pod发生变化时，IP地址需要变动\n          # value: 10.100.1.60\n          # 此处我指定的是ClusterIP的地址，ClusterIP的地址被我固定\n          value: 10.200.0.36\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        - name: WORDPRESS_DB_USER\n          value: linux92\n        - name: WORDPRESS_DB_PASSWORD\n          value: \"123\"\n[root@master231 v1]# \n[root@master231 v1]# \n[root@master231 v1]# cat 04-svc-wordpress.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: wp-svc\nspec:\n  type: NodePort\n  selector:\n    apps: wp\n  ports:\n  - port: 80\n    targetPort: 80\n    nodePort: 30090\n[root@master231 v1]# \n[root@master231 v1]# kubectl apply -f .\nreplicationcontroller/rc-mysql created\nservice/db-svc created\nreplicationcontroller/rc-wordpress created\nservice/wp-svc created\n[root@master231 v1]# \n[root@master231 v1]# kubectl get po,svc -o wide\nNAME                     READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\npod/rc-mysql-7vlgx       1/1     Running   0          6s    10.100.2.25   worker233   <none>           <none>\npod/rc-wordpress-8vkbz   1/1     Running   0          6s    10.100.2.26   worker233   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR\nservice/db-svc       ClusterIP   10.200.0.36    <none>        3306/TCP       6s      apps=mysql80\nservice/kubernetes   ClusterIP   10.200.0.1     <none>        443/TCP        2d17h   <none>\nservice/wp-svc       NodePort    10.200.134.1   <none>        80:30090/TCP   6s      apps=wp\n[root@master231 v1]# \n\n\n\t2.初始化wordpress的页面\n略。\n\n\t3.将wordpress的副本你修改为3观察现象。\n[root@master231 v1]# kubectl edit rc rc-wordpress \nreplicationcontroller/rc-wordpress edited\n[root@master231 v1]# \n\n\n\n\n- wordpress实现数据持久化\n\t1.创建测试目录\n[root@master231 ~]# mkdir -pv /oldboyedu/data/nfs-server/wordpress\nmkdir: created directory '/oldboyedu/data/nfs-server/wordpress'\n[root@master231 ~]# \n[root@master231 ~]# chmod +777 /oldboyedu/data/nfs-server/wordpress\n[root@master231 ~]# \n[root@master231 ~]# rm -rf /oldboyedu/data/nfs-server/mysql80/*\n[root@master231 ~]# \n[root@master231 ~]# ll -ld /oldboyedu/data/nfs-server/mysql80/\ndrwxrwxrwx 2 lxd root 4096 Aug  1 10:36 /oldboyedu/data/nfs-server/mysql80//\n[root@master231 ~]# \n[root@master231 ~]# ll  /oldboyedu/data/nfs-server/mysql80/\ntotal 8\ndrwxrwxrwx 2 lxd  root 4096 Aug  1 10:36 ./\ndrwxr-xr-x 4 root root 4096 Aug  1 10:35 ../\n[root@master231 ~]# \n\n\t2.编写资源清单部署\n[root@master231 v2-svc-volumes]# cat 01-rc-mysql.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-mysql\nspec:\n  replicas: 1\n  selector:\n    apps: mysql80\n  template:\n    metadata:\n      labels:\n        apps: mysql80\n    spec:   \n      volumes:\n      - name: data\n        nfs:\n          server: master231\n          path: /oldboyedu/data/nfs-server/mysql80\n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-db/mysql:8.3.0-oracle\n        name: db\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: oldboyedu\n        - name: MYSQL_DATABASE\n          value: wordpress\n        - name: MYSQL_USER\n          value: linux92\n        - name: MYSQL_PASSWORD\n          value: \"123\"\n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# cat 02-svc-db.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: db-svc\nspec:\n  type: ClusterIP\n  # 指定ClusterIP的VIP地址，指定svc的网段即可，我们集群部署采用的svc网段为\"10.200.0.0/16\"\n  clusterIP: 10.200.0.36\n  selector:\n    apps: mysql80\n  ports:\n  - port: 3306\n    targetPort: 3306\n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# cat 03-rc-wordpress.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-wordpress\nspec:\n  replicas: 3\n  selector:\n    apps: wp\n  template:\n    metadata:\n      labels:\n        apps: wp\n    spec:\n      volumes:\n      - name: data\n        nfs:\n          server: master231\n          path: /oldboyedu/data/nfs-server/wordpress\n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-web/wordpress\n        name: wp\n        volumeMounts:\n        - name: data\n          mountPath: /var/www/html\n        env:\n        - name: WORDPRESS_DB_HOST\n          # 指定的是Pod的地址当Pod发生变化时，IP地址需要变动\n          # value: 10.100.1.60\n          # 此处我指定的是ClusterIP的地址，ClusterIP的地址被我固定\n          value: 10.200.0.36\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        - name: WORDPRESS_DB_USER\n          value: linux92\n        - name: WORDPRESS_DB_PASSWORD\n          value: \"123\"\n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# cat 04-svc-wordpress.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: wp-svc\nspec:\n  type: NodePort\n  selector:\n    apps: wp\n  ports:\n  - port: 80\n    targetPort: 80\n    nodePort: 30090\n[root@master231 v2-svc-volumes]# \n\n\n\t3.创建资源\n[root@master231 v2-svc-volumes]# ll\ntotal 24\ndrwxr-xr-x 2 root root 4096 Aug  1 10:40 ./\ndrwxr-xr-x 4 root root 4096 Aug  1 10:35 ../\n-rw-r--r-- 1 root root  743 Aug  1 10:40 01-rc-mysql.yaml\n-rw-r--r-- 1 root root  294 Aug  1 10:35 02-svc-db.yaml\n-rw-r--r-- 1 root root  941 Aug  1 10:39 03-rc-wordpress.yaml\n-rw-r--r-- 1 root root  163 Aug  1 10:35 04-svc-wordpress.yaml\n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# vim 03-rc-wordpress.yaml \n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# kubectl apply -f .\nreplicationcontroller/rc-mysql created\nservice/db-svc created\nreplicationcontroller/rc-wordpress created\nservice/wp-svc created\n[root@master231 v2-svc-volumes]# \n[root@master231 v2-svc-volumes]# kubectl get pods -o wide\nNAME                 READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nrc-mysql-75ww9       1/1     Running   0          5s    10.100.1.69   worker232   <none>           <none>\nrc-wordpress-7xn2b   1/1     Running   0          5s    10.100.2.34   worker233   <none>           <none>\nrc-wordpress-lb7b2   1/1     Running   0          5s    10.100.2.33   worker233   <none>           <none>\nrc-wordpress-tzxlj   1/1     Running   0          5s    10.100.1.70   worker232   <none>           <none>\n[root@master231 v2-svc-volumes]# \n\n\t\n\t4.验证测试\n略。见视频 \n\t\n\t\n\t\n- 引入coreDNS附加组件实现wordpress的数据库解析\n\t1.作用\n将svc的名称解析为CLusterIP\n\n\t2.案例-wordpress \n[root@master231 v3-svc-volumes-CoreDNS]# ll\ntotal 24\ndrwxr-xr-x 2 root root 4096 Aug  1 10:55 ./\ndrwxr-xr-x 5 root root 4096 Aug  1 10:51 ../\n-rw-r--r-- 1 root root  743 Aug  1 10:51 01-rc-mysql.yaml\n-rw-r--r-- 1 root root  296 Aug  1 10:55 02-svc-db.yaml\n-rw-r--r-- 1 root root 1146 Aug  1 10:54 03-rc-wordpress.yaml\n-rw-r--r-- 1 root root  163 Aug  1 10:51 04-svc-wordpress.yaml\n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# cat 01-rc-mysql.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-mysql\nspec:\n  replicas: 1\n  selector:\n    apps: mysql80\n  template:\n    metadata:\n      labels:\n        apps: mysql80\n    spec:   \n      volumes:\n      - name: data\n        nfs:\n          server: master231\n          path: /oldboyedu/data/nfs-server/mysql80\n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-db/mysql:8.3.0-oracle\n        name: db\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: oldboyedu\n        - name: MYSQL_DATABASE\n          value: wordpress\n        - name: MYSQL_USER\n          value: linux92\n        - name: MYSQL_PASSWORD\n          value: \"123\"\n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# cat 02-svc-db.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: db-svc\nspec:\n  type: ClusterIP\n  # 指定ClusterIP的VIP地址，指定svc的网段即可，我们集群部署采用的svc网段为\"10.200.0.0/16\"\n  # clusterIP: 10.200.0.36\n  selector:\n    apps: mysql80\n  ports:\n  - port: 3306\n    targetPort: 3306\n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# cat 03-rc-wordpress.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-wordpress\nspec:\n  replicas: 3\n  selector:\n    apps: wp\n  template:\n    metadata:\n      labels:\n        apps: wp\n    spec:\n      volumes:\n      - name: data\n        nfs:\n          server: master231\n          path: /oldboyedu/data/nfs-server/wordpress\n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-web/wordpress\n        name: wp\n        volumeMounts:\n        - name: data\n          mountPath: /var/www/html\n        env:\n        - name: WORDPRESS_DB_HOST\n          # 指定的是Pod的地址当Pod发生变化时，IP地址需要变动\n          # value: 10.100.1.60\n          # 此处我指定的是ClusterIP的地址，ClusterIP的地址被我固定。\n          # value: 10.200.0.36\n          # 有些场合下，svc的地址无法固定，或者已经分配，则不建议使用ClusterIP进行通信\n          # 可以考虑直接使用svc的名称即可。\n          value: db-svc\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        - name: WORDPRESS_DB_USER\n          value: linux92\n        - name: WORDPRESS_DB_PASSWORD\n          value: \"123\"\n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# \n[root@master231 v3-svc-volumes-CoreDNS]# cat 04-svc-wordpress.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: wp-svc\nspec:\n  type: NodePort\n  selector:\n    apps: wp\n  ports:\n  - port: 80\n    targetPort: 80\n    nodePort: 30090\n[root@master231 v3-svc-volumes-CoreDNS]# \n\n\t\n\n\t- 验证coreDNS附加组件是否正常工作\n\t\t1.查看所有名称空间的资源\n[root@master231 ~]# kubectl get svc -A\nNAMESPACE     NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE\ndefault       db-svc       ClusterIP   10.200.23.61   <none>        3306/TCP                 6m55s\ndefault       kubernetes   ClusterIP   10.200.0.1     <none>        443/TCP                  2d18h\ndefault       wp-svc       NodePort    10.200.5.240   <none>        80:30090/TCP             6m55s\nkube-system   kube-dns     ClusterIP   10.200.0.10    <none>        53/UDP,53/TCP,9153/TCP   2d18h\n[root@master231 ~]# \n\n\n\t\t2.查看coreDNS组件是否正常运行\n[root@master231 ~]# kubectl get pods -n kube-system --show-labels -l k8s-app=kube-dns\nNAME                      READY   STATUS    RESTARTS      AGE     LABELS\ncoredns-6d8c4cb4d-2l5jw   1/1     Running   2 (26h ago)   2d18h   k8s-app=kube-dns,pod-template-hash=6d8c4cb4d\ncoredns-6d8c4cb4d-qs4pd   1/1     Running   2 (26h ago)   2d18h   k8s-app=kube-dns,pod-template-hash=6d8c4cb4d\n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# kubectl get pods -A --show-labels -l k8s-app=kube-dns\nNAMESPACE     NAME                      READY   STATUS    RESTARTS      AGE     LABELS\nkube-system   coredns-6d8c4cb4d-2l5jw   1/1     Running   2 (26h ago)   2d18h   k8s-app=kube-dns,pod-template-hash=6d8c4cb4d\nkube-system   coredns-6d8c4cb4d-qs4pd   1/1     Running   2 (26h ago)   2d18h   k8s-app=kube-dns,pod-template-hash=6d8c4cb4d\n[root@master231 ~]# \n\n\t\t\n\t\t3.验证coreDNS组件是否正常工作方式一\n[root@master231 ~]# kubectl run test-dns --image=harbor.oldboyedu.com/oldboyedu-linux/alpine:3.20.2  -it --rm  -- sh\nIf you don't see a command prompt, try pressing enter.\n/ # \n/ # ping wp-svc\nPING wp-svc (10.200.5.240): 56 data bytes\n^C\n--- wp-svc ping statistics ---\n5 packets transmitted, 0 packets received, 100% packet loss\n/ # \n/ # \n/ # ping kubernetes\nPING kubernetes (10.200.0.1): 56 data bytes\n^C\n--- kubernetes ping statistics ---\n3 packets transmitted, 0 packets received, 100% packet loss\n/ # \n/ # \n/ # ping db-svc\nPING db-svc (10.200.23.61): 56 data bytes\n^C\n--- db-svc ping statistics ---\n3 packets transmitted, 0 packets received, 100% packet loss\n/ # \n/ # \n/ # ping kube-dns  # kube-dns的svc并不属于default名称空间，因此无法ping通\nping: bad address 'kube-dns'\n/ # \n/ # ping kube-dns.kube-system   # 如果ping不通的名称空间，则需要指定其所属的名称空间即可。\nPING kube-dns.kube-system (10.200.0.10): 56 data bytes\n^C\n--- kube-dns.kube-system ping statistics ---\n2 packets transmitted, 0 packets received, 100% packet loss\n/ # \n\n\n\t\t4.验证coreDNS组件是否正常工作方式二\n[root@master231 ~]# kubectl get svc -A\nNAMESPACE     NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE\ndefault       db-svc       ClusterIP   10.200.23.61   <none>        3306/TCP                 13m\ndefault       kubernetes   ClusterIP   10.200.0.1     <none>        443/TCP                  2d18h\ndefault       wp-svc       NodePort    10.200.5.240   <none>        80:30090/TCP             13m\nkube-system   kube-dns     ClusterIP   10.200.0.10    <none>        53/UDP,53/TCP,9153/TCP   2d18h\n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# dig @10.200.0.10 db-svc.default.svc.oldboyedu.com +short\n10.200.23.61\n[root@master231 ~]# \n[root@master231 ~]# dig @10.200.0.10 wp-svc.default.svc.oldboyedu.com +short\n10.200.5.240\n[root@master231 ~]# \n[root@master231 ~]# dig @10.200.0.10 kubernetes.default.svc.oldboyedu.com +short\n10.200.0.1\n[root@master231 ~]# \n[root@master231 ~]# dig @10.200.0.10 kube-dns.kube-system.svc.oldboyedu.com +short\n10.200.0.10\n[root@master231 ~]#  \n\n语法格式:\n\tdig @DNS服务器  A记录解析格式 \n\nA记录格式:\n\tsvc名称.名称空间.svc.你K8S集群的域名。\n\t\n举个例子:\n\tdb-svc.default.svc.oldboyedu.com\n\t\n\t\n温馨提示:\n\t若域名没有指定，则默认是\"cluster.local\"。\n\t\n\t\n\t- K8S的名称空间管理\n\t\t1.什么名称空间呢？\nK8S所谓的名称空间，就是用来隔离K8S集群资源的。\n\nK8S一切皆资源，有的资源支持名称空间，我们称之为局部资源，有的资源不支持名称空间，我们称之为全局资源。\n\n\n如何判读一个资源是否支持名乘空间呢？可以通过如下命令参考：\n[root@master231 ~]# kubectl api-resources \nNAME                              SHORTNAMES   APIVERSION                             NAMESPACED   KIND\nbindings                                       v1                                     true         Binding\ncomponentstatuses                 cs           v1                                     false        ComponentStatus\nconfigmaps                        cm           v1                                     true         ConfigMap\nendpoints                         ep           v1                                     true         Endpoints\nevents                            ev           v1                                     true         Event\nlimitranges                       limits       v1                                     true         LimitRange\nnamespaces                        ns           v1                                     false        Namespace\nnodes                             no           v1                                     false        Node\npersistentvolumeclaims            pvc          v1                                     true         PersistentVolumeClaim\npersistentvolumes                 pv           v1                                     false        PersistentVolume\npods                              po           v1                                     true         Pod\npodtemplates                                   v1                                     true         PodTemplate\nreplicationcontrollers            rc           v1                                     true         ReplicationController\nresourcequotas                    quota        v1                                     true         ResourceQuota\nsecrets                                        v1                                     true         Secret\nserviceaccounts                   sa           v1                                     true         ServiceAccount\nservices                          svc          v1                                     true         Service\nmutatingwebhookconfigurations                  admissionregistration.k8s.io/v1        false        MutatingWebhookConfiguration\nvalidatingwebhookconfigurations                admissionregistration.k8s.io/v1        false        ValidatingWebhookConfiguration\ncustomresourcedefinitions         crd,crds     apiextensions.k8s.io/v1                false        CustomResourceDefinition\napiservices                                    apiregistration.k8s.io/v1              false        APIService\ncontrollerrevisions                            apps/v1                                true         ControllerRevision\ndaemonsets                        ds           apps/v1                                true         DaemonSet\ndeployments                       deploy       apps/v1                                true         Deployment\nreplicasets                       rs           apps/v1                                true         ReplicaSet\nstatefulsets                      sts          apps/v1                                true         StatefulSet\ntokenreviews                                   authentication.k8s.io/v1               false        TokenReview\nlocalsubjectaccessreviews                      authorization.k8s.io/v1                true         LocalSubjectAccessReview\nselfsubjectaccessreviews                       authorization.k8s.io/v1                false        SelfSubjectAccessReview\nselfsubjectrulesreviews                        authorization.k8s.io/v1                false        SelfSubjectRulesReview\nsubjectaccessreviews                           authorization.k8s.io/v1                false        SubjectAccessReview\nhorizontalpodautoscalers          hpa          autoscaling/v2                         true         HorizontalPodAutoscaler\ncronjobs                          cj           batch/v1                               true         CronJob\njobs                                           batch/v1                               true         Job\ncertificatesigningrequests        csr          certificates.k8s.io/v1                 false        CertificateSigningRequest\nleases                                         coordination.k8s.io/v1                 true         Lease\nendpointslices                                 discovery.k8s.io/v1                    true         EndpointSlice\nevents                            ev           events.k8s.io/v1                       true         Event\nflowschemas                                    flowcontrol.apiserver.k8s.io/v1beta2   false        FlowSchema\nprioritylevelconfigurations                    flowcontrol.apiserver.k8s.io/v1beta2   false        PriorityLevelConfiguration\ningressclasses                                 networking.k8s.io/v1                   false        IngressClass\ningresses                         ing          networking.k8s.io/v1                   true         Ingress\nnetworkpolicies                   netpol       networking.k8s.io/v1                   true         NetworkPolicy\nruntimeclasses                                 node.k8s.io/v1                         false        RuntimeClass\npoddisruptionbudgets              pdb          policy/v1                              true         PodDisruptionBudget\npodsecuritypolicies               psp          policy/v1beta1                         false        PodSecurityPolicy\nclusterrolebindings                            rbac.authorization.k8s.io/v1           false        ClusterRoleBinding\nclusterroles                                   rbac.authorization.k8s.io/v1           false        ClusterRole\nrolebindings                                   rbac.authorization.k8s.io/v1           true         RoleBinding\nroles                                          rbac.authorization.k8s.io/v1           true         Role\npriorityclasses                   pc           scheduling.k8s.io/v1                   false        PriorityClass\ncsidrivers                                     storage.k8s.io/v1                      false        CSIDriver\ncsinodes                                       storage.k8s.io/v1                      false        CSINode\ncsistoragecapacities                           storage.k8s.io/v1beta1                 true         CSIStorageCapacity\nstorageclasses                    sc           storage.k8s.io/v1                      false        StorageClass\nvolumeattachments                              storage.k8s.io/v1                      false        VolumeAttachment\n[root@master231 ~]# \n\n\n\t2.响应式管理名称空间\n\t\t2.1 创建名称空间\n[root@master231 ~]# kubectl create ns oldboyedu\nnamespace/oldboyedu created\n[root@master231 ~]# \n\n\t\t2.2 查看名称空间\n[root@master231 ~]# kubectl get ns\nNAME              STATUS   AGE\ndefault           Active   2d18h\nkube-flannel      Active   2d18h\nkube-node-lease   Active   2d18h\nkube-public       Active   2d18h\nkube-system       Active   2d18h\noldboyedu         Active   2s\n[root@master231 ~]# \n[root@master231 ~]# kubectl get ns oldboyedu   # 查看指定的名称空间\nNAME        STATUS   AGE\noldboyedu   Active   5s\n[root@master231 ~]# \n[root@master231 ~]# kubectl get ns oldboyedu  --show-labels\nNAME        STATUS   AGE   LABELS\noldboyedu   Active   10s   kubernetes.io/metadata.name=oldboyedu\n[root@master231 ~]# \n\n\n\t\t2.3 修改名称空间\n[root@master231 ~]# kubectl get ns oldboyedu  --show-labels\nNAME        STATUS   AGE   LABELS\noldboyedu   Active   25s   kubernetes.io/metadata.name=oldboyedu\n[root@master231 ~]# \n[root@master231 ~]# \n[root@master231 ~]# kubectl label namespaces oldboyedu school=oldboyedu\nnamespace/oldboyedu labeled\n[root@master231 ~]# \n[root@master231 ~]# kubectl label ns oldboyedu class=linux92\nnamespace/oldboyedu labeled\n[root@master231 ~]# \n[root@master231 ~]# kubectl get ns oldboyedu  --show-labels\nNAME        STATUS   AGE   LABELS\noldboyedu   Active   56s   class=linux92,kubernetes.io/metadata.name=oldboyedu,school=oldboyedu\n[root@master231 ~]# \n\n\n温馨提示:\n\t名称空间不支持改名，但是可以修改标签信息。\n\t\t\n\t\t2.4 Pod使用名称空间案例\n[root@master231 pods]# cat 13-pods-xiuxian-namespace.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-v1\n  # 指定名称空间，若不指定，则默认为\"default\"名称空间\n  # namespace: default\n  namespace: oldboyedu\nspec:\n  nodeName: worker232\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 13-pods-xiuxian-namespace.yaml \npod/xiuxian-v1 created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -n oldboyedu # 查看指定名称空间的Pod，若不使用-n选项指的，则默认使用default名称空间\nNAME         READY   STATUS    RESTARTS   AGE\nxiuxian-v1   1/1     Running   0          5s\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -n oldboyedu -o wide\nNAME         READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nxiuxian-v1   1/1     Running   0          10s   10.100.1.80   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# curl 10.100.1.80  \n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"utf-8\"/>\n    <title>yinzhengjie apps v1</title>\n    <style>\n       div img {\n          width: 900px;\n          height: 600px;\n          margin: 0;\n       }\n    </style>\n  </head>\n\n  <body>\n    <h1 style=\"color: green\">凡人修仙传 v1 </h1>\n    <div>\n      <img src=\"1.jpg\">\n    <div>\n  </body>\n\n</html>\n[root@master231 pods]# \n\n\n\t\t\n\t\t2.5 使用-A选项查看的是所有名称空间资源\n[root@master231 pods]# kubectl get pods -A\nNAMESPACE      NAME                                READY   STATUS    RESTARTS      AGE\ndefault        rc-mysql-2n8vc                      1/1     Running   0             32m\ndefault        rc-wordpress-95gwz                  1/1     Running   0             32m\ndefault        rc-wordpress-9ljx6                  1/1     Running   0             32m\ndefault        rc-wordpress-pfg5c                  1/1     Running   0             32m\ndefault        xiuxian-v1                          1/1     Running   0             2m48s\nkube-flannel   kube-flannel-ds-ckkbk               1/1     Running   2 (26h ago)   2d18h\nkube-flannel   kube-flannel-ds-kst7g               1/1     Running   2 (26h ago)   2d18h\nkube-flannel   kube-flannel-ds-ljktm               1/1     Running   2 (26h ago)   2d18h\nkube-system    coredns-6d8c4cb4d-2v5xn             1/1     Running   0             16m\nkube-system    coredns-6d8c4cb4d-ts22f             1/1     Running   0             16m\nkube-system    etcd-master231                      1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-apiserver-master231            1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-controller-manager-master231   1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-proxy-2vxh9                    1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-proxy-65z9n                    1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-proxy-rmn84                    1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-scheduler-master231            1/1     Running   2 (26h ago)   2d18h\noldboyedu      xiuxian-v1                          1/1     Running   0             2m19s\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods --all-namespaces \nNAMESPACE      NAME                                READY   STATUS    RESTARTS      AGE\ndefault        rc-mysql-2n8vc                      1/1     Running   0             32m\ndefault        rc-wordpress-95gwz                  1/1     Running   0             32m\ndefault        rc-wordpress-9ljx6                  1/1     Running   0             32m\ndefault        rc-wordpress-pfg5c                  1/1     Running   0             32m\ndefault        xiuxian-v1                          1/1     Running   0             2m56s\nkube-flannel   kube-flannel-ds-ckkbk               1/1     Running   2 (26h ago)   2d18h\nkube-flannel   kube-flannel-ds-kst7g               1/1     Running   2 (26h ago)   2d18h\nkube-flannel   kube-flannel-ds-ljktm               1/1     Running   2 (26h ago)   2d18h\nkube-system    coredns-6d8c4cb4d-2v5xn             1/1     Running   0             16m\nkube-system    coredns-6d8c4cb4d-ts22f             1/1     Running   0             16m\nkube-system    etcd-master231                      1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-apiserver-master231            1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-controller-manager-master231   1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-proxy-2vxh9                    1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-proxy-65z9n                    1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-proxy-rmn84                    1/1     Running   2 (26h ago)   2d18h\nkube-system    kube-scheduler-master231            1/1     Running   2 (26h ago)   2d18h\noldboyedu      xiuxian-v1                          1/1     Running   0             2m27s\n[root@master231 pods]#  \n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -n default \nNAME                 READY   STATUS    RESTARTS   AGE\nrc-mysql-2n8vc       1/1     Running   0          33m\nrc-wordpress-95gwz   1/1     Running   0          33m\nrc-wordpress-9ljx6   1/1     Running   0          33m\nrc-wordpress-pfg5c   1/1     Running   0          33m\nxiuxian-v1           1/1     Running   0          3m9s\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods --namespace oldboyedu \nNAME         READY   STATUS    RESTARTS   AGE\nxiuxian-v1   1/1     Running   0          2m48s\n[root@master231 pods]# \n\n\n\t\t2.6\t删除名称空间 \n[root@master231 pods]# kubectl get pods --namespace oldboyedu \nNAME         READY   STATUS    RESTARTS   AGE\nxiuxian-v1   1/1     Running   0          3m24s\n[root@master231 pods]# \n[root@master231 pods]# kubectl delete ns oldboyedu \nnamespace \"oldboyedu\" deleted\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods --namespace oldboyedu \nNo resources found in oldboyedu namespace.\n[root@master231 pods]# \n\n\n温馨提示:\n\t删除名称空间，意味着该名称空间下的所有资源都被删除。生成环境中，谨慎操作!\n\t\n\t\n\t3.声明式管理名称空间\n\t\t3.1 获取资源的yaml文件\n[root@master231 ~]# kubectl get ns default -o yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  creationTimestamp: \"2024-07-29T08:38:15Z\"\n  labels:\n    kubernetes.io/metadata.name: default\n  name: default\n  resourceVersion: \"205\"\n  uid: 2a911d87-c943-4ff1-a406-6366cde1fa41\nspec:\n  finalizers:\n  - kubernetes\nstatus:\n  phase: Active\n[root@master231 ~]# \n\n\n\t\t3.2 根据提供的yaml文件做减法，实现资源创建\n[root@master231 v4-svc-volumes-CoreDNS-ns]# cat 05-ns-oldboyedu.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    school: oldboyedu\n    class: linux92\n  name: oldboyedu\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# kubectl apply -f 05-ns-oldboyedu.yaml\nnamespace/oldboyedu created\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# kubectl get ns oldboyedu --show-labels\nNAME        STATUS   AGE   LABELS\noldboyedu   Active   15s   class=linux92,kubernetes.io/metadata.name=oldboyedu,school=oldboyedu\n[root@master231 v4-svc-volumes-CoreDNS-ns]#  \n\n\n\t\t3.3 使用名称空间改写wordpress案例\n[root@master231 v4-svc-volumes-CoreDNS-ns]# ll\ntotal 28\ndrwxr-xr-x 2 root root 4096 Aug  1 12:14 ./\ndrwxr-xr-x 6 root root 4096 Aug  1 11:59 ../\n-rw-r--r-- 1 root root  766 Aug  1 12:03 01-rc-mysql-ns-oldboyedu.yaml\n-rw-r--r-- 1 root root  319 Aug  1 12:06 02-svc-db-ns-oldboyedu.yaml\n-rw-r--r-- 1 root root 1510 Aug  1 12:14 03-rc-wordpress.yaml\n-rw-r--r-- 1 root root  188 Aug  1 12:07 04-svc-wordpress.yaml\n-rw-r--r-- 1 root root  110 Aug  1 12:00 05-ns-oldboyedu.yaml\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# cat 01-rc-mysql-ns-oldboyedu.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-mysql\n  namespace: oldboyedu\nspec:\n  replicas: 1\n  selector:\n    apps: mysql80\n  template:\n    metadata:\n      labels:\n        apps: mysql80\n    spec:   \n      volumes:\n      - name: data\n        nfs:\n          server: master231\n          path: /oldboyedu/data/nfs-server/mysql80\n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-db/mysql:8.3.0-oracle\n        name: db\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: oldboyedu\n        - name: MYSQL_DATABASE\n          value: wordpress\n        - name: MYSQL_USER\n          value: linux92\n        - name: MYSQL_PASSWORD\n          value: \"123\"\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# cat 02-svc-db-ns-oldboyedu.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: db-svc\n  namespace: oldboyedu\nspec:\n  type: ClusterIP\n  # 指定ClusterIP的VIP地址，指定svc的网段即可，我们集群部署采用的svc网段为\"10.200.0.0/16\"\n  # clusterIP: 10.200.0.36\n  selector:\n    apps: mysql80\n  ports:\n  - port: 3306\n    targetPort: 3306\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# cat 03-rc-wordpress.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-wordpress\n  namespace: kube-public\nspec:\n  replicas: 3\n  selector:\n    apps: wp\n  template:\n    metadata:\n      labels:\n        apps: wp\n    spec:\n      volumes:\n      - name: data\n        nfs:\n          server: master231\n          path: /oldboyedu/data/nfs-server/wordpress\n      containers:\n      - image: harbor.oldboyedu.com/oldboyedu-web/wordpress\n        name: wp\n        volumeMounts:\n        - name: data\n          mountPath: /var/www/html\n        env:\n        - name: WORDPRESS_DB_HOST\n          # 指定的是Pod的地址当Pod发生变化时，IP地址需要变动\n          # value: 10.100.1.60\n          # 此处我指定的是ClusterIP的地址，ClusterIP的地址被我固定。\n          # value: 10.200.0.36\n          # 有些场合下，svc的地址无法固定，或者已经分配，则不建议使用ClusterIP进行通信\n          # 可以考虑直接使用svc的名称即可。但前提是资源同一名称空间\n          # value: db-svc\n          # 当数据库和wordpress不在同一个名称空间时，需要写完整的A记录。\n          # value: db-svc.oldboyedu.svc.oldboyedu.com\n          # 其实，也可以简写到名称空间为止即可，也就说，svc及后面的配置可以省略。\n          value: db-svc.oldboyedu\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        - name: WORDPRESS_DB_USER\n          value: linux92\n        - name: WORDPRESS_DB_PASSWORD\n          value: \"123\"\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# cat 04-svc-wordpress.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: wp-svc\n  namespace: kube-public\nspec:\n  type: NodePort\n  selector:\n    apps: wp\n  ports:\n  - port: 80\n    targetPort: 80\n    nodePort: 30090\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# cat 05-ns-oldboyedu.yaml \napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    school: oldboyedu\n    class: linux92\n  name: oldboyedu\n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n[root@master231 v4-svc-volumes-CoreDNS-ns]# \n\n\n\n\n\t- Pod的DNS策略修改\n[root@master231 pods]# cat 14-pods-xiuxian-hostNetwork-dnsPolicy.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-hostnetwork-dnspolicy\n  namespace: default\nspec:\n  # 若不指定，默认策略为“ClusterFirst”，\n  # 如果使用了宿主机网络，建议修改，否则无法解析svc的名称哟~\n  dnsPolicy: \"ClusterFirstWithHostNet\"\n  hostNetwork: true\n  nodeName: worker232\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n[root@master231 pods]# \n[root@master231 pods]# kubectl apply -f 14-pods-xiuxian-hostNetwork-dnsPolicy.yaml \npod/xiuxian-hostnetwork-dnspolicy created\n[root@master231 pods]# \n[root@master231 pods]# kubectl get pods -o wide \nNAME                            READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES\nxiuxian-hostnetwork-dnspolicy   1/1     Running   0          4s    10.0.0.232   worker232   <none>           <none>\n[root@master231 pods]# \n[root@master231 pods]# \n[root@master231 pods]# kubectl get svc -A\nNAMESPACE     NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE\ndefault       db-svc       ClusterIP   10.200.113.122   <none>        3306/TCP                 17m\ndefault       kubernetes   ClusterIP   10.200.0.1       <none>        443/TCP                  2d19h\nkube-system   kube-dns     ClusterIP   10.200.0.10      <none>        53/UDP,53/TCP,9153/TCP   2d19h\n[root@master231 pods]# \n[root@master231 pods]# kubectl exec -it xiuxian-hostnetwork-dnspolicy -- sh\n/ # ping db-svc \nPING db-svc (10.200.113.122): 56 data bytes\n^C\n--- db-svc ping statistics ---\n2 packets transmitted, 0 packets received, 100% packet loss\n/ # \n/ # ping kubernetes\nPING kubernetes (10.200.0.1): 56 data bytes\n^C\n--- kubernetes ping statistics ---\n1 packets transmitted, 0 packets received, 100% packet loss\n/ # \n/ # \n/ # ping kube-dns.kube-system\nPING kube-dns.kube-system (10.200.0.10): 56 data bytes\n^C\n--- kube-dns.kube-system ping statistics ---\n1 packets transmitted, 0 packets received, 100% packet loss\n/ # \n/ # ping kube-dns.kube-system.svc.oldboyedu.com\nPING kube-dns.kube-system.svc.oldboyedu.com (10.200.0.10): 56 data bytes\n^C\n\n \n- Pod的创建|删除|修改流程\n\t1.执行命令时会加载证书文件($HOME/.kube/config)连接Api-server(假设是rc资源创建Pod副本数量为5);\n\t\tPod状态： Pending\n\t2.Api-server对客户端请求进行验证，权限校验及资源清单配置文件解析;\n\t3.若权限校验没问题，就会将请求记录写入到etcd数据库中进行存储;\n\t4.Control Manager组件查询api-server当前集群是否有任务需要维护(发现有一个rc资源有需要创建5个副本数，目前为0，于是会watch事件，监督其副本数量升为5个);\n\t5.scheduler查询api-server是否有Pod需要处于调度状态，api-server返回需要调度的列表，及集群的状态信息供给scheduler调度;\n\t6.scheduler调度完成后将结果返回给api-sever，api-sever将结果存储到etcd中;\n\t7.kubelet将Pod状态及worker节点资源状态周期性上报给api-server;\n\t8.api-server会验证kubelet的证书文件，验证通过后将数据写入到etcd中，与此同时，会将etcd中调度到该节点的Pod任务下发给kubelet;\n\t9.kubelet开始创建Pod，并周期性上报该Pod状态及节点状态给api-server; \n\n\n\t\n- Pod的端口暴露实现服务访问\n\t1.编写资源清单\n[root@master231 pods]# cat 15-pods-xiuxian-ports.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-ports\n  namespace: default\nspec:\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n    # 配置Pod的端口映射\n    ports:\n      # 指定暴露容器端口\n    - containerPort: 80\n      # 指定宿主机的IP地址\n      hostIP: 0.0.0.0\n      # 指定宿主机的端口号\n      hostPort: 8888\n      # 给端口起别名，要求唯一。\n      name: web\n      # 指定容器端口的协议，有效值: UDP, TCP, or SCTP，默认值为\"TCP\"\n      protocol: TCP\n    - containerPort: 53\n      name: dns\n      protocol: UDP \n\n[root@master231 pods]# \n\n\t2.windows访问测试 \n查看调度到哪个节点，然后基于该节点的8888端口访问即可。\n\n\n\n\n- svc的多端口映射\n[root@master231 pods]# cat 16-pods-xiuxian-ports-svc.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: xiuxian-ports-svc\n  labels:\n    apps: xiuxian\nspec:\n  containers:\n  - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n    name: xiuxian\n    ports:\n    - containerPort: 80\n      # 这个名称其实就是你用来标识服务的，比如可以是业务名称\n      name: web\n      protocol: TCP\n    - containerPort: 53\n      name: dns\n      protocol: UDP \n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc\nspec:\n  type: ClusterIP\n  selector:\n    apps: xiuxian\n  ports:\n    # 建议svc的端口名称要和后端的端口名称保持一致。\n  - port: 80\n    # 指定的是Pod的端口名称，当Pod的containerPort修改，并不会响应关联。\n    name: web\n  - port: 53\n    name: dns\n    protocol: UDP\n[root@master231 pods]# \n\n \n \n- rc资源不支持声明式更新\n\t1.准备环境\n[root@master231 rc]# cat 02-rc-xiuxian-update.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rc-xiuxian\nspec:\n  replicas: 3\n  selector:\n    apps: xiuxian\n  template:\n    metadata:\n      labels:\n        apps: xiuxian\n        school: oldboyedu\n        class: linux92\n    spec:   \n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n        name: xiuxian\n        ports:\n        - containerPort: 80\n          name: xiuxian\n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc\nspec:\n  type: ClusterIP\n  selector:\n    apps: xiuxian\n  ports:\n  - port: 80\n    name: xiuxian\n\n[root@master231 rc]# \n[root@master231 rc]# kubectl apply -f 02-rc-xiuxian-update.yaml \nreplicationcontroller/rc-xiuxian created\nservice/xiuxian-svc created\n[root@master231 rc]# \n[root@master231 rc]# \n[root@master231 rc]# kubectl get pods,svc\nNAME                   READY   STATUS    RESTARTS   AGE\npod/rc-xiuxian-ppljk   1/1     Running   0          18s\npod/rc-xiuxian-qbt8j   1/1     Running   0          18s\npod/rc-xiuxian-rjqws   1/1     Running   0          18s\n\nNAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nservice/kubernetes    ClusterIP   10.200.0.1       <none>        443/TCP   2d23h\nservice/xiuxian-svc   ClusterIP   10.200.118.107   <none>        80/TCP    18s\n[root@master231 rc]# \n\n\n\t2.访问测试\n[root@master231 rc]# while true; do curl 10.200.118.107; sleep 0.5;done\n\n\t\n\t\n\t3.修改rc的镜像名称\n[root@master231 rc]# kubectl get rc rc-xiuxian -o yaml | grep \"\\- image:\"\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n[root@master231 rc]# \n[root@master231 rc]# kubectl apply -f 02-rc-xiuxian-update.yaml  # 修改配置\nreplicationcontroller/rc-xiuxian configured\nservice/xiuxian-svc unchanged\n[root@master231 rc]# \n[root@master231 rc]# kubectl get rc rc-xiuxian -o yaml | grep \"\\- image:\"  # rc的镜像模板已经修改成功了\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2\n[root@master231 rc]# \n[root@master231 rc]# \n[root@master231 rc]# kubectl get pods -o wide  # 但是并不会自动删除旧的Pod\nNAME               READY   STATUS    RESTARTS   AGE    IP            NODE        NOMINATED NODE   READINESS GATES\nrc-xiuxian-ppljk   1/1     Running   0          104s   10.100.2.52   worker233   <none>           <none>\nrc-xiuxian-qbt8j   1/1     Running   0          104s   10.100.1.93   worker232   <none>           <none>\nrc-xiuxian-rjqws   1/1     Running   0          104s   10.100.2.51   worker233   <none>           <none>\n[root@master231 rc]# \n[root@master231 rc]# kubectl get pods -o yaml  | grep \"\\- image:\"  # 镜像是没有更新的\n    - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n    - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1\n[root@master231 rc]# \n[root@master231 rc]# kubectl delete pods --all  # 手动删除旧的Pod\npod \"rc-xiuxian-ppljk\" deleted\npod \"rc-xiuxian-qbt8j\" deleted\npod \"rc-xiuxian-rjqws\" deleted\n[root@master231 rc]# \n[root@master231 rc]# kubectl get pods -o wide  # 会自动创建新的Pod，而新的Pod使用的镜像是新的镜像版本\nNAME               READY   STATUS    RESTARTS   AGE   IP            NODE        NOMINATED NODE   READINESS GATES\nrc-xiuxian-2l7wp   1/1     Running   0          4s    10.100.1.94   worker232   <none>           <none>\nrc-xiuxian-jwwqp   1/1     Running   0          4s    10.100.1.95   worker232   <none>           <none>\nrc-xiuxian-x95c9   1/1     Running   0          4s    10.100.2.53   worker233   <none>           <none>\n[root@master231 rc]# \n[root@master231 rc]# kubectl get pods -o yaml  | grep \"\\- image:\"\n    - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2\n    - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2\n    - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2\n[root@master231 rc]# \n\n\n\n温馨提示:\n\t1.rc资源不支持声明式更新，因为需要运维人员手动删除Pod后，才能使用新的模板;\n\t2.上面直接上来就删除所有的Pod方法不可取，尽管此案例中我们是成功了，但是工作中可能会出现新的镜像无法启动，无法拉取镜像，或者启动后有bug。\n\t\n\t\n- K8S实现发布和回滚三种方案对比\n\t1.蓝绿部署\n特点:\n\t同时部署两套（蓝，绿）环境，但仅有一套环境对外提供服务。\n\n缺点:\n\t有一套环境空跑。\n\t\nK8S实现蓝绿发布方案:\n\t- 1.基于控制器创建blue版本的应用;\n\t- 2.svc关联blue版本的Pod;\n\t- 3.基于控制器创建green版本的应用;\n\t- 4.修改svc的标签选择器为green版本\n\t\n\t\n\n\t2.灰度发布|金丝雀发布\n特点：\n\t核心理论就是逐步替换，不会一次性全部替换，会升级部分应用进行测试，因此会存在旧版本和新版本短期共存的现象。\n\t最终新版本会将旧版本全量替换。\n\t\n缺点:\n\t无法细粒度控制更新的范围。\n\t\nK8S实现蓝绿发布方案:\n\t- 1.基于控制器创建旧版本的应用，设置2套标签，初始副本设置为3;\n\t\tapps: v1 \n\t\ttype: xiuxian \n\t\t\n\t- 2.svc关联的Pod业务;\n\t\ttype: xiuxian \n\t\n\t- 3.基于控制器创建新版本的应用，设置2套标签，初始副本设置为1;\n\t\tapps: v2 \n\t\ttype: xiuxian \n\t\t\n\t- 4.将旧版本的副本数由3变0，将新版本的副本数由1变3;\n\t\n\t\n\t3.A/B测试\n特点:\n\t可以让部分用户访问新版本。\n\t\n缺点:\n\t需要单独部署组件实现。比如借助\"istio\"插件实现此功能。\n\t\n\t\n- K8S实现蓝绿部署:\n\t1.部署蓝版本应用\n[root@master231 01-blue-green]# cat 01-blue-xiuxian-v1.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: xiuxian-blue\nspec:\n  replicas: 3\n  selector:\n    apps: xiuxian\n  template:\n    metadata:\n      labels:\n        apps: xiuxian\n    spec:   \n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n        name: xiuxian\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# cat 02-svc-xiuxian.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc\nspec:\n  type: ClusterIP\n  selector:\n    apps: xiuxian\n  ports:\n  - port: 80\n    targetPort: 80\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl apply -f .\nreplicationcontroller/xiuxian-blue created\nservice/xiuxian-svc configured\n\n\n\t2.访问测试 \n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl get svc\nNAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nkubernetes    ClusterIP   10.200.0.1       <none>        443/TCP   3d\nxiuxian-svc   ClusterIP   10.200.138.186   <none>        80/TCP    22m\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# while true ; do curl 10.200.138.186;sleep 0.5;done\n\n\n\n\t3.部署绿版本\n[root@master231 01-blue-green]# cat 03-green-xiuxian-v2.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: xiuxian-green\nspec:\n  replicas: 3\n  selector:\n    apps: green\n  template:\n    metadata:\n      labels:\n        apps: green\n    spec:   \n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2\n        name: xiuxian\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl apply -f 03-green-xiuxian-v2.yaml \nreplicationcontroller/xiuxian-green created\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl get pods -o wide -l apps=green\nNAME                  READY   STATUS    RESTARTS   AGE   IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-green-l8r7f   1/1     Running   0          19s   10.100.1.100   worker232   <none>           <none>\nxiuxian-green-l9qjj   1/1     Running   0          19s   10.100.2.57    worker233   <none>           <none>\nxiuxian-green-pq4xz   1/1     Running   0          19s   10.100.1.99    worker232   <none>           <none>\n[root@master231 01-blue-green]# \n\n\t\n\t4.切换版本\n[root@master231 01-blue-green]# cat 02-svc-xiuxian.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc\nspec:\n  type: ClusterIP\n  selector:\n    # apps: xiuxian\n    apps: green\n  ports:\n  - port: 80\n    targetPort: 80\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl apply -f 02-svc-xiuxian.yaml \nservice/xiuxian-svc configured\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl get svc xiuxian-svc \nNAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nxiuxian-svc   ClusterIP   10.200.138.186   <none>        80/TCP    25m\n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# \n[root@master231 01-blue-green]# kubectl describe svc xiuxian-svc \nName:              xiuxian-svc\nNamespace:         default\nLabels:            <none>\nAnnotations:       <none>\nSelector:          apps=green\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.200.138.186\nIPs:               10.200.138.186\nPort:              <unset>  80/TCP\nTargetPort:        80/TCP\nEndpoints:         10.100.1.100:80,10.100.1.99:80,10.100.2.57:80\nSession Affinity:  None\nEvents:            <none>\n[root@master231 01-blue-green]# \n\n\t5.删除测试环境\n[root@master231 01-blue-green]# kubectl delete -f .\nreplicationcontroller \"xiuxian-blue\" deleted\nservice \"xiuxian-svc\" deleted\nreplicationcontroller \"xiuxian-green\" deleted\n[root@master231 01-blue-green]# \n\n\n- K8S实现金丝雀发布 \n\t1.部署旧版本 \n[root@master231 02-huidu]# cat 01-old-xiuxian-v1.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: xiuxian-old\nspec:\n  replicas: 3\n  selector:\n    apps: v1\n  template:\n    metadata:\n      labels:\n        apps: v1\n        school: oldboyedu\n    spec:   \n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v1 \n        name: xiuxian\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# \n[root@master231 02-huidu]# cat 02-svc-xiuxian.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: xiuxian-svc\nspec:\n  type: ClusterIP\n  selector:\n    school: oldboyedu\n  ports:\n  - port: 80\n    targetPort: 80\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl apply -f .\nreplicationcontroller/xiuxian-old created\nservice/xiuxian-svc created\n[root@master231 02-huidu]# \n\n\n\t2.测试应用\n[root@master231 02-huidu]# kubectl get pods -l apps=v1 -o wide\nNAME                READY   STATUS    RESTARTS   AGE   IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-old-94n98   1/1     Running   0          12s   10.100.2.58    worker233   <none>           <none>\nxiuxian-old-b4wgt   1/1     Running   0          12s   10.100.1.101   worker232   <none>           <none>\nxiuxian-old-bknrd   1/1     Running   0          12s   10.100.1.102   worker232   <none>           <none>\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get svc \nNAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\nkubernetes    ClusterIP   10.200.0.1      <none>        443/TCP   3d\nxiuxian-svc   ClusterIP   10.200.135.27   <none>        80/TCP    17s\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# while true;do curl 10.200.135.27; sleep 0.5;done\n\n\t\n\t3.部署新版本 \n[root@master231 02-huidu]# cat 03-new-xiuxian-v2.yaml \napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: xiuxian-new\nspec:\n  replicas: 1\n  selector:\n    apps: v2\n  template:\n    metadata:\n      labels:\n        apps: v2\n        school: oldboyedu\n    spec:   \n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/yinzhengjie-k8s/apps:v2\n        name: xiuxian\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl apply -f 03-new-xiuxian-v2.yaml \nreplicationcontroller/xiuxian-new created\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get pods -o wide -l apps=v2\nNAME                READY   STATUS    RESTARTS   AGE   IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-new-l2t2k   1/1     Running   0          22s   10.100.1.103   worker232   <none>           <none>\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get pods -o wide -l apps=v1\nNAME                READY   STATUS    RESTARTS   AGE     IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-old-94n98   1/1     Running   0          3m51s   10.100.2.58    worker233   <none>           <none>\nxiuxian-old-b4wgt   1/1     Running   0          3m51s   10.100.1.101   worker232   <none>           <none>\nxiuxian-old-bknrd   1/1     Running   0          3m51s   10.100.1.102   worker232   <none>           <none>\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get pods -o wide -l school\nNAME                READY   STATUS    RESTARTS   AGE     IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-new-l2t2k   1/1     Running   0          50s     10.100.1.103   worker232   <none>           <none>\nxiuxian-old-94n98   1/1     Running   0          4m16s   10.100.2.58    worker233   <none>           <none>\nxiuxian-old-b4wgt   1/1     Running   0          4m16s   10.100.1.101   worker232   <none>           <none>\nxiuxian-old-bknrd   1/1     Running   0          4m16s   10.100.1.102   worker232   <none>           <none>\n[root@master231 02-huidu]# \n\n\t4.观察Pod访问的情况\n此时会出现新版本和旧版本共存的现象。\n\n\n\t5.使用新版本逐渐替换旧版本\n将旧版本的副本数逐渐减少，由3到0，将新版本的数量逐渐增加由1到3。\n\t\n[root@master231 02-huidu]# kubectl edit rc xiuxian-old   # 将旧的版本副本数量修改为2\nreplicationcontroller/xiuxian-old edited\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl edit rc xiuxian-new   # 将新的版本副本数量修改为2\nreplicationcontroller/xiuxian-new edited\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get pods -o wide -l school\nNAME                READY   STATUS    RESTARTS   AGE     IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-new-82q8v   1/1     Running   0          4s      10.100.2.59    worker233   <none>           <none>\nxiuxian-new-l2t2k   1/1     Running   0          3m6s    10.100.1.103   worker232   <none>           <none>\nxiuxian-old-b4wgt   1/1     Running   0          6m32s   10.100.1.101   worker232   <none>           <none>\nxiuxian-old-bknrd   1/1     Running   0          6m32s   10.100.1.102   worker232   <none>           <none>\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl edit rc xiuxian-old  # 将旧的版本副本数量修改为1\nreplicationcontroller/xiuxian-old edited\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl edit rc xiuxian-new  # 将新的版本副本数量修改为3\nreplicationcontroller/xiuxian-new edited\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get pods -o wide -l school\nNAME                READY   STATUS    RESTARTS   AGE     IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-new-57srq   1/1     Running   0          12s     10.100.2.60    worker233   <none>           <none>\nxiuxian-new-82q8v   1/1     Running   0          41s     10.100.2.59    worker233   <none>           <none>\nxiuxian-new-l2t2k   1/1     Running   0          3m43s   10.100.1.103   worker232   <none>           <none>\nxiuxian-old-b4wgt   1/1     Running   0          7m9s    10.100.1.101   worker232   <none>           <none>\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl edit rc xiuxian-old  # 将旧的版本副本数量修改为0\nreplicationcontroller/xiuxian-old edited\n[root@master231 02-huidu]# \n[root@master231 02-huidu]# kubectl get pods -o wide -l school\nNAME                READY   STATUS    RESTARTS   AGE    IP             NODE        NOMINATED NODE   READINESS GATES\nxiuxian-new-57srq   1/1     Running   0          37s    10.100.2.60    worker233   <none>           <none>\nxiuxian-new-82q8v   1/1     Running   0          66s    10.100.2.59    worker233   <none>           <none>\nxiuxian-new-l2t2k   1/1     Running   0          4m8s   10.100.1.103   worker232   <none>           <none>\n[root@master231 02-huidu]# \n\n\n\t6.观察数据结果\n不难发现，此时集群出现的都是v2的版本哟~\n\n\n\n\n\n\n今日内容回顾:\n\t- K8S部署wordpress的流程\t*****\n\t\n\t- coreDNS组件 \n\t\t- 能够解析svc的名称为CLusterIP;\n\t\t- 两种方式验证coreDNS组件是否正常工作;\t\t*****\n\t\t\n\t- 名称空间 *****\n\t\t- 对资源进行隔离\n\t\t- 如果支持名称空间，则称为局部资源，若不支持名称空间，称为全局资源。\n\t\t常见的全局资源： ns,no,cs,...pv,\n\t\t\n\t\t常见的局部资源: po,rc,svc,...cm,secrets,sts,ds,cj,jobs,pvc,...\n\t\t\n\t\t如何判断资源是否支持名称空间: \"kubectl api-resources\"\n\t\t\n\t- Pod的nds解析策略，尤其是使用了宿主机网络\t\t*****\n\t\n\t- Pod的端口映射\t*\n\t\n\t- svc实现多端口映射\t*\n\t\n\t- 获取资源的清单\t*\n\t\t-o yaml \n\t\t\n\t- Pod创建流程\t\t*****\n\t\n\t- pv，svc，和rc的作用图解\t*****\n\t\n\t- 发布策略\t\t*****\n\t\t- 蓝绿部署 \n\t\t- 灰度发布 \n\t\t- A/B测试 \n\t\t\n\t\t\n今日作业:\n\t- 完成课堂的所有练习并整理思维导图;\n\t\n扩展作业:\n\t- 使用rc和svc实现MySQL的主从复制集群。数据不丢失！\n\n\n\t- rs控制器\n\t- deploy控制器\n\t\n\t\n\t- Jenkins和K8S集成项目实战\n\t\t明天准备一台2c4G的Ubuntu虚拟机，要求啥服务都不要部署，\"干净\"。\n\t\t10.0.0.211 jenkins211\n\t\t\n\t","x":-100,"y":860,"width":940,"height":680},
		{"id":"a3ccc3708d1dd8c4","type":"text","text":"数据存储卷；\nPod故障排查技巧；\nrc和svc快速入门","x":-1180,"y":1120,"width":460,"height":50,"color":"1"},
		{"id":"0c14580aa7eaedce","type":"text","text":"Pod基本管理及常用命令","x":-1180,"y":1020,"width":280,"height":50,"color":"1"},
		{"id":"391c1f539d7af66d","type":"text","text":"wordpress上线K8S，名称空间，coreDNS组件，Pod创建流程，发布策略实战","x":-1180,"y":1220,"width":660,"height":60,"color":"1"},
		{"id":"255583447f717f36","type":"file","file":"Linux_运维/图片/rc，svc，Pod之间的关系.jpg","x":1294,"y":1400,"width":733,"height":1140},
		{"id":"cda6506cfa47d73b","type":"file","file":"Linux_运维/图片/Pod的创建流程图解.jpg","x":1294,"y":-470,"width":733,"height":1794},
		{"id":"541a87ae89b91daf","type":"text","text":"网址","x":-1180,"y":900,"width":250,"height":60,"color":"1"},
		{"id":"8e673a245d09f56d","type":"text","text":"#### 工作顾问\n\n##### 阿里云盘资料\n>面试录音  面试题等\nhttps://www.alipan.com/s/S3gfaFqzsq2\n##### 简历投递\n>boss投递技巧，投递逻辑、策略\nhttps://www.alipan.com/s/iDzY8jymWzm\n##### 实时技术文档 （持续更新中）\nhttps://www.yuque.com/youngfit\n##### 基础部分涵盖面试题\n>记不住就死拉拉滴-\nhttps://www.yuque.com/dayang-gfkb7/lgdl3w/fpy6rknfoo2674py?singleDoc# \n##### 综合问题\n>面试hr、入职后场景等问题、涵盖基础部分，网站已适配pc\\pad\\phone。\nwww.dayangs.cn:880 \n\n##### 李老师的语雀笔记\nhttps://www.yuque.com/lidao996/sre\n\n##### 尹老师的博客园\nhttps://www.cnblogs.com/yinzhengjie/tag","x":-100,"y":-1080,"width":940,"height":540}
	],
	"edges":[
		{"id":"8f62663991b7aca0","fromNode":"0c14580aa7eaedce","fromSide":"right","toNode":"ef97f55b5a2b95a1","toSide":"left"},
		{"id":"49060f6412f09e1e","fromNode":"a3ccc3708d1dd8c4","fromSide":"right","toNode":"454425a435250052","toSide":"left"},
		{"id":"f4c339410e7fe883","fromNode":"391c1f539d7af66d","fromSide":"right","toNode":"bc85b2ffc4279153","toSide":"left"},
		{"id":"7f55a732357995db","fromNode":"bc85b2ffc4279153","fromSide":"right","toNode":"255583447f717f36","toSide":"left"},
		{"id":"5c8c6580c5dcead7","fromNode":"bc85b2ffc4279153","fromSide":"right","toNode":"cda6506cfa47d73b","toSide":"left"}
	]
}
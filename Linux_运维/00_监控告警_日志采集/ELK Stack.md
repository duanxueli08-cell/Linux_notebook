



## ELK Stack

### ç†è®ºæ¦‚å¿µï¼š

##### **ELK Stack ç”±å››ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼š**

1. **Elasticsearch (E):** å­˜å‚¨ã€æœç´¢å’Œåˆ†ææ•°æ®çš„æ ¸å¿ƒå¼•æ“ã€‚
2. **Logstash (L):** æ•°æ®æ”¶é›†ã€è¿‡æ»¤å’Œè½¬å‘ï¼›
3. **Kibana (K):** æ•°æ®å¯è§†åŒ–å’Œç”¨æˆ·ç•Œé¢ã€‚
4. **Beats (B):** è½»é‡çº§å•ç”¨é€”æ•°æ®é‡‡é›†å™¨ï¼ˆå¦‚ Filebeat, Metricbeatï¼‰ã€‚

##### åŸºç¡€æ¦‚å¿µï¼š

- æ•°æ®ä»¥ **æ–‡æ¡£** çš„å½¢å¼å­˜å‚¨ã€‚
- å¤šä¸ªç›¸ä¼¼çš„æ–‡æ¡£æ„æˆä¸€ä¸ª **ç´¢å¼•**ã€‚
- **ç´¢å¼•** è¢«åˆ†æˆå¤šä¸ª **ä¸»åˆ†ç‰‡**ï¼Œä»¥å®ç°åˆ†å¸ƒå¼å­˜å‚¨å’Œå¤„ç†ã€‚
- æ¯ä¸ª **ä¸»åˆ†ç‰‡** éƒ½æœ‰ä¸€ä¸ªæˆ–å¤šä¸ª **å‰¯æœ¬**ï¼Œä»¥å®ç°é«˜å¯ç”¨å’Œé«˜æŸ¥è¯¢æ€§èƒ½ã€‚

| **æ¦‚å¿µ**                                  | **å«ä¹‰**                                                     | **ä½œç”¨**                                                     |
| ----------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **ç´¢å¼• (Index)**                          | ç±»ä¼¼å…³ç³»æ•°æ®åº“ä¸­çš„â€œæ•°æ®åº“â€ã€‚å®ƒæ˜¯å…·æœ‰ç›¸ä¼¼ç‰¹å¾çš„æ–‡æ¡£é›†åˆã€‚     | æ•°æ®çš„é€»è¾‘åˆ†ç»„ï¼Œæ˜¯æ‰§è¡Œæœç´¢ã€æ›´æ–°å’Œåˆ é™¤æ“ä½œçš„å…¥å£ç‚¹ã€‚         |
| **æ–‡æ¡£ (Document)**                       | ç±»ä¼¼å…³ç³»æ•°æ®åº“ä¸­çš„â€œè¡Œâ€ã€‚å®ƒæ˜¯å¯ä»¥è¢«ç´¢å¼•çš„åŸºæœ¬ä¿¡æ¯å•å…ƒï¼Œä»¥ JSON æ ¼å¼å­˜å‚¨ã€‚ | å®é™…å­˜å‚¨çš„æ•°æ®è½½ä½“ï¼Œæ˜¯ Elasticsearch ä¸­æœ€å°çš„å­˜å‚¨å’Œæœç´¢å•å…ƒã€‚ |
| **åˆ†ç‰‡ (Shard) / ä¸»åˆ†ç‰‡ (Primary Shard)** | ç´¢å¼•è¢«**æ°´å¹³åˆ‡åˆ†**æˆè‹¥å¹²ä¸ªåˆ†ç‰‡ã€‚æ¯ä¸ªåˆ†ç‰‡éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€åŠŸèƒ½å®Œæ•´çš„æœç´¢å¼•æ“å®ä¾‹ã€‚ | **å®ç°æ•°æ®çš„åˆ†å¸ƒå¼å­˜å‚¨å’Œå¤„ç†**ã€‚å®ƒå…è®¸ç´¢å¼•å®¹é‡çªç ´å•ä¸ªèŠ‚ç‚¹çš„é™åˆ¶ï¼Œå¹¶æ”¯æŒå¹¶è¡Œæ“ä½œä»¥**æé«˜æ€§èƒ½**ã€‚ä¸»åˆ†ç‰‡çš„æ•°é‡åœ¨ç´¢å¼•åˆ›å»ºæ—¶ç¡®å®šä¸”ä¸å¯æ›´æ”¹ã€‚ |
| **å‰¯æœ¬ (Replica Shard)**                  | ä¸»åˆ†ç‰‡çš„**ç²¾ç¡®æ‹·è´**ï¼Œå¯ä»¥æœ‰é›¶ä¸ªæˆ–å¤šä¸ªå‰¯æœ¬ã€‚                 | 1. **é«˜å¯ç”¨æ€§/æ•…éšœè½¬ç§»**ï¼šå½“ä¸»åˆ†ç‰‡èŠ‚ç‚¹å¤±æ•ˆæ—¶ï¼Œå‰¯æœ¬åˆ†ç‰‡ä¼šè¢«æå‡ä¸ºæ–°çš„ä¸»åˆ†ç‰‡ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢å¤±ã€‚ 2. **è´Ÿè½½å‡è¡¡/æé«˜æ€§èƒ½**ï¼šæœç´¢è¯·æ±‚å¯ä»¥ç”±ä¸»åˆ†ç‰‡æˆ–å‰¯æœ¬åˆ†ç‰‡å¤„ç†ï¼ŒElasticsearch ä¼šè‡ªåŠ¨å¯¹æœç´¢è¯·æ±‚è¿›è¡Œ**è´Ÿè½½å‡è¡¡**ï¼Œæå‡æŸ¥è¯¢å¹¶å‘èƒ½åŠ›ã€‚å‰¯æœ¬åˆ†ç‰‡çš„æ•°é‡å¯ä»¥åŠ¨æ€è°ƒæ•´ã€‚ |

##### ELK å·¥ä½œæµç¨‹

> - **Filebeat:** è½»é‡çº§é‡‡é›†å™¨ï¼Œå¯¹æœåŠ¡å™¨èµ„æºå ç”¨å°ã€‚
> - **Kafka:** å¼•å…¥æ¶ˆæ¯é˜Ÿåˆ—ä½œä¸º**ç¼“å†²åŒº (Buffer)**ï¼Œå®ç°äº†**å‰Šå³°å¡«è°·**ï¼Œé˜²æ­¢ Logstash/ES å¤„ç†ä¸è¿‡æ¥æ—¶æ—¥å¿—ä¸¢å¤±ï¼Œè¿™æ˜¯ç”Ÿäº§ç¯å¢ƒçš„**æœ€ä½³å®è·µ**ã€‚
> - **Logstash:** è´Ÿè´£å¤æ‚çš„æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–ã€‚
> - **Elasticsearch:** è´Ÿè´£é«˜é€Ÿå­˜å‚¨å’Œåˆ†æã€‚
> - **Kibana:** æä¾›äº†æœ€ç»ˆçš„ç”¨æˆ·ç•Œé¢å’Œå¯è§†åŒ–èƒ½åŠ›ã€‚

```powershell
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   åº”ç”¨æœåŠ¡å™¨     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ æ—¥å¿—æ–‡ä»¶ â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Filebeat
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kafka       â”‚â—„â”€â”€ç¼“å†²/è§£è€¦
â”‚   (æ¶ˆæ¯é˜Ÿåˆ—)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Logstash     â”‚â—„â”€â”€è¿‡æ»¤/è§£æ/è½¬æ¢
â”‚   (æ•°æ®å¤„ç†)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Elasticsearch   â”‚â—„â”€â”€å­˜å‚¨/ç´¢å¼•/æœç´¢
â”‚   (æ•°æ®å­˜å‚¨)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kibana      â”‚â—„â”€â”€ä»ªè¡¨ç›˜/æŸ¥è¯¢/åˆ†æ
â”‚   (å¯è§†åŒ–)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```



##### å¸¸è§çš„é›†ç¾¤æ¨¡å¼

- å°†æ ¸å¿ƒèŒè´£åˆ†ç¦»ï¼Œä»¥ä¿éšœé›†ç¾¤çš„ç¨³å®šæ€§å’Œé«˜å¯ç”¨æ€§ã€‚è¿™æ˜¯ç”Ÿäº§ç¯å¢ƒæ¨èçš„æœ€å°åŒ–é«˜å¯ç”¨é…ç½®ã€‚
- åœ¨ Elasticsearch ä¸­ï¼Œé€šè¿‡é…ç½® `node.roles` æ•°ç»„ï¼Œæ‚¨å¯ä»¥çµæ´»åœ°ä¸ºé›†ç¾¤ä¸­çš„æ¯ä¸ªæœåŠ¡å™¨å®šä¹‰å…¶èŒè´£ã€‚
- **åè°ƒèŠ‚ç‚¹**æ˜¯ä¸€ä¸ª**éšå¼**çš„è§’è‰²ã€‚**ä»»ä½•ä¸€ä¸ªæ¥æ”¶åˆ°å®¢æˆ·ç«¯è¯·æ±‚çš„èŠ‚ç‚¹ï¼Œå³ä½¿å®ƒæ²¡æœ‰è¢«æ˜ç¡®é…ç½®ä¸º `coordinating` è§’è‰²ï¼Œä¹Ÿä¼šæ‰®æ¼”åè°ƒèŠ‚ç‚¹çš„èŒè´£**ã€‚
- è®¾ç½® node.master:true æŒ‡å®šæ˜¯å¦å‚ä¸ Master èŠ‚ç‚¹é€‰ä¸¾ï¼Œé»˜è®¤æ˜¯true ï¼›å¦‚æœæ”¹ä¸º flase åˆ™ä¸å‚ä¸åç»­çš„ Master é€‰ä¸¾ï¼›
- è®¾ç½® node.data:true æŒ‡å®šä¸º data èŠ‚ç‚¹ï¼Œé»˜è®¤æ˜¯ true ï¼Œå³é»˜è®¤æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯ data èŠ‚ç‚¹ç±»å‹ï¼›
- è®¾ç½® node.coordinating:true æŒ‡å®šä¸º coordinating èŠ‚ç‚¹ï¼Œå‰ææ˜¯ï¼šnode.master:flase node.data:flase node.ingest:flase 

| **èŠ‚ç‚¹**       | **è§’è‰²åˆ†é…**   | **æ•°é‡**              | **ä½œç”¨**                                               |
| -------------- | -------------- | --------------------- | ------------------------------------------------------ |
| **ä¸“æœ‰ä¸»èŠ‚ç‚¹** | `master`       | $3$ ä¸ªï¼ˆæ¨èå¥‡æ•°ï¼‰    | è´Ÿè´£æ•´ä¸ªé›†ç¾¤çš„å¢åˆ æ”¹ï¼›æ¯”å¦‚ç´¢å¼•ï¼ŒèŠ‚ç‚¹å’Œåˆ†ç‰‡çš„é‡æ–°åˆ†é…ï¼› |
| **æ•°æ®èŠ‚ç‚¹**   | `data, ingest` | $N$ ä¸ªï¼ˆè‡³å°‘ $2$ ä¸ªï¼‰ | ä¸“èŒè´Ÿè´£æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢ã€‚                               |
| **åè°ƒèŠ‚ç‚¹**   | `coordinating` | $M$ ä¸ªï¼ˆå¯é€‰ï¼‰        | ä¸“èŒè´Ÿè´£å®¢æˆ·ç«¯è¯·æ±‚çš„è·¯ç”±å’Œèšåˆã€‚                       |



##### ç´¢å¼•

> **æ³¨æ„ï¼šESçš„å‰¯æœ¬æŒ‡ä¸åŒ…æ‹¬ä¸»åˆ†ç‰‡çš„å…¶å®ƒå‰¯æœ¬,å³åªåŒ…æ‹¬å¤‡ä»½ï¼Œè¿™ä¸Kafkaæ˜¯ä¸åŒçš„**
>
> åˆ›å»ºç´¢å¼•ï¼Œå®‰è£…æ’ä»¶ï¼Œé€šè¿‡æ’ä»¶ Head æŸ¥çœ‹ç´¢å¼•ï¼Œä»¥åŠåˆ†ç‰‡å’Œå‰¯æœ¬
>
> åˆ›å»ºçš„åˆ†ç‰‡æœ€ä½³æ•°é‡æ˜¯ä¸èŠ‚ç‚¹æ•°é‡ç›¸ç­‰ï¼›

```powershell
# åˆ›å»ºç´¢å¼•index1,ç®€å•è¾“å‡º
curl -XPUT 'http://10.0.0.201:9200/index1'
# Elasticsearch é»˜è®¤æ•°æ®å­˜å‚¨è·¯å¾„
ls /var/lib/elasticsearch
# æŸ¥çœ‹ Elasticsearch å…¨éƒ¨ç´¢å¼•åˆ—è¡¨
curl 'http://10.0.0.201:9200/_cat/indices?v'
# åˆ›å»º3ä¸ªåˆ†ç‰‡å’Œ2ä¸ªå‰¯æœ¬çš„ç´¢å¼•
curl -X PUT "10.0.0.202:9200/index2" -H "Content-Type: application/json" -d '{
    "settings": {
      "index": {
        "number_of_shards": 3,
        "number_of_replicas": 1
      }
    }
  }'
```

> ç´¢å¼•è™½ç„¶ä»é€»è¾‘ä¸Šç”¨äºæ•°æ®åˆ†ç»„ï¼Œä½†æ˜¯åˆ é™¤ç´¢å¼•ä¼šç«‹å³åˆ é™¤åº•å±‚æ‰€æœ‰çœŸå®æ•°æ®æ–‡ä»¶ï¼›
>
> ES çš„çœŸå®æ•°æ®ç»“æ„æ˜¯è¿™æ ·çš„ï¼š
>
> ```powershell
> ç´¢å¼• index
> â”œâ”€â”€ ä¸»åˆ†ç‰‡ shard 0
> â”‚    â”œâ”€â”€ segment_1
> â”‚    â”œâ”€â”€ segment_2
> â”‚    â””â”€â”€ ...
> â”œâ”€â”€ ä¸»åˆ†ç‰‡ shard 1
> â””â”€â”€ å‰¯æœ¬åˆ†ç‰‡ shard 0
> ```



##### ES æ–‡æ¡£

é»˜è®¤æƒ…å†µä¸‹ï¼ŒES ä½¿ç”¨ **æ–‡æ¡£ ID** ä½œä¸ºè·¯ç”±é”®ï¼š

- **åŒä¸€ä¸ªæ–‡æ¡£ ID â†’ æ°¸è¿œè½åœ¨åŒä¸€ä¸ªä¸»åˆ†ç‰‡**
- å‰¯æœ¬åˆ†ç‰‡åªæ˜¯ä¸»åˆ†ç‰‡çš„å¤åˆ¶

```powershell
shard = hash(_id) % number_of_primary_shards
```

æ–‡æ¡£å†™å…¥æµç¨‹ï¼š

```powershell
å®¢æˆ·ç«¯å†™å…¥æ–‡æ¡£
     â†“
åè°ƒèŠ‚ç‚¹ï¼ˆcoordinating nodeï¼‰
     â†“
æ ¹æ® æ–‡æ¡£id è®¡ç®— hash
     â†“
å®šä½ä¸»åˆ†ç‰‡ï¼ˆæ¯”å¦‚ shard 1ï¼‰
     â†“
å†™å…¥ shard 1 ä¸»åˆ†ç‰‡
     â†“
åŒæ­¥åˆ° shard 1 çš„å‰¯æœ¬åˆ†ç‰‡
```

Elasticsearch åˆ›å»ºæ–‡æ¡£

- æ–‡æ¡£ ID æ˜¯å“ˆå¸Œç®—æ³•å¾—å‡ºçš„ç»“æœï¼›

```powershell
# è‡ªåŠ¨ç”Ÿæˆ ES æ–‡æ¡£ ID
curl -X POST "http://10.0.0.201:9200/user/_doc" \
-H "Content-Type: application/json" \
-d '{
  "name": "å¼ ä¸‰",
  "age": 25,
  "city": "Beijing"
}'
```

Elasticsearch æŸ¥è¯¢æ–‡æ¡£

```powershell
curl -X GET "http://10.0.0.201:9200/user/_doc/test"
```

åŸºäº DSL è¯­å¥æŸ¥è¯¢

- `_search`ï¼šæœç´¢æ¥å£
- `match`ï¼šå…¨æ–‡æ£€ç´¢
- `"name": "éŸ©"`ï¼šå¦‚æœ `name` æ˜¯ `text + ä¸­æ–‡åˆ†è¯`ï¼Œä¼šåŒ¹é…åŒ…å«â€œéŸ©â€çš„æ–‡æ¡£

```powershell
POST 10.0.0.93:9200/oldboyedu-linux92/_search
{
  "query": {
    "match": {
      "name": "éŸ©"
    }
  }
}
```

ES ä¿®æ”¹æ–‡æ¡£

```powershell
POST oldboyedu-linux92/_update/202407101700001
{
  "doc": {
    "school": "ä¿®æ”¹å†…å®¹"
  }
}
```

ES åˆ é™¤æ–‡æ¡£

```powershell
DELETE oldboyedu-linux92/_doc/202407101700001
```



##### ES é›†ç¾¤å¸¸è§æœ¯è¯­

- ES clusterï¼šæŒ‡çš„æ˜¯ ES é›†ç¾¤çš„å„ä¸ªèŠ‚ç‚¹ï¼›
- indexï¼šç´¢å¼•ã€‚ç”¨äºæ•°æ®è¯»å–çš„é€»è¾‘å•å…ƒï¼›ä¸€ä¸ªç´¢å¼•æœ€å°‘è¦æœ‰ä¸€ä¸ªåˆ†ç‰‡ï¼›
- shardï¼šåˆ†ç‰‡ï¼Œç”¨äºå®é™…å­˜å‚¨æ•°æ®ä¿¡æ¯çš„ï¼›
- replicaï¼šå¯¹åˆ†ç‰‡è¿›è¡Œå¤‡ä»½çš„ shardï¼›
  - primary shardï¼šè´Ÿè´£æ•°æ®çš„è¯»å†™ï¼›ï¼ˆä¸»åˆ†ç‰‡ï¼‰
  - replica shardï¼šä» primary shard åŒæ­¥æ•°æ®ä¸”è´Ÿè´£è¯»çš„è´Ÿè½½å‡è¡¡ï¼›ï¼ˆä»åˆ†ç‰‡ï¼‰
- documentï¼šå®é™…æ•°æ®ï¼›æ°›å›´å…ƒæ•°æ®å’Œæºæ•°æ®ï¼›
  - å…ƒæ•°æ®ï¼šæè¿°æ•°æ®çš„æ•°æ®ï¼Œæ¯”å¦‚ï¼š _index,_id,_type,_source,...
  - æºæ•°æ®ï¼šç”¨æˆ·å®é™…çš„å­˜å‚¨æ•°æ®ï¼Œæ•°æ®å­˜å‚¨åœ¨ â€â€”â€”sourceâ€œ å­—æ®µä¸­ï¼›
- allocationï¼šå°†ç´¢å¼•çš„ä¸åŒåˆ†ç‰‡åˆ†é…åˆ°æ•´ä¸ªé›†ç¾¤çš„è¿‡ç¨‹ï¼›ï¼ˆåˆ†é…ï¼‰

##### ES é›†ç¾¤çŠ¶å†µ

- green ç»¿è‰²çŠ¶æ€ï¼šè¡¨ç¤ºé›†ç¾¤å„èŠ‚ç‚¹è¿è¡Œæ­£å¸¸ï¼Œè€Œä¸”æ²¡æœ‰ä¸¢å¤±ä»»ä½•æ•°æ®ï¼›
- yellow é»„è‰²çŠ¶æ€ï¼šéƒ¨åˆ†å‰¯æœ¬åˆ†ç‰‡å¼‚å¸¸ï¼›
- red çº¢è‰²çŠ¶æ€ï¼šéƒ¨åˆ†ä¸»åˆ†ç‰‡å¼‚å¸¸ï¼›





##### Filebeat æ”¶é›†æ—¥å¿—

- Logstash ä¹Ÿå¯ä»¥ç›´æ¥æ”¶é›†æ—¥å¿—,ä½†éœ€è¦å®‰è£…JDKå¹¶ä¸”ä¼šå ç”¨è‡³å°‘ 500M ä»¥ä¸Šçš„å†…å­˜ï¼›
- ç”Ÿäº§ä¸€èˆ¬ä½¿ç”¨filebeatä»£æ›¿logstash, åŸºäºgoå¼€å‘,éƒ¨ç½²æ–¹ä¾¿,é‡è¦çš„æ˜¯åªéœ€è¦10Må¤šå†…å­˜,æ¯”è¾ƒèŠ‚çº¦èµ„æºï¼›



###### Filebeat å®‰è£…

> - ä¸‹è½½åœ°å€ï¼š[Download Filebeat | Elastic](https://www.elastic.co/cn/downloads/beats/filebeat)
> - å®˜æ–¹æ–‡æ¡£ï¼šhttps://www.elastic.co/docs/reference/beats/filebeat

```powershell
dpkg -i filebeat-9.2.2-amd64.deb
systemctl start filebeatps aux|grep filebeat
```

- filebeat æœåŠ¡ä»¥ root èº«ä»½å¯åŠ¨



###### Filebeat é…ç½®

- é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„ï¼š/etc/filebeat/filebeat.yml

```powershell
systemctl cat filebeat.service
file /usr/share/filebeat/bin/filebeat
ldd /usr/share/filebeat/bin/filebeat
/usr/share/filebeat/bin/filebeat --help
```

```powershell
vim /etc/filebeat/stdin.yml
filebeat.inputs:
- type: stdin
  enabled: true
  json.keys_under_root: true # è§£æjson
  tags: ["stdin-tags","myapp"] #æ·»åŠ æ–°å­—æ®µåtagsï¼Œå¯ä»¥ç”¨äºåˆ¤æ–­ä¸åŒç±»å‹çš„è¾“å…¥ï¼Œå®ç°ä¸åŒçš„è¾“å‡º
  fields:
    status_code: "200" #æ·»åŠ æ–°å­—æ®µåfields.status_codeï¼Œå¯ä»¥ç”¨äºåˆ¤æ–­ä¸åŒç±»å‹çš„è¾“å…¥ï¼Œå®ç°ä¸åŒçš„è¾“å‡º
    author: "wangxiaochun"
output.console:
  pretty: true
  enable: true

# æ£€æŸ¥é…ç½®è¯­æ³•å’Œç»“æ„
filebeat test config -c /etc/filebeat/stdin.yml
# æ£€æŸ¥è¾“å‡ºç«¯æ˜¯å¦èƒ½è¿é€šï¼ˆES / Logstashï¼‰
filebeat test output -c /etc/filebeat/stdin.yml
```

```powershell
# ç”¨æŒ‡å®šé…ç½®æ–‡ä»¶å¯åŠ¨ Filebeat æœåŠ¡ï¼ŒçœŸå®æ‰§è¡Œæ—¥å¿—é‡‡é›†ã€å¤„ç†å¹¶å‘é€åˆ°é…ç½®çš„è¾“å‡ºç«¯ã€‚
filebeat -c /etc/filebeat/stdin.yml
# è¾“å…¥ä¸€æ®µå­—ç¬¦ä¸²æµ‹è¯•ï¼Œç„¶åç¨ç­‰ç‰‡åˆ»ï¼Œä¼šåœ¨ä»¥ JSON æ ¼å¼çš„æ—¥å¿—è¾“å‡ºåˆ°ç»ˆç«¯
hello duan
# è¾“å…¥jsonæ ¼å¼ï¼Œè¿›è¡Œè§£æ
{"name" : "wangxiaochun", "age" : "18", "phone" : "0123456789"}
```

```powershell
vim /etc/filebeat/file.yaml
filebeat.inputs:
- type: filestream
  id: my-filestream
  enabled: true
  paths:
    - /var/log/test.log
  parsers:
    - ndjson:
        target: ""
output.console:
  pretty: true
  enable: true
```



##### Logstash 

###### å®‰è£…

```powershell
dpkg -i logstash-7.6.2-amd64.deb
# æœåŠ¡æ–¹å¼å¯åŠ¨,ç”±äºé»˜è®¤æ²¡æœ‰é…ç½®æ–‡ä»¶,æ‰€ä»¥7.Xæ— æ³•å¯åŠ¨ï¼Œ8.Xå¯ä»¥å¯åŠ¨
systemctl start logstash.service ; systemctl status logstash.service
# ç”Ÿæˆä¸“æœ‰ç”¨æˆ·logstash,ä»¥æ­¤ç”¨æˆ·å¯åŠ¨æœåŠ¡,åç»­ä½¿ç”¨æ—¶å¯èƒ½ä¼šå­˜åœ¨æƒé™é—®é¢˜
id logstash
```



```powershell
vim /etc/filebeat/stdin.yml
filebeat.inputs:
- type: log
  enabled: true # å¼€å¯æ—¥å¿—
  paths:
  - /var/log/nginx/access_json.log # æŒ‡å®šæ”¶é›†çš„æ—¥å¿—æ–‡ä»¶
  json.keys_under_root: true
  tags: ["nginx-access"]
- type: log
  enabled: true # å¼€å¯æ—¥å¿—
  paths:
  - /var/log/syslog # æŒ‡å®šæ”¶é›†çš„æ—¥å¿—æ–‡ä»¶
  fields:
    logtype: "syslog" # æ·»åŠ è‡ªå®šä¹‰å­—æ®µlogtype
output.logstash:
  hosts: ["10.0.0.104:5044"] # æŒ‡å®šLogstashæœåŠ¡å™¨çš„åœ°å€å’Œç«¯å£
```










#### Elasticsearch

- ä¸‹è½½åœ°å€ï¼šhttps://www.elastic.co/cn/downloads/elasticsearch

- å†…ç½®JAVA

  - åŸºäº JAVA çš„åº”ç”¨ï¼Œè€Œä¸”å®‰è£…æ—¶ä¼šè‡ªåŠ¨å†…åµŒ JAVA ç¯å¢ƒï¼Œä½†æ˜¯ Elasticsearch çš„ JAVA ç¯å¢ƒä»…ä»…è‡ªå·±èƒ½ç”¨ï¼Œä¸èƒ½å…±äº«ï¼›
  - /usr/share/elasticsearch/jdk/bin/java -version

- dpkg ä¸ apt install å®‰è£…åŒ…æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

  - dpkg åªå®‰è£…åŒ…æœ¬èº«ï¼Œä¸ä¼šè‡ªåŠ¨è§£å†³ä¾èµ–ã€‚
  - apt ä¼šè‡ªåŠ¨è§£å†³ä¾èµ–ã€è‡ªåŠ¨ä¸‹è½½ç¼ºå°‘çš„åŒ…ï¼Œå¹¶æ›´å®‰å…¨ï¼›ï¼ˆå®é™…æœ€å¸¸ç”¨ï¼‰
  - dpkg è´Ÿè´£è§£åŒ…ï¼Œapt è´Ÿè´£ä¾èµ–ã€‚çº¿ä¸Šç”¨ aptï¼Œç¦»çº¿ç”¨ dpkgã€‚

- JVMä¼˜åŒ–

  - ç¼–è¾‘ /etc/elasticsearch/jvm.options æ–‡ä»¶ï¼Œæ·»åŠ æˆ–ä¿®æ”¹å‚æ•°ï¼š-Xms128m   å’Œ -Xmx128m

  - `-Xms` = JVM åˆå§‹å †å¤§å°

    `-Xmx` = JVM æœ€å¤§å †å¤§å°

  - ç”Ÿäº§ç¯å¢ƒè®¾ç½®è§„åˆ™ï¼š

    - **Elasticsearch è¦æ±‚ Xms å’Œ Xmx ä¿æŒä¸€è‡´**ï¼Œå¦åˆ™é¢‘ç¹æ‰©å®¹å †ä¼šå¯¼è‡´ Stop-The-World å¡é¡¿ã€‚
    - **å †å¤§å°å ç³»ç»Ÿç‰©ç†å†…å­˜çš„ 50% å·¦å³** ï¼ˆå®˜æ–¹å»ºè®®ï¼‰ã€‚
    - æœ€å¤§ä¸è¦è¶…è¿‡ 30GB ï¼›è¶…è¿‡ 30GB å°±ä¼šå¤±æ•ˆ â†’ æ€§èƒ½ç«‹åˆ»ä¸‹é™ ï¼›æ—¥å¿—ç±»ä¸šåŠ¡æ›´ä¾èµ–ç£ç›˜ååï¼Œè€Œä¸æ˜¯å †å¤§å°ï¼
    - å †è¶Šå¤§ â†’ GC æ‰«æè¶Šå¤š â†’ STW æ—¶é—´æ›´é•¿
    - å †è¶…è¿‡ 30GB â†’ ç¦ç”¨ Compressed Oops â†’ å†…å­˜å ç”¨å˜å¤§ â†’ GC è´Ÿæ‹…å‰§å¢ â†’ STW æ›´é•¿
    - è‹¥æ˜¯å®¹å™¨å¯åŠ¨ï¼Œåˆ™å¦è¯´ï¼

- ä¸‹è½½å®‰è£…åŒ…å»ºè®®å…ˆæŸ¥çœ‹äº§å“æ–‡æ¡£ï¼Œå½“å‰çš„ç³»ç»Ÿç‰ˆæœ¬ä¸ Elasticsearch çš„å…¼å®¹æ€§ï¼›[æ”¯æŒçŸ©é˜µ | Elastic](https://www.elastic.co/cn/support/matrix)

- å¼ºåˆ¶è¦æ±‚ï¼šå¿…é¡»ä»¥æ™®é€šç”¨æˆ·èº«ä»½å¯åŠ¨ï¼Œä¸èƒ½ä»¥è¶…çº§ç”¨æˆ·èº«ä»½å¯åŠ¨ï¼Œå¦åˆ™å¤±è´¥ï¼›

- Elasticsearch JAVA æ¯”è¾ƒåƒå†…å­˜ï¼Œå®éªŒæ—¶å»ºè®®è®¾ç½®ä¸º4GBå†…å­˜ï¼›

- Elasticsearch å®‰è£…å®Œæˆæ—¶ä¼šæ˜¾ç¤ºç™»å½•å¯†ç ï¼›

  - é‡ç½®å¯†ç ï¼š/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic

- é»˜è®¤ 9.X å¼€å¯ xpack å®‰å…¨ï¼Œå¯¼è‡´æ— æ³•ç›´æ¥è®¿é—®  curl 127.0.0.1:9200  è¿™æ ·ç›´æ¥è®¿é—®ä¼šå¤±è´¥ï¼

  - å…³é—­XPACKåŠŸèƒ½ï¼Œå°±å¯ä»¥ç›´æ¥è®¿é—®  curl 127.0.0.1:9200
    - ä¿®æ”¹ /etc/elasticsearch/elasticsearch.yml æ–‡ä»¶   xpack.security.enabled: false # ä¿®æ”¹ä¸ºfalse

- ç™»å½•ï¼šcurl -u"elastic:$PASSWORD" -k https://127.0.0.1:9200

##### åŒ…å®‰è£…ï¼ˆå•æœºï¼‰

```powershell
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-9.2.1-amd64.deb
apt install ./elasticsearch-9.2.1-amd64.deb
free -h
/usr/share/elasticsearch/jdk/bin/java -version
systemctl start elasticsearch.service
curl https://127.0.0.1:9200 -k
/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic
PASSWORD=cz+1XmXs9lPgOYWockJq
curl -u"elastic:$PASSWORD" -k https://127.0.0.1:9200
sed -i 's#^xpack.security.enabled#xpack.security.enabled: false#' /etc/elasticsearch/elasticsearch.yml
vim /etc/elasticsearch/jvm.options
-Xms2G
-Xmx2G
sudo sed -i '/Xmx4g$/a -Xms2G\n-Xmx2G' /etc/elasticsearch/jvm.options
sudo sed -i 's#128m#2G#' /etc/elasticsearch/jvm.options
grep -- Xm /etc/elasticsearch/jvm.options

systemctl restart elasticsearch.service
ps aux | grep java | grep Xms
```

```powershell
curl 127.0.0.1:9200/_cat/health
```

##### ES å•ç‚¹å¸è½½

- å¸è½½æ­¥éª¤ï¼š
  1. åœæœåŠ¡ï¼›
  2. å¸è½½è½¯ä»¶ï¼›(æ­¤æ“ä½œä¸ä¼šåˆ é™¤ES çš„æ•°æ®)
  3. åˆ é™¤æ•°æ®ï¼›ï¼ˆç”Ÿäº§ç¯å¢ƒä¸å»ºè®®è¿™æ ·åšï¼ï¼‰
  4. åˆ é™¤æ—¥å¿—ï¼›
  5. æ¸…ç©ºä¸´æ—¶æ•°æ®ï¼›

```powershell
systemctl stop elasticsearch
dpkg -r elasticsearch
rm -rf /var/lib/elasticsearch/*
ll /var/{var,log}/elasticsearch
rm -rf /tmp/*
```



##### ES  é›†ç¾¤éƒ¨ç½²

- 8.X ä»¥ä¸Šç‰ˆæœ¬é›†ç¾¤é…ç½®

- ç¼–è¾‘ /etc/elasticsearch/elasticsearch.yml æ–‡ä»¶é…ç½®

  - node.name: node-1      ä¿®æ”¹æ­¤è¡Œï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸åŒï¼›

  - http.port: 9200  é»˜è®¤ä¹Ÿæ˜¯9200ï¼›

  - network.host: 0.0.0.0    é›†ç¾¤æ¨¡å¼å¿…é¡»ä¿®æ”¹æ­¤è¡Œï¼Œå¦åˆ™é›†ç¾¤èŠ‚ç‚¹æ— æ³•é€šè¿‡9300ç«¯å£é€šä¿¡ï¼›æ¯ä¸ªèŠ‚ç‚¹ç›¸åŒï¼›

  - å»æ³¨é‡Š cluster.name: my-application ï¼›è¿™æ˜¯é›†ç¾¤åï¼Œåç§°æ— æ‰€è°“ï¼Œä½†æ˜¯åŒé›†ç¾¤å†…è¿™ä¸ªåç§°å¿…é¡»å”¯ä¸€ï¼›

  - discovery.seed_hosts: ["10.0.0.201", "10.0.0.202","10.0.0.203"]               ä¿®æ”¹æ­¤è¡Œï¼Œæ¯ä¸ªèŠ‚ç‚¹ç›¸åŒï¼›

  - cluster.initial_master_nodes: ["10.0.0.201", "10.0.0.202","10.0.0.203"]     ä¿®æ”¹æ­¤è¡Œï¼Œæ¯ä¸ªèŠ‚ç‚¹ç›¸åŒï¼›è¿™ä¸ªå‚æ•°æœ‰ä¸¤ä¸ªï¼Œè®°å¾—è¦æ³¨é‡Šå…¶ä¸­ä¸€ä¸ªï¼›

    - ä»…ä»…ç”Ÿæ•ˆäºé¦–æ¬¡é€‰ä¸¾ï¼›ç¬¬äºŒæ¬¡ç¬¬ä¸‰æ¬¡åŠä»¥åçš„é€‰ä¸¾ä¸æ­¤é…ç½®æ— å…³ï¼›
    - è®¾ç½® node.master:true æŒ‡å®šæ˜¯å¦å‚ä¸ Master èŠ‚ç‚¹é€‰ä¸¾ï¼Œé»˜è®¤æ˜¯true ï¼›å¦‚æœæ”¹ä¸º flase åˆ™ä¸å‚ä¸åç»­çš„ Master é€‰ä¸¾ï¼›

  - xpack.security.enabled: false       ä¿®æ”¹æ­¤è¡Œï¼Œæ¯ä¸ªèŠ‚ç‚¹ç›¸åŒï¼›

  - bootstrap.memory_lock: true        ï¼ˆä¼˜åŒ–ï¼‰å†…å­˜é”ï¼›å¼€å¯æ­¤åŠŸèƒ½å¯¼ 8.X è‡´é›†ç¾¤æ¨¡å¼æ— æ³•å¯åŠ¨ï¼Œä½†å•æœºæ¨¡å¼å¯ä»¥å¯åŠ¨ï¼›

    - ```powershell
      sudo sed -i '/^\[Service\]/a LimitMEMLOCK=infinity' /usr/lib/systemd/system/elasticsearch.service
      ```

      ä½œç”¨ï¼šå…è®¸ Elasticsearch è¿›ç¨‹é”å®šä¸é™é‡å†…å­˜ï¼Œå¦åˆ™å¯ç”¨ bootstrap.memory_lock ä¼šç›´æ¥æŠ¥é”™ã€‚

```powershell
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-9.2.1-amd64.deb
apt install ./elasticsearch-9.2.1-amd64.deb

vi /etc/elasticsearch/elasticsearch.yml
node.name: node-1
network.host: 0.0.0.0
xpack.security.enabled: false
cluster.name: my-application
discovery.seed_hosts: ["10.0.0.201","10.0.0.202","10.0.0.203"]
cluster.initial_master_nodes: ["10.0.0.201","10.0.0.202","10.0.0.203"]
#cluster.initial_master_nodes: ["MINIO-201"]	# æœ‰ä¸¤ä¸ªç›¸åŒçš„å‚æ•°ï¼Œåªèƒ½ç•™ä¸€ä¸ªï¼

for i in {201..203} ; do scp /etc/elasticsearch/elasticsearch.yml 10.0.0.$i:/etc/elasticsearch/elasticsearch.yml ; done
sed -i 's#^node.name.*#node.name: node-2#' /etc/elasticsearch/elasticsearch.yml && grep 'node-2' /etc/elasticsearch/elasticsearch.yml
sed -i 's#^node.name.*#node.name: node-3#' /etc/elasticsearch/elasticsearch.yml && grep 'node-3' /etc/elasticsearch/elasticsearch.yml
grep cluster.initial_master_nodes /etc/elasticsearch/elasticsearch.yml

sudo sed -i 's#2G#1G#' /etc/elasticsearch/jvm.options && grep -- Xm /etc/elasticsearch/jvm.options

sudo systemctl daemon-reload
systemctl restart elasticsearch.service && systemctl status elasticsearch.service
ss -ntlp |grep -E '9200|9300'

# é€šè¿‡æµè§ˆå™¨è®¿é—® Elasticsearch æœåŠ¡ç«¯å£
http://10.0.0.201:9200/ 
```

```powershell
curl http://10.0.0.201:9200/_cat/health
curl -s 10.0.0.201:201/_cat/nodes
curl -s 10.0.0.201:[201..203] | grep cluster_uuid
```





##### æ’ä»¶

- é€šè¿‡ä½¿ç”¨å„ç§æ’ä»¶å¯ä»¥å®ç°å¯¹ ES é›†ç¾¤çš„çŠ¶æ€ç›‘æ§, æ•°æ®è®¿é—®, ç®¡ç†é…ç½®ç­‰åŠŸèƒ½;

Cerebro æ’ä»¶

- ä¸ªäººä¸å–œæ¬¢è¿™ä¸ªæ’ä»¶ï¼Œæ‰€ä»¥æ²¡æœ‰åšè¿™ä¸ªæœåŠ¡ï¼

Head æ’ä»¶

- gitåœ°å€ï¼šhttps://github.com/mobz/elasticsearch-head
- æµè§ˆå™¨å®‰è£…ï¼šç®¡ç†æ‰©å±• â€”â€” æ·»åŠ æ‰©å±• â€”â€” æ·»åŠ å®Œæˆåï¼Œç‚¹å‡»è¯¥æ’ä»¶ä½¿ç”¨

![image-20251204220901976](C:\Program Files\Obsidian\data\Obsidian_Vault\image-20251204220901976.png)

##### æ•…éšœè‡ªæ„ˆ

- å½“èŠ‚ç‚¹å®•æœºåï¼ŒElasticsearch ä¼šè‡ªåŠ¨æ£€æµ‹åˆ°åˆ†ç‰‡ä¸¢å¤±ï¼Œå¹¶åœ¨å…¶ä»–èŠ‚ç‚¹é‡å»ºå‰¯æœ¬ï¼Œæ¢å¤èŠ‚ç‚¹åå†è¿›è¡Œåˆ†ç‰‡å‡è¡¡ï¼Œä»è€Œå®ç°çœŸæ­£æ„ä¹‰ä¸Šçš„â€œæ•…éšœè‡ªæ„ˆâ€ã€‚

> å‡†å¤‡å·¥ä½œï¼šå®Œæˆä¸Šé¢çš„é›†ç¾¤ï¼›å®‰è£…æ’ä»¶ï¼›
>
> ```powershell
> # åˆ›å»ºä¸€ä¸ªç´¢å¼• index2ï¼ŒåŒ…å« 3 ä¸ªä¸»åˆ†ç‰‡ï¼ˆPï¼‰+ 1 ä¸ªå‰¯æœ¬åˆ†ç‰‡ï¼ˆRï¼‰ï¼š
> curl -X PUT "10.0.0.202:9200/index2" -H "Content-Type: application/json" -d '{
>  "settings": {
>    "index": {
>      "number_of_shards": 3,
>      "number_of_replicas": 1
>    }
>  }
> }'
> systemctl stop elasticsearch
> ```
>
> æ­¤æ—¶åœ¨ 3 èŠ‚ç‚¹é›†ç¾¤ä¸­ï¼Œ**æ¯ä¸ªä¸»åˆ†ç‰‡ P éƒ½ä¼šè¢«åˆ†å¸ƒåˆ°ä¸åŒçš„èŠ‚ç‚¹ä¸Šï¼Œæ¯ä¸ªå‰¯æœ¬ R ä¹Ÿä¼šåˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹**ï¼Œç¡®ä¿æ²¡æœ‰ P å’Œ R è½åœ¨åŒä¸€èŠ‚ç‚¹ä¸Šã€‚

> æ¨¡æ‹ŸèŠ‚ç‚¹æ•…éšœï¼ˆä¸‹çº¿ 10.0.0.201ï¼‰
>
> ```powershell
> systemctl stop elasticsearch
> ```
>
> **å¥åº·çŠ¶æ€ä» green â†’ yellow**
>
> - æŸä¸ªèŠ‚ç‚¹å®•æœºåï¼Œè½åœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„ **å‰¯æœ¬åˆ†ç‰‡ï¼ˆReplicaï¼‰ä¸å¯ç”¨**ã€‚
> - ä¸»åˆ†ç‰‡ä»åœ¨å…¶ä»–èŠ‚ç‚¹ä¸Šï¼Œæ‰€ä»¥ **æ•°æ®ä¾ç„¶èƒ½è¯»å†™**ã€‚
> - å‰¯æœ¬åˆ†ç‰‡ç¼ºå¤± â†’ é›†ç¾¤çŠ¶æ€å˜ä¸º **Yellowï¼ˆéƒ¨åˆ†å‰¯æœ¬ç¼ºå¤±ï¼‰**ã€‚
>
> ğŸ‘‰ **Yellow è¡¨ç¤ºæ•°æ®å¯ç”¨ï¼Œä½†å†—ä½™ä¸è¶³ã€‚**

> **Elasticsearch è‡ªåŠ¨æ•…éšœè‡ªæ„ˆ**
>
> å½“èŠ‚ç‚¹ 10.0.0.201 ä¸‹çº¿åï¼Œè¿‡ä¸€æ®µæ—¶é—´ï¼ˆé»˜è®¤ 1 åˆ†é’Ÿå·¦å³ï¼‰ï¼ŒES ä¼šè§¦å‘ä»¥ä¸‹åŠ¨ä½œï¼š
>
> **è‡ªåŠ¨é‡æ–°åˆ†é…å‰¯æœ¬ï¼ˆReplica Reallocationï¼‰**
>
> - ES ä¼šæ£€æµ‹åˆ°æŸèŠ‚ç‚¹ä¸å¯ç”¨
> - é›†ç¾¤ä¼šåœ¨å‰©ä½™å¥åº·çš„èŠ‚ç‚¹ä¸Š **è‡ªåŠ¨é‡å»ºå‰¯æœ¬åˆ†ç‰‡**
> - å†—ä½™æ¢å¤å®Œæ•´åï¼ŒçŠ¶æ€ä» **Yellow â†’ Green**
>
> ğŸ‘‰ æ­¤è¿‡ç¨‹ç§°ä¸ºï¼š
>
> **â— è‡ªåŠ¨åˆ†ç‰‡é‡åˆ†é…ï¼ˆAuto Shard Reallocationï¼‰**
>
> ä¹Ÿè¢«ç§°ä¸ºï¼š
>
> - å‰¯æœ¬è‡ªæ„ˆ
> - åˆ†ç‰‡ä¿®å¤æœºåˆ¶
> - é›†ç¾¤å†å‡è¡¡

> æ¢å¤èŠ‚ç‚¹åï¼ˆé‡æ–°å¯åŠ¨ 10.0.0.201ï¼‰
>
> ```powershell
> systemctl start elasticsearch
> ```
>
> èŠ‚ç‚¹é‡æ–°åŠ å…¥é›†ç¾¤åï¼š
>
> **é›†ç¾¤é‡æ–°å¹³è¡¡ï¼ˆShard Rebalancingï¼‰**
>
> - ES ä¼šå°†éƒ¨åˆ†ä¸»åˆ†ç‰‡æˆ–å‰¯æœ¬åˆ†ç‰‡è¿å›åˆ°è¿™ä¸ªèŠ‚ç‚¹
> - æœ€ç»ˆå†æ¬¡è¾¾åˆ°åˆ†ç‰‡å‡è¡¡çŠ¶æ€ï¼ˆå¹³è¡¡è´Ÿè½½ï¼‰
>
> ğŸ‘‰ è¿™ç§°ä¸ºï¼š
>
> **â— è‡ªåŠ¨åˆ†ç‰‡é‡æ–°å‡è¡¡ï¼ˆAuto Shard Rebalancingï¼‰**
>
> æ¢å¤åé›†ç¾¤å†æ¬¡ä¿æŒï¼š
>
> - çŠ¶æ€ï¼š**Green**
> - ä¸»åˆ†ç‰‡æ­£å¸¸
> - å‰¯æœ¬åˆ†ç‰‡å®Œæ•´
> - è´Ÿè½½å‡è¡¡

![image-20251204221226150](C:\Program Files\Obsidian\data\Obsidian_Vault\image-20251204221226150.png)

Elasticsearch æ•°æ®çš„æ›´æ”¹æ˜¯ç”±ä¸»åˆ†ç‰‡å†³å®šçš„ï¼Œä¸»åˆ†ç‰‡æ‰§è¡Œå®Œå¢åˆ æ”¹ååŒæ­¥åˆ°å‰¯åˆ†ç‰‡ä¸­ï¼›



### ELK ç»¼åˆå®æˆ˜æ¡ˆä¾‹

```powershell
åšä¸€ä¸ªæ–¹æ¡ˆï¼ˆå®éªŒï¼‰ï¼šFilebeat æ”¶é›†Nginxæ—¥å¿—åˆ©ç”¨ Redis ç¼“å­˜å‘é€è‡³ Elasticsearchï¼›
nginxæœåŠ¡å™¨ï¼š10.0.0.100
FilebeatæœåŠ¡ï¼š10.0.0.100	å¯¹åº”ç‰ˆæœ¬ï¼šfilebeat-9.2.2-amd64.deb
redisæœåŠ¡å™¨ï¼š10.0.0.201
logstashæœåŠ¡å™¨ï¼š10.0.0.100	å¯¹åº”ç‰ˆæœ¬ï¼šlogstash-9.2.2-amd64.deb
ElasticsearchæœåŠ¡é›†ç¾¤ï¼š10.0.0.201ï¼›10.0.0.202ï¼›10.0.0.203	å¯¹åº”ç‰ˆæœ¬ï¼šelasticsearch-9.2.1-amd64.deb
kibanaæœåŠ¡å™¨ï¼š10.0.0.200		å¯¹åº”ç‰ˆæœ¬ï¼škibana-9.2.2-amd64.deb
å¤‡æ³¨ï¼šéƒ½æ˜¯Ubuntu2404ç³»ç»Ÿï¼›
```

#### æ¡ˆä¾‹ä¸€

æ‹“æ‰‘å›¾

```powershell
Nginx â€”â€”> Redis/Kafka â€”â€”> Logstash â€”â€”> ES â€”â€”> kibana â€”â€”> ä¸–ç•Œåœ°å›¾
  |                          |
  |â€”â€”â€”â€”> kibana å®‰å…¨è®¤è¯      |â€”â€”â€”â€”> Mysql
```



- Filebeat æ”¶é›† Nginx æ—¥å¿—åˆ©ç”¨ Redis ç¼“å­˜å‘é€è‡³ Elasticsearch ï¼›
  - åˆ©ç”¨ Redis ç¼“å­˜æ—¥å¿—æ•°æ®,ä¸»è¦è§£å†³åº”ç”¨è§£è€¦ï¼Œå¼‚æ­¥æ¶ˆæ¯ï¼Œæµé‡å‰Šé”‹ç­‰é—®é¢˜ï¼›
  - å±€é™æ€§ï¼šä¸æ”¯æŒRedis é›†ç¾¤ï¼Œå­˜åœ¨å•ç‚¹é—®é¢˜ï¼Œä½†æ˜¯å¯ä»¥å¤šèŠ‚ç‚¹è´Ÿè½½å‡è¡¡ï¼›Redis åŸºäºå†…å­˜ï¼Œå› æ­¤å­˜æ”¾æ•°æ®é‡æœ‰é™

##### Redis  ï¼ˆäºŒé€‰ä¸€ï¼‰

```powershell
apt update && apt -y install redis
vim /etc/redis/redis.conf
bind 0.0.0.0
save "" #ç¦ç”¨rdbæŒä¹…ä¿å­˜
# cluster-enabled no  # ç¡®ä¿æ˜¯ no æˆ–è€…æ³¨é‡Š
requirepass 123123

systemctl restart redis
```

æŸ¥çœ‹ Redis ä¸­çš„æ•°æ®

```powershell
# æŸ¥çœ‹æ‰€æœ‰é”®ï¼š
redis-cli -a 123123 --no-auth-warning keys '*'
# æŸ¥çœ‹ filebeat é”®çš„æ•°æ®ç±»å‹ï¼š
redis-cli -a 123123 --no-auth-warning type filebeat
# æŸ¥çœ‹ filebeat é”®ä¸­çš„å‰ä¸¤ä¸ªæ•°æ®ï¼š
redis-cli -a 123123 --no-auth-warning lrange filebeat 0 1

keys *
llen filebeat
```

##### Kafka  é›†ç¾¤ï¼ˆäºŒé€‰ä¸€ï¼‰

- åŸºäº zookeeper å®‰è£… ï¼ˆä¸»æµï¼‰
- ä»¥ä¸‰ä¸ªèŠ‚ç‚¹æ­å»ºä¸€ä¸ª Kafka é›†ç¾¤

```powershell
# ä¿®æ”¹æ¯ä¸ªkafkaèŠ‚ç‚¹çš„ä¸»æœºå
hostnamectl set-hostname node1
hostnamectl set-hostname node2
hostnamectl set-hostname node3
# åœ¨æ‰€æœ‰kafkaèŠ‚ç‚¹ä¸Šå®ç°ä¸»æœºåç§°è§£æ
cat >> /etc/hosts <<eof
10.0.0.91 node3
10.0.0.92 node1
10.0.0.93 node2
eof
# å®‰è£… JAVA
apt update && apt -y install openjdk-21-jre
java -version
update-alternatives --config java
# ä¸‹è½½äºŒè¿›åˆ¶åŒ…å¹¶å®‰è£…
wget https://mirrors.aliyun.com/apache/kafka/3.9.1/kafka_2.13-3.9.1.tgz
tar xf kafka_2.13-3.9.1.tgz -C /usr/local/
cd /usr/local/ && ls
ln -s /usr/local/kafka_2.13-3.9.1/ /usr/local/kafka && ls /usr/local/kafka
# ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œæ­¤ç›®å½•æ— éœ€æ‰‹åŠ¨åˆ›å»ºï¼Œå¯åŠ¨ä¼šè‡ªåŠ¨åˆ›å»º
sed -i "s#^dataDir.*#dataDir=/data/zookeeper#" /usr/local/kafka/config/zookeeper.properties
sed -i "s#^log.dirs.*#log.dirs=/data/kafka-logs#" /usr/local/kafka/config/server.properties
# ä¸´æ—¶å¯åŠ¨ ï¼ˆå¯é€‰ï¼‰
/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties
/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties
```

```powershell
mkdir -p /usr/local/kafka/data/
# é›†ç¾¤é…ç½®å¿…é¡»é…ç½®æ—¶é—´ç›¸å…³ ï¼ˆä¸‰ä¸ªèŠ‚ç‚¹å°±é…ç½®ç›¸åŒï¼‰
vim /usr/local/kafka/config/zookeeper.properties
#å¿…é¡»æ·»åŠ æ—¶é—´ç›¸å…³é…ç½®
tickTime=2000
initLimit=10
syncLimit=5
#ä¿ç•™ä¸‹é¢å†…å®¹
clientPort=2181
maxClientCnxns=0
admin.enableServer=false
#æ·»åŠ ä¸‹é¢é›†ç¾¤é…ç½®
dataDir=/usr/local/kafka/data/
server.1=10.0.0.91:2888:3888
server.2=10.0.0.92:2888:3888
server.3=10.0.0.93:2888:3888

# ä¸»æœºï¼š10.0.0.91
echo 1 > /usr/local/kafka/data/myid
# ä¸»æœºï¼š10.0.0.92
echo 2 > /usr/local/kafka/data/myid	
# ä¸»æœºï¼š10.0.0.93
echo 3 > /usr/local/kafka/data/myid
```

```powershell
# å„èŠ‚ç‚¹éƒ¨ç½² Kafka é…ç½®æ–‡ä»¶ ï¼ˆå•æœºéƒ¨ç½²ä¸éœ€è¦æ”¹é…ç½®ï¼Œä½†æ˜¯é›†ç¾¤éƒ¨ç½²å¿…é¡»è¦ä¿®æ”¹ä¸€äº›å‚æ•°ï¼ï¼‰
vi /usr/local/kafka/config/server.properties 
# æ¯ä¸ªèŠ‚ç‚¹idå·å”¯ä¸€ ï¼ˆ10.0.0.91å¯¹åº”1ï¼›ä»¥æ­¤ç±»æ¨ï¼‰
broker.id=1
# kafkaç›‘å¬ç«¯å£ï¼Œé»˜è®¤9092 (æ¯ä¸ªèŠ‚ç‚¹å†™è‡ªèº«çš„ipåœ°å€)
listeners=PLAINTEXT://10.0.0.91:9092
log.dirs=/usr/local/kafka/data
zookeeper.connect=10.0.0.91:2181,10.0.0.92:2181,10.0.0.93:2181

â€”â€”â€”â€” åˆ†å‰²çº¿ â€”â€”â€”â€”

ls /root/.ssh/id_rsa.pub | ssh-keygen -t rsa
for host in 10.0.0.{92,93}; do ssh-copy-id -i /root/.ssh/id_rsa.pub -o StrictHostKeyChecking=no root@$host ;  done

for i in {92,93} ; do scp /etc/hosts  10.0.0.$i:/etc/hosts; done
for i in {92,93} ; do scp /usr/local/kafka/config/zookeeper.properties  10.0.0.$i:/usr/local/kafka/config/zookeeper.properties ; done
for i in {92,93} ; do scp /usr/local/kafka/config/server.properties  10.0.0.$i:/usr/local/kafka/config/server.properties ; done
sed -i "s#//10.0.0.91#//10.0.0.92#" /usr/local/kafka/config/server.properties && grep "10.0.0." /usr/local/kafka/config/server.properties
sed -i "s#broker.id=1#broker.id=2#" /usr/local/kafka/config/server.properties && grep "^broker" /usr/local/kafka/config/server.properties

sed -i "s#//10.0.0.91#//10.0.0.93#" /usr/local/kafka/config/server.properties && grep "10.0.0." /usr/local/kafka/config/server.properties
sed -i "s#broker.id=1#broker.id=3#" /usr/local/kafka/config/server.properties && grep "^broker" /usr/local/kafka/config/server.properties
```

```powershell
# åˆ›å»ºserviceæ–‡ä»¶
cat > /lib/systemd/system/zookeeper.service <<EOF
[Unit]
Description=zookeeper.service
After=network.target

[Service]
Type=forking
ExecStart=/usr/local/kafka/bin/zookeeper-server-start.sh -daemon /usr/local/kafka/config/zookeeper.properties
ExecStop=/usr/local/kafka/bin/zookeeper-server-stop.sh
ExecReload=/bin/kill -HUP \$MAINPID

[Install]
WantedBy=multi-user.target
EOF
# åˆ›å»ºserviceæ–‡ä»¶
cat > /lib/systemd/system/kafka.service <<EOF
[Unit]
Description=kafka.service
After=network.target zookeeper.service

[Service]
Type=forking
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh
ExecReload=/bin/kill -HUP \$MAINPID

[Install]
WantedBy=multi-user.target
EOF

systemctl  start zookeeper && systemctl  status zookeeper
systemctl  start kafka && systemctl  status kafka
ss -tunlp | grep 9092

# è¿›å…¥å›¾å½¢å®¢æˆ·ç«¯åï¼Œåœ¨brokersçš„idsæ–‡ä»¶å¤¹ä¸­å¯ä»¥çœ‹åˆ°012è¿™ä¸‰ä¸ªbrokersç¼–å·ï¼
```



##### Nginx

- éƒ¨ç½² Nginx æœåŠ¡é…ç½® Json æ ¼å¼çš„è®¿é—®æ—¥å¿—
- ä¿®æ”¹nginxè®¿é—®æ—¥å¿—ä¸ºJsonæ ¼å¼
- é»˜è®¤å¼€å¯nginxçš„é”™è¯¯æ—¥å¿—,ä½†å¦‚æœæ˜¯ubuntu,è¿˜éœ€è¦ä¿®æ”¹ä¸‹é¢è¡Œæ‰èƒ½è®°å½•é”™è¯¯æ—¥å¿—
- éªŒè¯è®¿é—®æ—¥å¿—çš„jsonæ ¼å¼

```powershell
apt update && apt -y install nginx
vim /etc/nginx/nginx.conf
http {
    log_format access_json '{"@timestamp":"$time_iso8601",'
    '"host":"$server_addr",'
    '"clientip":"$remote_addr",'
    '"size":$body_bytes_sent,'
    '"responsetime":$request_time,'
    '"upstreamtime":"$upstream_response_time",'
    '"upstreamhost":"$upstream_addr",'
    '"http_host":"$host",'
    '"uri":"$uri",'
    '"domain":"$host",'
    '"xff":"$http_x_forwarded_for",'
    '"referer":"$http_referer",'
    '"tcp_xff":"$proxy_protocol_addr",'
    '"http_user_agent":"$http_user_agent",'
    '"status":"$status"}';

    access_log /var/log/nginx/access.log access_json;
}
# é»˜è®¤å¼€å¯nginxçš„é”™è¯¯æ—¥å¿—,ä½†å¦‚æœæ˜¯ubuntu,è¿˜éœ€è¦ä¿®æ”¹ä¸‹é¢è¡Œæ‰èƒ½è®°å½•é”™è¯¯æ—¥å¿—
vim /etc/nginx/sites-available/default
    location / {
        # First attempt to serve request as file, then
        # as directory, then fall back to displaying a 404.
        try_files $uri $uri/ =404; # å°†æ­¤è¡Œæ³¨é‡Š

# éªŒè¯è®¿é—®æ—¥å¿—çš„jsonæ ¼å¼
tail -n 1 /etc/nginx/nginx.conf/access_json.log

systemctl restart nginx
```

##### Filebeat 

- **åˆ©ç”¨ Filebeat æ”¶é›†æ—¥å¿—åˆ° Redis ï¼ˆäºŒé€‰ä¸€ï¼‰**

```powershell
dpkg -i filebeat-9.2.2-amd64.deb

cat > /etc/filebeat/filebeat.yml <<'eof'
filebeat.inputs:
  # Nginxè®¿é—®æ—¥å¿—ï¼ˆJSONæ ¼å¼ï¼‰
  - type: filestream
    id: my-filestream-id-1
    enabled: true
    tags: ["nginx-access"]
    paths:
      - /var/log/nginx/access_json.log
    # åªæœ‰JSONæ ¼å¼çš„æ—¥å¿—æ‰ä½¿ç”¨ndjsonè§£æå™¨
    parsers:
      - ndjson:
          target: ""  # è§£æç»“æœå­˜æ”¾åœ¨æ ¹ä¸‹
          # message_key: message  # ä»…å½“JSONåœ¨messageå­—æ®µä¸­æ—¶æ‰éœ€è¦

  # Nginxé”™è¯¯æ—¥å¿—ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
  - type: filestream
    id: my-filestream-id-2
    enabled: true
    tags: ["nginx-error"]
    paths:
      - /var/log/nginx/error.log
    # æ–‡æœ¬æ ¼å¼æ—¥å¿—ä¸éœ€è¦ndjsonè§£æå™¨
    # å¦‚æœéœ€è¦ç»“æ„åŒ–è§£æï¼Œåº”è¯¥ä½¿ç”¨grokæ¨¡å¼æˆ–dissectå¤„ç†å™¨

  # Syslogï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
  - type: filestream
    id: my-filestream-id-3
    enabled: true
    tags: ["syslog"]
    paths:
      - /var/log/syslog
    # æ–‡æœ¬æ ¼å¼æ—¥å¿—ä¸éœ€è¦ndjsonè§£æå™¨
    # å¯ä»¥ä½¿ç”¨syslogè§£æå™¨æˆ–åæœŸå¤„ç†

# è¾“å‡ºé…ç½®
output.redis:
  hosts: ["10.0.0.91:6379"]
  password: "123123"
  db: "0"
  key: "filebeat"
eof

# æ£€æŸ¥é…ç½®è¯­æ³•å’Œç»“æ„
filebeat test config -c /etc/filebeat/filebeat.yml

systemctl restart filebeat.service ; systemctl status filebeat.service
```

- **åˆ©ç”¨ Filebeat æ”¶é›†æ—¥å¿—åˆ° Kafka ï¼ˆäºŒé€‰ä¸€ï¼‰**

```powershell
cat > /etc/filebeat/filebeat.yml <<'eof'
filebeat.inputs:
  - type: filestream
    id: nginx-access
    enabled: true
    paths:
      - /var/log/nginx/access_json.log
    json:
      keys_under_root: true
      overwrite_keys: true
    tags: ["nginx-access"]

  - type: filestream
    id: nginx-error
    enabled: true
    paths:
      - /var/log/nginx/error.log
    tags: ["nginx-error"]

  - type: filestream
    id: syslog
    enabled: true
    paths:
      - /var/log/syslog
    tags: ["syslog"]

output.kafka:
  hosts: ["10.0.0.91:9092", "10.0.0.92:9092", "10.0.0.93:9092"]
  topic: filebeat-log

  partition.round_robin:
    reachable_only: true

  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000
eof

grep -Ev "#|^$" /etc/filebeat/filebeat.yml
# é‡å¯ filebeat æœåŠ¡ï¼Œä¸å‡ºæ„å¤–çš„è¯åœ¨ kafka å›¾å½¢å·¥å…·å±•ç¤ºä¸­å°±èƒ½çœ‹åˆ° æŒ‡å®šçš„ kafka topic
filebeat test config
filebeat test output
systemctl restart filebeat
# åœ¨ vi  /var/log/nginx/access.log ä¸­å†™å…¥æ—¥å¿—æ•°æ®ï¼Œ åœ¨kafkaæŸ¥çœ‹æ˜¯å¦æœ‰æ•°æ®
/usr/local/kafka/bin/kafka-topics.sh --list --bootstrap-server 10.0.0.91:9092
/usr/local/kafka/bin/kafka-console-consumer.sh --topic filebeat-log --bootstrap-server 10.0.0.91:9092 --from-beginning
```



##### Logstash

- åˆ›å»º Logstash çš„ pipeline é…ç½®æ–‡ä»¶ï¼›

  - ä» Redis é‡Œå– Filebeat æ¨é€çš„æ—¥å¿— â†’ å¤„ç†ï¼ˆGeoIP/å­—æ®µç±»å‹è½¬æ¢ï¼‰â†’ æŒ‰ tag å†™å…¥ä¸åŒçš„ Elasticsearch ç´¢å¼•ï¼›

  - å®ƒéµå¾ª Logstash çš„ä¸‰æ®µå¼ç»“æ„ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š

    ```powershell
    input   â†’  filter  â†’  output
    ```

  - input / redis ï¼šä» Redis list(filebeat) ä¸­é˜»å¡è¯»å–æ—¥å¿—äº‹ä»¶ï¼›

  - filter / geoip + mutateï¼šå¯¹ nginx-access æ—¥å¿—åšå¢å¼ºå¤„ç†ï¼›

    - geoipï¼šç»™ IP æ‰“ä¸Šå›½å®¶ / åŸå¸‚ / ç»çº¬åº¦ï¼›
    - mutate.convertï¼šæŠŠå­—ç¬¦ä¸²å˜æˆæ•°å€¼ï¼Œæ–¹ä¾¿ ES èšåˆï¼ˆavg / maxï¼‰

  - output / æ¡ä»¶è·¯ç”±ï¼šä¸åŒæ—¥å¿— â†’ ä¸åŒç´¢å¼•

```powershell
# 8.X è¦æ±‚JDK11æˆ–17
apt update && apt -y install openjdk-17-jdk
dpkg -i logstash-9.2.2-amd64.deb

systemctl start logstash.service ; systemctl status logstash.service
# ç”Ÿæˆä¸“æœ‰ç”¨æˆ·logstash,ä»¥æ­¤ç”¨æˆ·å¯åŠ¨æœåŠ¡,åç»­ä½¿ç”¨æ—¶å¯èƒ½ä¼šå­˜åœ¨æƒé™é—®é¢˜
id logstash
```

- é…ç½® Logstash è¯»å– Redis æ—¥å¿—å‘é€åˆ° Elasticsearch ï¼ˆäºŒé€‰ä¸€ï¼‰

```powershell
# åˆ›å»º Logstash çš„ pipeline é…ç½®æ–‡ä»¶
cat > /etc/logstash/conf.d/redis-to-es.conf << 'EOF'
input {
  redis {
    host => "10.0.0.91"
    port => 6379
    password => "123123"
    db => 0
    key => "filebeat"
    data_type => "list"
    threads => 2
  }
}

filter {
  if [message] {
    json {
      source => "message"
      target => "parsed"
    }
  }
  
  if "nginx-access" in [tags] {
    if [parsed][upstreamtime] {
      mutate {
        convert => { "[parsed][upstreamtime]" => "float" }
      }
    }
    
    if [parsed][responsetime] {
      mutate {
        convert => { "[parsed][responsetime]" => "float" }
      }
    }
    
    if [parsed][size] {
      mutate {
        convert => { "[parsed][size]" => "integer" }
      }
    }
    
    if [parsed][status] {
      mutate {
        convert => { "[parsed][status]" => "integer" }
      }
    }
  }
  
  date {
    match => [ "@timestamp", "ISO8601" ]
    target => "@timestamp"
  }
}

output {
  if "syslog" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200", "10.0.0.202:9200", "10.0.0.203:9200"]
      index => "syslog-%{+YYYY.MM.dd}"
    }
  }
  
  if "nginx-access" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200", "10.0.0.202:9200", "10.0.0.203:9200"]
      index => "nginx-access-%{+YYYY.MM.dd}"
      template_overwrite => true
    }
    
    stdout {
      codec => rubydebug
    }
  }
  
  if "nginx-error" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200", "10.0.0.202:9200", "10.0.0.203:9200"]
      index => "nginx-error-%{+YYYY.MM.dd}"
      template_overwrite => true
    }
  }
}
EOF

# åœæ­¢æœåŠ¡ï¼Œä»¥ logstash ç”¨æˆ·åœ¨å‰å°å¯åŠ¨é…ç½®æ–‡ä»¶
systemctl  stop logstash.service
sudo -u logstash /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis-to-es.conf -r
# åœ¨ filebeat æœåŠ¡æ‰€åœ¨çš„è®¾å¤‡è¿›è¡Œæ¨¡æ‹Ÿæ—¥å¿—æ•°æ®å˜æ›´ï¼Œç„¶ååœ¨ logstash æœåŠ¡å™¨è¿›è¡Œè§‚å¯Ÿ
mv mall_app.log  /var/log/mall_app.log 
# logstash æœåŠ¡å™¨æ”¶åˆ° filebeat æ”¶é›†çš„æ•°æ®ï¼Œæ•´ç†å¹¶å‘é€åˆ° ES ä¸­ï¼Œåœ¨ ES å¯è§†åŒ–å›¾å½¢ç•Œé¢ä¸­å¯ä»¥çœ‹åˆ°è¿™ä¸ªç´¢å¼•
mall-app-2025.12.09
```

##### æ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯

- å°†æ—¥å¿—ä¸­çš„å®¢æˆ·ç«¯IPæ·»åŠ åœ°ç†ä½ç½®ä¿¡æ¯ ï¼›ï¼ˆå¯é€‰ï¼‰

```powershell
cat > /etc/logstash/conf.d/redis-to-es.conf <<'eof'
input {
  redis {
    host     => "10.0.0.91"
    port     => "6379"
    password => "123123"
    db       => "0"
    key      => "filebeat"
    data_type => "list"
  }
}

filter {

  if "nginx-access" in [tags] {
    geoip {
      source => "clientip"
      target => "geoip"
      database => "/usr/share/logstash/vendor/bundle/jruby/3.1.0/gems/logstash-filter-geoip-7.3.1-java/vendor/GeoLite2-City.mmdb"
      add_field => ["[geoip][coordinates]", "%{[geoip][geo][location][lon]}"]
      add_field => ["[geoip][coordinates]", "%{[geoip][geo][location][lat]}"]
    }

    mutate {
      convert => { "[geoip][coordinates]" => "float" }
    }
  }

  mutate {
    convert => { "upstreamtime" => "float" }
  }

}

output {

  if "syslog" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200", "10.0.0.202:9200", "10.0.0.203:9200"]
      index => "syslog-%{+YYYY.MM.dd}"
    }
  }

  if "nginx-access" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200", "10.0.0.202:9200", "10.0.0.203:9200"]
      index => "nginxaccess-%{+YYYY.MM.dd}"
      template_overwrite => true
    }
    stdout {
      codec => rubydebug
    }
  }

  if "nginx-error" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200", "10.0.0.202:9200", "10.0.0.203:9200"]
      index => "nginxerrorlog-%{+YYYY.MM.dd}"
      template_overwrite => true
    }
  }

}
eof
```

```powershell
# æµ‹è¯•
logstash
sudo -u logstash /usr/share/logstash/bin/logstash -r -f /etc/logstash/conf.d/redis-to-es.conf

# åœ¨ Nginx æœåŠ¡å™¨å°†åœ°ç†åæ ‡æ–‡ä»¶åˆ·åˆ°æ—¥å¿—æ–‡ä»¶ä¸­ï¼Œåœ¨ logstash ä¸­è§‚å¯Ÿï¼›
å¦‚æœåˆ·å…¥æ—¥å¿—æ•°æ®ä¸èƒ½ç”Ÿæ•ˆï¼Œåˆ™å°è¯•åˆ·å…¥å°‘é‡æ•°æ®
head -n20 nginx.access_json.log-20210421 > /var/log/nginx/access_json.log
cat nginx.access_json.log-20210421   > /var/log/nginx/access_json.log 


# æŸ¥çœ‹å¹¶æ·»åŠ  Kibana æ ·ä¾‹åœ°å›¾ ï¼ˆå…·ä½“æ“ä½œå¯è§è§†é¢‘æˆ–è€…è¯¾ä»¶ 6.3.7.1 ï¼‰
# ç”Ÿæˆç´¢å¼•æ¨¡æ¿ï¼Œå¤åˆ¶ä¸Šé¢ GET æŸ¥è¯¢ç´¢å¼•çš„ç»“æœä¸­mappingså¼€å§‹çš„è¡Œåˆ° settings è¡Œä¹‹å‰ç»“æŸ,å¹¶æœ€åå†åŠ ä¸€ä¸ª }
# å°† GET å¾—å‡ºçš„ mappings éƒ¨åˆ†å†…å®¹å¤åˆ¶åˆ° PUT æ¨¡æ¿ä¸­ï¼Œåªä¿®æ”¹"coordinates": { "type": "geo_point" } éƒ¨åˆ†
GET /nginx-access-2025.12.09
PUT /_template/template_nginx_accesslog
# å°† GET å†…å®¹æ›¿æ¢æ‰ PUT å†…å®¹åï¼Œå°†ä¿®æ”¹åçš„æ¨¡æ¿åœ¨å¼€å‘å·¥å…·çš„æ§åˆ¶å°è¾“å…¥ï¼Œæ‰§è¡Œ ok åˆ™åç»­è¦åˆ é™¤æ—§çš„ç´¢å¼•æ•°æ®,ä¸Šé¢ä¿®æ”¹æ‰èƒ½ç”Ÿæ•ˆï¼ˆå¿…é¡»ï¼‰

```



- é…ç½® Logstash è¯»å– Kafka æ—¥å¿—å‘é€åˆ° Elasticsearch ï¼ˆäºŒé€‰ä¸€ï¼‰

```powershell
cat > /etc/logstash/conf.d/kafka-to-es.conf <<'eof'
input {
  kafka {
    bootstrap_servers => "10.0.0.91:9092,10.0.0.92:9092,10.0.0.93:9092"
    topics => "filebeat-log"
    codec => "json"

    # group_id => "logstash"          # æ¶ˆè´¹è€…ç»„åç§°
    # consumer_threads => "3"         # å»ºè®®å’Œ kafka åˆ†åŒºæ•°ä¸€è‡´
    # topics_pattern => "nginx-.*"    # é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…topicï¼Œè€Œéç”¨ä¸Šé¢topics=>æŒ‡å®šå›ºå®šå€¼
  }
}

filter {
  if "nginx-access" in [tags] {
    geoip {
      source => "clientip"
      target => "geoip"
      add_field => ["[geoip][coordinates]", "%{[geoip][geo][location][lon]}"]
      add_field => ["[geoip][coordinates]", "%{[geoip][geo][location][lat]}"]
    }

    mutate {
      convert => ["[geoip][coordinates]", "float"]
    }
  }

  mutate {
    convert => ["upstreamtime", "float"]
  }
}

output {
  # stdout {}   # è°ƒè¯•ä½¿ç”¨

  if "nginx-access" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200"]
      index => "logstash-kafka-nginx-accesslog-%{+YYYY.MM.dd}"
    }
  }

  if "nginx-error" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200"]
      index => "logstash-kafka-nginx-errorlog-%{+YYYY.MM.dd}"
    }
  }

  if "syslog" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.201:9200"]
      index => "logstash-kafka-syslog-%{+YYYY.MM.dd}"
    }
  }
}
eof

# åœæ­¢æœåŠ¡ï¼Œä»¥ logstash ç”¨æˆ·åœ¨å‰å°å¯åŠ¨é…ç½®æ–‡ä»¶
systemctl  stop logstash.service
sudo -u logstash /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-to-es.conf -r
# åœ¨ filebeat æœåŠ¡æ‰€åœ¨çš„è®¾å¤‡è¿›è¡Œæ¨¡æ‹Ÿæ—¥å¿—æ•°æ®å˜æ›´ï¼Œç„¶ååœ¨ logstash æœåŠ¡å™¨è¿›è¡Œè§‚å¯Ÿ
mv mall_app.log  /var/log/mall_app.log 
# logstash æœåŠ¡å™¨æ”¶åˆ° filebeat æ”¶é›†çš„æ•°æ®ï¼Œæ•´ç†å¹¶å‘é€åˆ° ES ä¸­ï¼Œåœ¨ ES å¯è§†åŒ–å›¾å½¢ç•Œé¢ä¸­å¯ä»¥çœ‹åˆ°è¿™ä¸ªç´¢å¼•
mall-app-2025.12.09
```

```powershell
# 9.0.1 ä¸èƒ½ä»¥ root å¯åŠ¨ï¼Œè¿˜è¦æ±‚å¯¹ /usr/share/logstash/data æœ‰æƒé™ï¼›
chmod 777 /usr/share/logstash/data
chown logstash:logstash /etc/logstash/conf.d/kafka-to-es.conf
chown -R logstash: /usr/share/logstash/data
su - logstash -s /bin/bash
/usr/share/logstash/bin/logstash --path.settings /etc/logstash -t
/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-to-es.conf

systemctl status logstash.service
```

éªŒè¯ç»“æœ

```powershell
# Logstash å…ˆå¯åŠ¨è®¢é˜… kafkaï¼Œå†ç”Ÿæˆæ–°æ•°æ®æ‰èƒ½é‡‡é›†ï¼›åˆ©ç”¨ Kafka tool å·¥å…·æŸ¥çœ‹
```

##### ES é›†ç¾¤ 

> å‚è€ƒä¹‹å‰çš„é…ç½®



##### Kibana

###### å®‰è£…

```powershell
dpkg -i kibana-9.2.2-amd64.deb

grep -Ev "^[a-Z]" /etc/kibana/kibana.yml
# ç›‘å¬ç«¯å£,æ­¤ä¸ºé»˜è®¤å€¼,å¯ä¸åšä¿®æ”¹
server.port: 5601 
# ä¿®æ”¹æ­¤è¡Œçš„ç›‘å¬åœ°å€,é»˜è®¤ä¸ºlocalhostï¼Œå³ï¼š127.0.0.1:5601
server.host: "0.0.0.0" 
# ä¿®æ”¹æ­¤è¡Œ,æŒ‡å‘ESä»»æ„æœåŠ¡å™¨åœ°å€æˆ–å¤šä¸ªèŠ‚ç‚¹åœ°å€å®ç°å®¹é”™,é»˜è®¤ä¸ºlocalhost
elasticsearch.hosts: ["http://10.0.0.201:9200","http://10.0.0.202:9200","http://10.0.0.203:9200"]
# ä¿®æ”¹æ­¤è¡Œ,ä½¿ç”¨"zh-CN"æ˜¾ç¤ºä¸­æ–‡ç•Œé¢,é»˜è®¤è‹±æ–‡
i18n.locale: "zh-CN"  
# 8.Xç‰ˆæœ¬æ–°æ·»åŠ é…ç½®,é»˜è®¤è¢«æ³¨é‡Š,ä¼šæ˜¾ç¤ºä¸‹é¢æç¤º
server.publicBaseUrl: "http://kibana.duan.org"
```

å¯åŠ¨ Kibana æœåŠ¡å¹¶éªŒè¯

```powershell
# é»˜è®¤æ²¡æœ‰å¼€æœºè‡ªåŠ¨å¯åŠ¨ï¼Œéœ€è¦è‡ªè¡Œè®¾ç½®
systemctl start kibana ; systemctl status kibana
ss -ntlp |grep node && ps aux |grep node
# é»˜è®¤ä»¥kibanaç”¨æˆ·å¯åŠ¨æœåŠ¡
id kibana
```

åœ¨ ES èŠ‚ç‚¹ä¸Šç”Ÿæˆtoken

> **Kibana 8.X å¼€å¯ xpack.security åŠŸèƒ½è¿æ¥ES**
>
> **ä» 8.x å¼€å§‹ enrollment token å¿…é¡»ä¾èµ– `xpack.security`ï¼›å¦‚æœé…ç½®ä¸­è¿™ä¸ªå‚æ•°æ˜¯ false é‚£ä¹ˆ enrollment token ç›´æ¥ä¸å¯ç”¨**
>
> é›†ç¾¤èŠ‚ç‚¹éƒ½éœ€è¦åš `xpack.security.enabled: true` é…ç½®ï¼›

```powershell
# åœ¨ESèŠ‚ç‚¹ä¸Šç”Ÿæˆtoken
#/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token --scope kibana
eyJ2ZXIiOiI4LjE0LjAiLCJhZHIiOlsiMTAuMC4wLjEwMDo5MjAwIl0sImZnciI6IjdhMzIyMWRhNmFm
OWI1YzUzYzJiMjM3YjJiMjg3MzcwZTBlOGNiOTZkNmJlYjI4MzdkZDFkYzJlNTE4ZDU3OWUiLCJrZXki
OiJRVl90TUpFQkk4OFloVFdtVHFKTDptdmsxNXUtYVI1T3g4bzZ3ZTNYVGdBIn0=
# ä¿®æ”¹kibanaé…ç½®æ–‡ä»¶
grep -Ev "#|^$" /etc/kibana/kibana.yml
server.host: 0.0.0.0 #ä¿®æ”¹æ­¤è¡Œ
elasticsearch.hosts: ['https://10.0.0.201:9200'] # ä¿®æ”¹æ­¤è¡Œ,æŒ‡å‘ elasticsearch åœ°å€
logging.appenders.file.type: file
logging.appenders.file.fileName: /var/log/kibana/kibana.log
logging.appenders.file.layout.type: json
logging.root.appenders: [default, file]
pid.file: /run/kibana/kibana.pid
i18n.locale: zh-CN # ä¿®æ”¹æ­¤è¡Œ

# æµè§ˆå™¨è®¿é—®,å¡«å†™ä¸Šé¢çš„token		http://10.0.0.201:5601/

# åˆ©ç”¨ elasticsearch çš„ç”¨æˆ·å¯†ç ç™»å½•
```

> **Kibana 8.X ç¦ç”¨ xpack.security åŠŸèƒ½è¿æ¥ES**

```powershell
# æµè§ˆå™¨è®¿é—®ä¸‹é¢é“¾æ¥ 
http://10.0.0.200:5601
# åœ¨å·¦ä¾§çš„ä»»åŠ¡æ ä¸­æ‹›åˆ° å †æ ˆç›‘æµ‹ â€”â€” ä½¿ç”¨å†…éƒ¨æ”¶é›†è®¾ç½® â€”â€” æ‰“å¼€ Monitoring 
# æŸ¥çœ‹çŠ¶æ€
http://10.0.0.200:5601/status
```

###### ç®¡ç†ç´¢å¼•

```powershell
# è¿›å…¥æµè§ˆå™¨ http://10.0.0.200:5601 â€”â€” å·¦ä¾§ä»»åŠ¡æ  â€”â€” å¼€å‘å·¥å…· â€”â€” æ§åˆ¶å°ä¸‹çš„ Shell è¾“å…¥ï¼šGET _search  â€”â€” æ‰§è¡Œï¼›
# åˆ›å»ºç´¢å¼•å¹¶æ‰§è¡Œ
POST /index_wang/_doc/1
{
"username": "wang",
"age": 18,
"title": "cto"
}
# æŸ¥çœ‹ç´¢å¼•
GET /index_wang/_doc/1
```

###### åˆ›å»ºç´¢å¼•æ¨¡å¼

```powershell
# è¿›å…¥æµè§ˆå™¨ http://10.0.0.200:5601 â€”â€” å·¦ä¾§ä»»åŠ¡æ  â€”â€” Stack Management â€”â€” å·¦ä¾§ä»»åŠ¡æ çš„ æ•°æ®è§†å›¾ â€”â€” åˆ›å»ºæ•°æ®è§†å›¾ â€”â€”è‡ªå®šä¹‰åç§°å’Œæ¨¡å¼ â€”â€” ä¿å­˜
```

**æŸ¥çœ‹ç´¢å¼•**

```powershell
# è¿›å…¥æµè§ˆå™¨ http://10.0.0.200:5601 â€”â€” å·¦ä¾§ä»»åŠ¡æ  â€”â€” Discover 
```



#### æ¡ˆä¾‹äºŒ

- æ”¶é›†åº”ç”¨ç‰¹å®šæ ¼å¼çš„æ—¥å¿—è¾“å‡ºè‡³ Elasticsearch å¹¶åˆ©ç”¨ Kibana å±•ç¤º

##### Filebeat

> - **Filebeat é…ç½®æ–‡ä»¶ä¸­çš„ type** 
>   - **åœ¨ 8.X ä»¥å‰ç‰ˆæœ¬æ˜¯ï¼š- type: log**
>   - **åœ¨ 8.X ä»¥åç‰ˆæœ¬æ˜¯ï¼š- type: filestream**

```powershell
ls /var/log/mall_app.log
cp  /etc/filebeat/filebeat.yml /root/filebeat.yaml-nginx-logstash && rm -f /etc/filebeat/filebeat.yml
# ä¿®æ”¹ filebeat é…ç½®æ–‡ä»¶
cat > /etc/filebeat/filebeat.yml <<'eof'
filebeat.inputs:
  - type: filestream
    id: my-filestream-id-1
    enabled: true
    tags: ["mall"]
    paths:
      - /var/log/mall_app.log
    parsers:
      - ndjson:
          target: ""   # è§£æç»“æœå­˜æ”¾åœ¨æŒ‡å®šå­—æ®µä¸‹ï¼Œå¦‚æœä¸ºç©ºåˆ™ä¿å­˜åœ¨æ ¹ä¸‹
          # message_key: message  # å¯¹å“ªä¸ªå­—æ®µåš json è§£æï¼Œå¯é€‰

output.logstash:
  hosts: ["10.0.0.100:5044"]
  indes: filebeat
  loadbalance: true
  worker: 1
  compression_level: 3
eof

systemctl  restart filebeat
```

##### Logstash

```powershell
mv   /etc/logstash/conf.d/  /root/
# åˆ›å»ºé…ç½®æ–‡ä»¶
cat /etc/logstash/conf.d/app_filebeat_filter_es.conf
input {
  beats {
    port => 5044
  }
}

filter {
  # mutate åˆ‡å‰²æ“ä½œ
  mutate {
    # å­—æ®µåˆ†éš”ç¬¦
    split => { "message" => "|" }

    # æ·»åŠ å­—æ®µ
    add_field => {
      "user_id" => "%{[message][1]}"
      "action"  => "%{[message][2]}"
      "time"    => "%{[message][3]}"
      # "[@metadata][target_index]" => "mall-app-%{+YYYY.MM.dd}"
    }

    # åˆ é™¤æ— ç”¨å­—æ®µ
    remove_field => ["message"]

    # å¯¹æ–°æ·»åŠ å­—æ®µè¿›è¡Œæ ¼å¼è½¬æ¢
    convert => {
      "user_id" => "integer"
      "action"  => "string"
      "time"    => "string"
    }
  }

  date {
    # è¦†ç›–åŸæ¥çš„ @timestamp æ—¶é—´å­—æ®µ
    match   => ["time", "yyyy-MM-dd HH:mm:ss"]
    target  => "@timestamp"
    timezone => "Asia/Shanghai"
  }
}

output {
  stdout {
    codec => rubydebug
  }

  elasticsearch {
    hosts => [
      "10.0.0.201:9200",
      "10.0.0.202:9200",
      "10.0.0.203:9200"
    ]
    index => "mall-app-%{+YYYY.MM.dd}"
    # index => "%{[@metadata][target_index]}"
    template_overwrite => true
  }
}


# åœæ­¢æœåŠ¡ï¼Œä»¥ logstash ç”¨æˆ·åœ¨å‰å°å¯åŠ¨é…ç½®æ–‡ä»¶
systemctl  stop logstash.service
sudo -u logstash /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/app_filebeat_filter_es.conf -r
# åœ¨ filebeat æœåŠ¡æ‰€åœ¨çš„è®¾å¤‡è¿›è¡Œæ¨¡æ‹Ÿæ—¥å¿—æ•°æ®å˜æ›´ï¼Œç„¶ååœ¨ logstash æœåŠ¡å™¨è¿›è¡Œè§‚å¯Ÿ
mv mall_app.log  /var/log/mall_app.log 
# logstash æœåŠ¡å™¨æ”¶åˆ° filebeat æ”¶é›†çš„æ•°æ®ï¼Œæ•´ç†å¹¶å‘é€åˆ° ES ä¸­ï¼Œåœ¨ ES å¯è§†åŒ–å›¾å½¢ç•Œé¢ä¸­å¯ä»¥çœ‹åˆ°è¿™ä¸ªç´¢å¼•
mall-app-2025.12.09
```

##### Kibana åˆ›å»ºç´¢å¼•æ¨¡å¼

```powershell
# åˆ›å»ºæ•°æ®è§†å›¾ â€”â€” discover â€”â€” å°±å¯ä»¥çœ‹åˆ°åˆšåˆšåˆ›å»ºçš„æ•°æ®è§†å›¾
# å¯¹æ•°æ®ä¸­çš„æ ‡ç­¾è¿›è¡Œè¿‡æ»¤é‡ç»„ï¼Œä½¿å…¶å¯è§†åŒ–ï¼Œè¿›å…¥ Visualize åº“ â€”â€” æ–°å»ºå¯è§†åŒ– â€”â€” ï¼ˆæ—§ç‰ˆï¼‰-èšåˆ â€”â€” å‚ç›´è§†å›¾ ï¼ˆå¯é€‰ï¼‰â€”â€” åˆ†æ¡¶ â€”â€” X â€”â€” è¯ â€”â€” é€‰æ‹©å­—æ®µ
```

![image-20251209163240962](C:\Program Files\Obsidian\data\Obsidian_Vault\image-20251209163240962.png)

![image-20251209164316010](C:\Program Files\Obsidian\data\Obsidian_Vault\image-20251209164316010.png)

![image-20251209164500979](C:\Program Files\Obsidian\data\Obsidian_Vault\image-20251209164500979.png)

![image-20251209172502099](C:\Program Files\Obsidian\data\Obsidian_Vault\image-20251209172502099.png)

##### Nginx

```powershell
# Kibana å¯è§†åŒ–å›¾è¡¨åšå¥½åï¼Œå¤åˆ¶ä¸Šé¢åµŒå…¥å¼é“¾æ¥ï¼›
# åœ¨ Nginx ä¸­æ–°å»ºæ–‡ä»¶ï¼Œå°†é“¾æ¥å¤åˆ¶è¿›å…¥ï¼Œå¹¶åšä¸€ç‚¹å°ºå¯¸å±•ç¤ºçš„è°ƒæ•´ï¼›
echo "<iframe src="http://10.0.0.200:5601/app/r/s/0et65" height="1600" width="1800"></iframe>" >> /var/www/html/index.html
# è®¿é—® Nginx ç½‘é¡µï¼Œå°±å¯ä»¥çœ‹åˆ° Kibana åšå¥½çš„å¯è§†åŒ–å›¾è¡¨
```




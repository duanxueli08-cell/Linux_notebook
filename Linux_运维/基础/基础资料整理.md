端口号和状态码这块的笔记还需要打磨一下！



## 常用指令

| 工具                   | 在运维的经典用途                         |
| ---------------------- | ---------------------------------------- |
| **sort**               | 排序（CPU、内存、磁盘、日志重复）        |
| **xargs**              | 批量执行命令（rm、kill、ping、grep、cp） |
| **sort + uniq + sort** | 统计次数（IP、错误日志）                 |
| **find + xargs**       | 批量操作文件                             |
| **awk + sort + xargs** | 实际生产排障组合拳                       |

查找最多的错误关键词
grep "ERROR" app.log | sort | uniq -c | sort -nr | head



```powershell
# 导出/导入镜像（离线迁移）
docker save -o [文件名].tar [镜像名]:[标签]
docker load -i [文件名].tar
# 为镜像打上名称和标签
docker tag 63eaf6028b7b jumpserver:v4.10.12
# 查看文件数量，以及文件中有多少行
root@ubuntu2404-203:~# find RuoYi/  -name  "*.java" | wc -l
271
root@ubuntu2404-203:~# find RuoYi/  -name  "*.java" | xargs cat | wc -l
35992
# 显示当前用户的所有资源限制;
ulimit -a 
# 对于传统方式（绝对路径启动关闭）编辑limits.conf
tail -n2 /etc/security/limits.conf 
root soft nofile 66666
root hard nofile 66666
# 对于主流方式（systemctl启动关闭）编辑ruoyi.service文件
cat /lib/systemd/system/ruoyi.service  | grep LimitNOFILE
LimitNOFILE=10000
# 查看服务进程优化数据（根据进程id查询）
ss -tunlp 
cat /proc/1129/limits
# harbor登陆
docker login harbor.wang.org -u magedu -p Magedu123
```

镜像打包

```powershell
前言：
	将主机A中的镜像打包传给主机B ；主机B加载镜像包
方法一：
# 打包镜像为 tar 文件
docker save -o jumpserver-v4.10.12.tar 63eaf6028b7b
# 查看打包的文件
ls -lh jumpserver-v4.10.12.tar
# 传输文件到目标主机
scp jumpserver-v4.10.12.tar 10.0.0.201:/root
# 在目标主机上加载镜像
docker load -i jumpserver-v4.10.12.tar
# 验证镜像
docker images | grep jumpserver
# 为镜像打上名称和标签
docker tag 63eaf6028b7b jumpserver:v4.10.12
——————分割线——————
方法二：
# 打包并压缩
docker save jumpserver/jms_all:v4.10.12 | gzip > jumpserver-v4.10.12.tar.gz
#　传输压缩文件
scp jumpserver-v4.10.12.tar.gz user@target-host:/path/
# 在目标主机加载（也可以先解压再加载）
docker load -i jumpserver-v4.10.12.tar.gz
# 检查镜像ID是否一致
docker images --no-trunc | grep 63eaf6028b7b
——————分割线——————
# vim编辑器中查看隐藏字符
:set list
```

离线下载安装软件包（了解）

```powershell
# 在 A 主机上先下载但不安装
apt download maven
# 拷贝 deb 包到 B 主机
scp maven_3.8.7-2_all.deb  10.0.0.200:/root/
# 在 B 主机上安装
dpkg -i maven_3.8.7-2_all.deb
# 如果出现依赖问题，运行以下命令修复
sudo apt-get install -f
# 检查 Maven 版本
mvn -version
# 检查安装路径
which mvn
```



## SSH 免密认证

**生成密钥**

```
ssh-keygen -t rsa

# 密钥文件默认存放中在：/用户/.ssh/
```

**批量传送自己的公钥**

```
for host in 10.0.0.{147,200,100,101,102}; do
    ssh-copy-id -i /root/.ssh/id_rsa.pub -o StrictHostKeyChecking=no root@$host
done

# 禁用首次连接时的 Host Key 检查：-o StrictHostKeyChecking=no
```

**测试免密连接**

```
ssh root@10.0.0.200

# 直接登录，无需输入密码和确认 
```



## 理论概念

> 事物的四大特性 ACID

首先，**原子性（Atomicity）**。我的理解是，它强调的是事务的“**整体性**”。一个事务里的所有操作，就像化学里的原子一样，是不可分割的整体。要么全部成功，要么全部失败回滚，没有中间状态。这在实际业务中至关重要，比如银行转账，必须保证“扣款”和“收款”作为一个整体，要么都做，要么都不做，绝对不会发生只扣钱不收款这种严重错误。数据库通常通过**回滚日志**来实现这一点。

第二，**一致性（Consistency）**。这个特性其实比较“宽泛”，它强调的是事务执行前后，数据库必须从一个**合法的状态**变到另一个**合法的状态**。这里的“合法”包含几层意思：一是数据本身的正确性，比如转账前后两个账户的总金额应该不变；二是要遵守所有预设的规则，比如主键、外键约束、字段类型、业务逻辑等。一致性是事务的**根本目的**，而原子性、隔离性、持久性其实都是实现一致性的手段。

第三，**隔离性（Isolation）**。这是针对**多个事务并发执行**的场景。它的目标是让每个事务都感觉不到有其他事务在同时执行，就像它是独占数据库一样。如果没有隔离性，就会出现经典的并发问题：**脏读**（读到别人没提交的数据）、**不可重复读**（两次读取同一数据结果不一样）、**幻读**（查询到的记录数发生变化）。为了平衡性能和隔离程度，SQL标准定义了四种隔离级别，从低到高是：读未提交、读已提交、可重复读、串行化。像MySQL的InnoDB引擎，默认使用**可重复读**级别，并且通过**MVCC（多版本并发控制）** 机制来实现，能在高并发下提供很好的性能。

最后，**持久性（Durability）**。这个特性解决的是系统**持久存储**的问题。一旦事务成功提交，它对数据的修改就是永久的，即使之后数据库发生崩溃、断电，重启后数据也不会丢失。这个特性是通过**重做日志**和**预写式日志**等技术来保证的。简单说，就是在数据实际写入磁盘前，先把要做的修改记录到日志里。这样即使中途崩溃，重启后也能根据日志把没做完的事务重新执行一遍，从而保证了提交后的修改不丢失。



| 类型    | 访问方式         | 协议         | 场景                             | 类比               |
| ------- | ---------------- | ------------ | -------------------------------- | ------------------ |
| **DAS** | 本地直连（块）   | SATA/SAS/USB | 单机                             | “本地硬盘”         |
| **NAS** | 网络访问（文件） | SMB/NFS      | 局域网（文件共享）               | “共享文件夹服务器” |
| **SAN** | 专用网络（块）   | FC / iSCSI   | 企业核心业务<br>（专用光纤网络） | “远程高性能硬盘”   |

| **特点**     | **存储桶 (Bucket)**                                          | **传统文件系统（顶级文件夹）**                              |
| ------------ | ------------------------------------------------------------ | ----------------------------------------------------------- |
| **层级结构** | **扁平结构：** Bucket 内部没有真实的文件夹层级，所有对象都是平级的。 | **树状结构：** 文件夹内部可以嵌套更多文件夹，形成深度层级。 |
| **管理策略** | **面向策略：** 权限、地域、版本控制等策略是针对整个 Bucket 设置的。 | **面向目录：** 权限可以精确到每个文件夹或文件。             |
| **访问方式** | 通过 **HTTP/S API 和唯一的 URL** 访问。                      | 通过文件路径和网络共享协议（如 SMB/NFS）访问。              |
| **容量限制** | 理论上**无限**。                                             | 受限于物理磁盘或文件系统（如 ext4, NTFS）的大小限制。       |

相比块存储，对象存储的成本通常更低，适合存储不常变动的冷数据或备份。
数据不再放在传统的文件夹目录中，而是放在一个巨大的扁平的地址空间 （存储桶）

对象存储，每个对象包含如下三个部分：

- 数据：实际存放数据（比如：图片、视频等）
- 键值：数据全局唯一标识符；
- 元数据：数据对象的描述信息（比如创建日期、类型等）

过去常用 **NFS** 或 **NAS**，但随着服务增多、容器化普及：

- 共享文件系统易锁死

- 单点问题严重

- 性能差、扩展差

MinIO 刚好解决这些痛点：

✓ 避免文件系统锁问题  
✓ S3 API 天生适合微服务  
✓ 多服务并发访问无压力  
✓ 容器环境极其友好（K8s 推荐方案）







## 共享数据

为了保持清晰，我们将设定：

- **服务器 (Server)：** `10.0.0.100` (作为数据源、NFS 共享方)

- **客户端 (Client)：** `10.0.0.200` (作为数据接收方、NFS 挂载方)

---

### 1. NFS 服务器 (10.0.0.100) 配置

**步骤 1: 安装与创建共享目录**

```
# 安装 NFS 服务器端软件包
sudo apt update
sudo apt install nfs-kernel-server -y

# 创建用于共享的目录
sudo mkdir -p /nfs_share
sudo chown nobody:nogroup /nfs_share
sudo chmod 777 /nfs_share
```

**步骤 2: 配置共享权限**

编辑 `/etc/exports` 文件，添加共享目录及其权限。

```
sudo vim /etc/exports
```

**添加以下行：**

```
/nfs_share    10.0.0.200(rw,sync,no_subtree_check)
```

- `10.0.0.200`：只允许客户端 IP 访问。

- `rw`：读写权限。

- `sync`：同步写入，数据立即写入磁盘。

**步骤 3: 导出共享并启动服务**

```
# 导出配置的共享目录
sudo exportfs -a

# 确保 NFS 服务启动并启用
sudo systemctl enable nfs-server
sudo systemctl start nfs-server
```

### 2. 💻 NFS 客户端 (10.0.0.200) 配置

**步骤 1: 安装客户端软件包**

```
# 安装 NFS 客户端软件包
sudo apt update
sudo apt install nfs-common -y

# 创建本地挂载点
sudo mkdir -p /mnt/nfs_remote
```

**步骤 2: 挂载远程共享**

Bash

```
# 挂载服务器的共享目录
sudo mount 10.0.0.100:/nfs_share /mnt/nfs_remote
```

**步骤 3: 示例验证**

在客户端上进行操作：

```
# 在客户端 (10.0.0.200) 写入文件
echo "This is a test file from the client." | sudo tee /mnt/nfs_remote/client_test.txt
```

在服务器 (`10.0.0.100`) 上查看：

```
# 在服务器端 (10.0.0.100) 查看文件
cat /nfs_share/client_test.txt
# 输出: This is a test file from the client.
```

**结论：** 客户端已成功读写服务器上的文件。

---

### II. Rsync (Remote Sync) 使用示例

Rsync 是一种高效的文件传输和同步工具，它只传输文件有变化的部分。通常用于单向、计划性的数据备份或同步。

#### 1. Rsync 服务器 (10.0.0.100) 配置

Rsync 默认通过 SSH 传输，**不需要额外的 Rsync 服务配置**，只需确保 SSH 服务运行即可。

准备同步目录

```
# 创建源数据目录
mkdir -p /data_source
echo "Initial data." > /data_source/file1.txt
```

#### 2. 💻 Rsync 客户端 (10.0.0.200) 执行同步

##### 示例: 从服务器拉取数据 (Pull)

**目标：** 将服务器 `/data_source` 目录的内容同步到客户端 `/data_target`。

```
# 客户端 (10.0.0.200) 创建目标目录
mkdir -p /data_target

# 执行 rsync 命令（通过 SSH 协议）
# -a：归档模式 (保持权限、时间戳等)
# -v：详细输出
# --delete：删除目标目录中源目录没有的文件
rsync -av --delete user@10.0.0.100:/data_source/ /data_target/

# 验证客户端文件
ls /data_target/
cat /data_target/file1.txt
```

**结论：** 客户端成功从服务器同步了文件。

---

### III. Sersync (Inotify + Rsync) 使用示例

Sersync 是一个基于 Linux **inotify** 机制的实时同步工具。它监控本地目录的事件（创建、修改、删除等），然后立即触发 Rsync 命令将更改推送到远程服务器。

#### 1. Sersync 服务器 (10.0.0.100) 配置

Sersync 在数据源端运行，负责监控和推送。

**步骤 1: 安装 Sersync (通常需要手动编译或下载预编译包)**

​	假设您已从 GitHub 下载并安装了 Sersync 的二进制文件，并将其放在 `/usr/local/sersync/` 目录下。

**步骤 2: 配置 Rsync 目标（目标服务器需要运行 Rsync Daemon 或使用 SSH）**

​	为了简化，我们继续使用 SSH 方式。确保服务器 `10.0.0.100` 可以免密 SSH 登录到 `10.0.0.200`（即设置 SSH 密钥）。

**步骤 3: 配置 Sersync XML 文件**

​	创建或编辑 Sersync 的配置文件 `/usr/local/sersync/conf/confxml.xml`：

```
<?xml version="1.0" encoding="utf-8"?>
<root>
    <conf>
        <localpath watch="/sersync_source">  <remotehost>
                <host name="10.0.0.200"/>   </remotehost>
        </localpath>
        <rsync>
            <path>/sersync_target</path>     <args>-avz --delete</args>      <auth start="false"/>           <user>user</user>               </rsync>
        <monitor>
            <interval>1</interval>          <blockduration>5</blockduration> </monitor>
    </conf>
</root>
```

步骤 4: 启动 Sersync 监控

```
# 准备监控目录
mkdir -p /sersync_source

# 启动 sersync (使用后台运行和配置文件)
/usr/local/sersync/bin/sersync -d -r -o /usr/local/sersync/conf/confxml.xml
```

#### 2. 💻 Sersync 客户端 (10.0.0.200) 准备

客户端只需要准备接收目录。

Bash

```
# 客户端 (10.0.0.200) 创建目标接收目录
mkdir -p /sersync_target
```

##### 示例: 实时同步验证

在服务器 (`10.0.0.100`) 上的被监控目录 `/sersync_source` 进行操作：

Bash

```
# 服务器 (10.0.0.100) 写入文件
echo "Real-time sync test." > /sersync_source/test_realtime.log

# 几秒后，检查客户端 (10.0.0.200) 的目标目录
ls /sersync_target/
cat /sersync_target/test_realtime.log
# 输出: Real-time sync test.
```

**结论：** Sersync 成功捕获文件创建事件，并实时通过 Rsync 推送到了客户端。



## Shell 编程笔记

- ### shell编程


##### if

> **嵌套 if**：条件之间是 **逐级递进、层层限制** 的关系。
>
> **if 里嵌套 elif**：在某个条件成立的前提下，进行 **多分支互斥选择**。

```powershell
if [ "$周树人" = "$鲁迅" ]; then
	echo "对，是我说的！"
	if [ "$鲁达" = "$周树人" ]; then
		echo "可以把周树人抓起来了"
	else
		echo "把鲁迅抓起来！"
	fi
elif [ "$鲁迅" = "$周迅" ]; then
	echo "抓捕周迅"
	if [ "$周迅" = "star" ]; then
		echo "将错就错"
	else
		echo "放人"
	fi
else
	echo "这不是我说的"
fi

		
if [[ "$OS" =~ ^(rocky|centos|rhel)$ ]]
[[ ... ]]
	• 这是 Bash 的高级条件测试，比 [ ... ] 功能更强。
	• 支持正则匹配、模式匹配等。
=~
	• 表示 正则表达式匹配。
	• 左边是字符串，右边是正则表达式。
如果字符串满足正则，条件为真（true），否则为假（false）


```

##### case

> **if**：适合做逻辑判断（大于/小于/组合条件）
>
> **case**：适合做 **等值匹配、模式匹配**，特别是对字符串匹配更直观

```powershell
case 变量 in
    模式1)
        命令1
        ;;
    模式2)
        命令2
        ;;
    模式3|模式4)   # 多个模式用 | 隔开
        命令3
        ;;
    *)
        默认命令    # 相当于 else
        ;;
esac

case … esac 是成对出现的（注意：esac 就是 case 倒过来）
每个模式后面跟 )
分支语句最后必须以 ;; 结束
* 表示默认匹配（类似 else）

```

##### for

```powershell
1. 列表循环（最常见）
for 变量 in 值1 值2 值3 ... 值N
do
    命令
done
# 变量 会依次取列表中的每个值
# 常用于遍历字符串、文件名、命令结果
******************
```

```powershell
2. 遍历命令结果
可以结合命令替换 `command` 或 $(command)：
for file in $(ls /etc/*.conf)
do
    echo "找到配置文件: $file"
done
******************
```

```powershell
3. C 风格 for（和 C 语言一样）
for (( 初始化; 条件; 递增 ))
do
    命令
done

示例：
for ((i=1; i<=5; i++))
do
    echo "第 $i 次循环"
done
```



##### 表达式

```powershell
[ ]：条件判断（字符串、数字比较等）。[]中的条件需要左右有空格，且不能省略。
-f：	检查文件是否存在且为普通文件。
-d：	检查文件是否存在且为目录。
=：	字符串相等。
-eq：数字相等。
-gt：数字大于。
-lt：数字小于。

{} 用来组织命令、进行范围扩展，或者表示函数体、控制结构等。
命令之间必须用分号 ; 分隔，或者换行。
{} 内的命令会在同一个 shell 环境下执行，不产生子进程。

[[]] 是 扩展的条件测试，提供比 [] 更强大的功能。
[[]] 是 Bash 和其他现代 shell 特有的扩展（非 POSIX 标准）。
[[]] 中不需要对某些特殊字符（如 <、>）进行转义，[] 中需要转义。
字符串比较：可以使用 == 和 !=，且支持通配符。
正则表达式：可以使用 =~ 进行正则匹配。
逻辑运算符：可以直接使用 && 和 || 进行多个条件的判断。


解释2>&1 &
2>&1
👉 把 标准错误输出 (stderr) 重定向到 标准输出 (stdout) 的位置。
效果：stdout 和 stderr 会合并。
再看 &
👉 把命令放到 后台运行。
后台进程会得到一个 作业号 (job id) 和 进程号 (PID)。
```

##### 函数

**封装代码块**，实现**功能复用**和组织

###### 示例一

```postgresql
#!/bin/bash
# 日志备份脚本
# 执行脚本后，会将 /var/log 目录下的 .log 文件打包成一个带时间戳的压缩包，存放在 /tmp 目录下。
# 定义函数：实现备份
backup_logs() {
    src_dir=$1      # 源目录
    dst_dir=$2      # 目标目录
    timestamp=$(date +"%Y%m%d_%H%M%S")

    # 检查源目录是否存在
    if [ ! -d "$src_dir" ]; then
        echo "源目录不存在: $src_dir"
        return 1	# 如果源目录不存在，函数返回1，后续的命令不会执行
    fi

    # 创建目标目录
    mkdir -p "$dst_dir"

    # 打包备份
    tar -czf "$dst_dir/logs_backup_$timestamp.tar.gz" "$src_dir"/*.log 2>/dev/null

    if [ $? -eq 0 ]; then
        echo "✅ 备份成功: $dst_dir/logs_backup_$timestamp.tar.gz"
    else
        echo "❌ 备份失败"
    fi
}

# 调用函数
backup_logs "/var/log" "/tmp"

```

##### expect自动化

```powershell
set 设定环境变量
	格式：set 变量名 变量值
send 接收一个字符串参数，并将该参数发送到新进程。
	样式：send "$password\r"
expect 识别用户输入的位置关键字
	格式：expect "yes"
spawn 启动新的进程，模拟手工在命令行启动服务
	样式：spawn ssh python@$host
	


```

##### 颜色

```powershell
前景色（文本颜色）	
颜色	代码
黑色	30		白色	37
红色	31		绿色	32
黄色	33		蓝色	34
紫色	35		青色	36
默认	0

PS1='\[\e[31m\]\u@\h\w:$\[\e[0m\]'
```



##### 变量

```powershell
 变量格式：
本地变量：变量名=变量值
全局变量：export		变量名=变量值
局部变量：local      变量名=变量值
普通变量：变量名="字符串"
命令变量：
	定义一：变量名=$(命令)       #建议用这个
	定义二：变量名=`变量名`      #注意这是反引号
	
查看所有的全局变量：env    |   grep   变量名
删除变量：unset   变量名

TOOLS=("net-tools" "vim" "curl" "wget" "git")
这是 Bash 的数组变量定义，不是普通字符串变量。
• 在 Bash 里，圆括号 () 表示创建一个数组。
• 数组里的元素用 空格 分隔。
给元素加上双引号，保证字符串里即使有空格，也会被当成一个整体。
```




 å¥½çš„ï¼ä»¥ä¸‹æ˜¯ä¸€ä»½**ä¸“ä¸º Kubernetes åˆå­¦è€…è®¾è®¡çš„ã€æ›´è¯¦ç»†ã€æ›´æ·±å…¥ã€æ›´æ˜“ç†è§£çš„ K8s è°ƒåº¦æœºåˆ¶ç¬”è®°**ã€‚åœ¨ä¿ç•™åŸæœ‰ç»“æ„çš„åŸºç¡€ä¸Šï¼Œæˆ‘å¯¹å…³é”®æ¦‚å¿µï¼ˆå¦‚ `maxSkew`ã€äº²å’Œæ€§é€»è¾‘ã€è°ƒåº¦æµç¨‹ç­‰ï¼‰è¿›è¡Œäº†**åŸç†çº§è§£é‡Š + å…¬å¼/è®¡ç®—ç¤ºä¾‹ + åœºæ™¯è¯´æ˜**ï¼Œç¡®ä¿åˆå­¦è€…ä¸ä»…èƒ½â€œçŸ¥é“æ˜¯ä»€ä¹ˆâ€ï¼Œè¿˜èƒ½â€œç†è§£ä¸ºä»€ä¹ˆâ€å’Œâ€œæ€ä¹ˆç”¨â€ã€‚

---

# **Kubernetes è°ƒåº¦æœºåˆ¶è¯¦è§£ï¼ˆåˆå­¦è€…å‹å¥½ç‰ˆï¼‰**

> æœ¬ç¬”è®°é¢å‘åˆšæ¥è§¦ Kubernetes çš„å¼€å‘è€…æˆ–è¿ç»´äººå‘˜ï¼Œç³»ç»Ÿè®²è§£ Pod æ˜¯å¦‚ä½•è¢«åˆ†é…åˆ°èŠ‚ç‚¹ä¸Šçš„ï¼Œæ¶µç›–è°ƒåº¦å™¨å·¥ä½œåŸç†ã€æ ¸å¿ƒç­–ç•¥é…ç½®åŠå®é™…ä½¿ç”¨æŠ€å·§ã€‚

---

## **1. Pod è°ƒåº¦æ¡†æ¶**

### **1.1 è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰æ˜¯ä»€ä¹ˆï¼Ÿ**
- Kubernetes ä¸­è´Ÿè´£å°† **æœªç»‘å®šçš„ Pod** åˆ†é…åˆ°åˆé€‚ **Node** ä¸Šè¿è¡Œçš„æ§åˆ¶å¹³é¢ç»„ä»¶ã€‚
- é»˜è®¤è°ƒåº¦å™¨åä¸º `default-scheduler`ã€‚
- å®ƒ**ä¸è´Ÿè´£å¯åŠ¨å®¹å™¨**ï¼Œåªè´Ÿè´£â€œå†³å®šåœ¨å“ªé‡Œè¿è¡Œâ€ã€‚

### **1.2 è°ƒåº¦çš„åŸºæœ¬æµç¨‹ï¼ˆä¸‰æ­¥èµ°ï¼‰**

1. **Filteringï¼ˆè¿‡æ»¤ï¼‰**  
   - åˆå« **Predicatesï¼ˆé¢„é€‰ï¼‰**ã€‚
   - æ’é™¤æ‰€æœ‰**ä¸ç¬¦åˆæ¡ä»¶**çš„èŠ‚ç‚¹ï¼ˆå¦‚èµ„æºä¸è¶³ã€æ ‡ç­¾ä¸åŒ¹é…ç­‰ï¼‰ã€‚
   - è¾“å‡ºï¼šå€™é€‰èŠ‚ç‚¹åˆ—è¡¨ï¼ˆCandidate Nodesï¼‰ã€‚

2. **Scoringï¼ˆæ‰“åˆ†ï¼‰**  
   - åˆå« **Prioritiesï¼ˆä¼˜é€‰ï¼‰**ã€‚
   - å¯¹å€™é€‰èŠ‚ç‚¹æŒ‰â€œé€‚åˆç¨‹åº¦â€æ‰“åˆ†ï¼ˆ0~10 åˆ†ï¼‰ï¼Œåˆ†æ•°è¶Šé«˜è¶Šä¼˜å…ˆã€‚
   - å¸¸è§æ‰“åˆ†é¡¹ï¼šèµ„æºå‰©ä½™å¤šã€å·²æœ‰é•œåƒã€äº²å’Œæ€§åŒ¹é…ç­‰ã€‚

3. **Bindingï¼ˆç»‘å®šï¼‰**  
   - å°† Pod ä¸é€‰å®šçš„ Node ç»‘å®šï¼ˆå†™å…¥ etcdï¼‰ã€‚
   - kubelet ç›‘å¬åˆ°åï¼Œå¼€å§‹æ‹‰å–é•œåƒå¹¶å¯åŠ¨å®¹å™¨ã€‚

> âœ… **ç±»æ¯”ç†è§£**ï¼šå°±åƒä½ æ‰¾å·¥ä½œâ€”â€”å…ˆç­›æ‰ä¸ç¬¦åˆå­¦å†è¦æ±‚çš„å…¬å¸ï¼ˆFilteringï¼‰ï¼Œå†ç»™å‰©ä¸‹çš„å…¬å¸æŒ‰è–ªèµ„ã€é€šå‹¤æ‰“åˆ†ï¼ˆScoringï¼‰ï¼Œæœ€åç­¾ offerï¼ˆBindingï¼‰ã€‚

---

## **2. æ ¸å¿ƒè°ƒåº¦ç­–ç•¥è¯¦è§£**

### **2.1 nodeSelectorï¼ˆæœ€ç®€å•çš„èŠ‚ç‚¹é€‰æ‹©ï¼‰**

```yaml
spec:
  nodeSelector:
    disktype: ssd
```

- **ä½œç”¨**ï¼šPod åªèƒ½è°ƒåº¦åˆ°å¸¦æœ‰ `disktype=ssd` æ ‡ç­¾çš„èŠ‚ç‚¹ã€‚
- **ç¼ºç‚¹**ï¼šåªèƒ½åšâ€œç­‰äºâ€åˆ¤æ–­ï¼Œä¸èƒ½åšâ€œæˆ–â€ã€â€œä¸ç­‰äºâ€ç­‰å¤æ‚é€»è¾‘ã€‚
- **é€‚ç”¨åœºæ™¯**ï¼šç®€å•ç¯å¢ƒéš”ç¦»ï¼ˆå¦‚æµ‹è¯•/ç”Ÿäº§ï¼‰ã€‚

---

### **2.2 èŠ‚ç‚¹äº²å’Œæ€§ï¼ˆnodeAffinityï¼‰â€”â€” æ›´å¼ºå¤§çš„ nodeSelector**

#### **ä¸¤ç§ç±»å‹ï¼š**

| ç±»å‹                                              | è¡Œä¸º   | æ˜¯å¦å¿…é¡»æ»¡è¶³                      |
| ------------------------------------------------- | ------ | --------------------------------- |
| `requiredDuringSchedulingIgnoredDuringExecution`  | ç¡¬äº²å’Œ | âœ… å¿…é¡»æ»¡è¶³ï¼Œå¦åˆ™ Pod ä¸€ç›´ Pending |
| `preferredDuringSchedulingIgnoredDuringExecution` | è½¯äº²å’Œ | âŒ ä¸æ»¡è¶³ä¹Ÿå¯è°ƒåº¦ï¼Œä½†ä¼šå°½é‡æ»¡è¶³    |

#### **æ“ä½œç¬¦ï¼ˆoperatorï¼‰æ”¯æŒï¼š**
- `In`, `NotIn`, `Exists`, `DoesNotExist`, `Gt`, `Lt`

#### **ç¤ºä¾‹ï¼šç¡¬äº²å’Œ + è½¯äº²å’Œç»„åˆ**
```yaml
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/os
          operator: In
          values: ["linux"]
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 50
      preference:
        matchExpressions:
        - key: zone
          operator: In
          values: ["us-east-1a"]
```
- **è§£é‡Š**ï¼š
  - å¿…é¡»è¿è¡Œåœ¨ Linux èŠ‚ç‚¹ä¸Šï¼ˆç¡¬æ€§è¦æ±‚ï¼‰ã€‚
  - å¦‚æœå¯èƒ½ï¼Œä¼˜å…ˆé€‰æ‹© `us-east-1a` åŒºåŸŸçš„èŠ‚ç‚¹ï¼ˆè½¯æ€§åå¥½ï¼Œæƒé‡ 50ï¼‰ã€‚

> ğŸ’¡ **weight èŒƒå›´æ˜¯ 1~100**ï¼Œæ•°å€¼è¶Šå¤§ï¼Œè°ƒåº¦å™¨è¶Šå€¾å‘äºé€‰æ‹©è¯¥èŠ‚ç‚¹ã€‚

---

### **2.3 Pod äº²å’Œæ€§ä¸åäº²å’Œæ€§ï¼ˆpodAffinity / podAntiAffinityï¼‰**

#### **ç”¨é€”**
- **äº²å’Œæ€§**ï¼šè®©ä¸¤ä¸ª Pod å°½é‡åœ¨ä¸€èµ·ï¼ˆå¦‚åŒä¸€æœºæˆ¿ã€åŒä¸€ä¸»æœºï¼‰ã€‚
- **åäº²å’Œæ€§**ï¼šè®©ä¸¤ä¸ª Pod å°½é‡åˆ†å¼€ï¼ˆæé«˜å®¹ç¾èƒ½åŠ›ï¼‰ã€‚

#### **å…³é”®å­—æ®µï¼štopologyKey**
- å®šä¹‰â€œåœ¨ä¸€èµ·â€çš„èŒƒå›´ã€‚
- å¸¸è§å€¼ï¼š
  - `kubernetes.io/hostname` â†’ åŒä¸€ç‰©ç†æœº
  - `topology.kubernetes.io/zone` â†’ åŒä¸€å¯ç”¨åŒº
  - `topology.kubernetes.io/region` â†’ åŒä¸€åœ°åŸŸ

#### **ç¤ºä¾‹ï¼šé¿å…å¤šä¸ª Web Pod åœ¨åŒä¸€èŠ‚ç‚¹ï¼ˆåäº²å’Œï¼‰**
```yaml
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchLabels:
          app: web
      topologyKey: kubernetes.io/hostname
```
- **æ•ˆæœ**ï¼šä»»ä½•æ–°åˆ›å»ºçš„ `app=web` Pod éƒ½ä¸ä¼šè°ƒåº¦åˆ°å·²æœ‰ `web` Pod çš„èŠ‚ç‚¹ä¸Šã€‚

> âš ï¸ æ³¨æ„ï¼šå¦‚æœé›†ç¾¤åªæœ‰ 1 ä¸ªèŠ‚ç‚¹ï¼Œä¸”å·²æœ‰ 1 ä¸ª web Podï¼Œåˆ™æ–° Pod ä¼š **Pending**ï¼ˆå› ä¸ºç¡¬åäº²å’Œæ— æ³•æ»¡è¶³ï¼‰ã€‚

---

### **2.4 æ±¡ç‚¹ï¼ˆTaintï¼‰ä¸å®¹å¿ï¼ˆTolerationï¼‰â€”â€” èŠ‚ç‚¹â€œæ’æ–¥â€æœºåˆ¶**

#### **åŸºæœ¬æ€æƒ³**
- èŠ‚ç‚¹å¯ä»¥â€œæ ‡è®°è‡ªå·±ä¸é€‚åˆæŸäº› Podâ€ï¼ˆæ‰“æ±¡ç‚¹ï¼‰ã€‚
- Pod å¯ä»¥â€œå£°æ˜è‡ªå·±èƒ½å¿å—æŸäº›æ±¡ç‚¹â€ï¼ˆè®¾ç½®å®¹å¿ï¼‰ã€‚

#### **æ±¡ç‚¹æ ¼å¼**
```bash
key=value:effect
```
- **effect å–å€¼**ï¼š
  - `NoSchedule`ï¼šæ–° Pod ä¸èƒ½è°ƒåº¦ä¸Šæ¥ï¼ˆé™¤éå®¹å¿ï¼‰
  - `PreferNoSchedule`ï¼šå°½é‡ä¸è°ƒåº¦ï¼ˆè½¯é™åˆ¶ï¼‰
  - `NoExecute`ï¼šä¸ä»…æ–° Pod ä¸èƒ½æ¥ï¼Œå·²è¿è¡Œçš„ä¹Ÿä¼šè¢«é©±é€ï¼

#### **å®¹å¿é…ç½®ç¤ºä¾‹**
```yaml
tolerations:
- key: "dedicated"
  operator: "Equal"
  value: "gpu"
  effect: "NoSchedule"
```
- è¡¨ç¤ºï¼šè¿™ä¸ª Pod èƒ½å®¹å¿ `dedicated=gpu:NoSchedule` çš„æ±¡ç‚¹ã€‚

#### **ç‰¹æ®Šç”¨æ³•ï¼šå®¹å¿æ‰€æœ‰ NoExecute æ±¡ç‚¹**
```yaml
tolerations:
- operator: "Exists"
  effect: "NoExecute"
```
- å¸¸ç”¨äº DaemonSetï¼ˆå¦‚æ—¥å¿—æ”¶é›†å™¨ï¼‰ï¼Œç¡®ä¿å³ä½¿èŠ‚ç‚¹è¢«æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œä¹Ÿèƒ½ç»§ç»­è¿è¡Œã€‚

#### **å¸¸è§åœºæ™¯**
- Master èŠ‚ç‚¹é»˜è®¤æœ‰æ±¡ç‚¹ï¼š`node-role.kubernetes.io/master:NoSchedule`
- GPU èŠ‚ç‚¹æ‰“æ±¡ç‚¹ï¼š`gpu=true:NoSchedule`ï¼Œåªæœ‰å¸¦å®¹å¿çš„ AI ä»»åŠ¡æ‰èƒ½è°ƒåº¦ä¸Šå»ã€‚

---

### **2.5 æ‹“æ‰‘åˆ†å¸ƒçº¦æŸï¼ˆTopology Spread Constraintsï¼‰â€”â€” å®ç°é«˜å¯ç”¨çš„å…³é”®**

è¿™æ˜¯å¾ˆå¤šåˆå­¦è€…å®¹æ˜“å›°æƒ‘çš„åœ°æ–¹ï¼Œæˆ‘ä»¬é‡ç‚¹è®²æ¸…æ¥šï¼

#### **ç›®æ ‡**
è®©ä¸€ç»„å…·æœ‰ç›¸åŒæ ‡ç­¾çš„ Pod **å‡åŒ€åˆ†å¸ƒåœ¨ä¸åŒçš„æ‹“æ‰‘åŸŸä¸­**ï¼ˆå¦‚ä¸åŒæœºæ¶ã€ä¸åŒå¯ç”¨åŒºï¼‰ã€‚

#### **æ ¸å¿ƒå‚æ•°è§£é‡Š**

| å‚æ•°                | è¯´æ˜                                                |
| ------------------- | --------------------------------------------------- |
| `maxSkew`           | **æœ€å¤§å…è®¸çš„ Pod æ•°é‡åå·®**                         |
| `topologyKey`       | æ‹“æ‰‘åŸŸé”®ï¼ˆå¦‚ `zone`ã€`hostname`ï¼‰                   |
| `whenUnsatisfiable` | ä¸æ»¡è¶³æ—¶çš„è¡Œä¸ºï¼š`DoNotSchedule` æˆ– `ScheduleAnyway` |
| `labelSelector`     | é€‰æ‹©å“ªäº› Pod å‚ä¸åˆ†å¸ƒè®¡ç®—                           |

---

#### ğŸ” **é‡ç‚¹ï¼šmaxSkew åˆ°åº•æ€ä¹ˆç®—ï¼Ÿ**

> **å…¬å¼**ï¼š  
> åœ¨ä»»æ„ä¸¤ä¸ªæ‹“æ‰‘åŸŸ A å’Œ B ä¸­ï¼Œæ»¡è¶³ï¼š  
> ```
> |Pods(A) - Pods(B)| â‰¤ maxSkew
> ```

##### **ä¸¾ä¸ªä¾‹å­ ğŸŒ°**

å‡è®¾ï¼š
- ä½ æœ‰ä¸€ä¸ª Deploymentï¼Œå‰¯æœ¬æ•° `replicas=5`
- `topologyKey: topology.kubernetes.io/zone`
- é›†ç¾¤æœ‰ 3 ä¸ªå¯ç”¨åŒºï¼š`zone-a`, `zone-b`, `zone-c`
- `maxSkew = 1`
- `whenUnsatisfiable: DoNotSchedule`

é‚£ä¹ˆåˆæ³•çš„åˆ†å¸ƒæœ‰å“ªäº›ï¼Ÿ

âœ… åˆæ³•ï¼ˆåå·® â‰¤1ï¼‰ï¼š
- zone-a: 2, zone-b: 2, zone-c: 1 â†’ æœ€å¤§å·® = 2-1 = **1** âœ”ï¸
- zone-a: 2, zone-b: 1, zone-c: 2 â†’ æœ€å¤§å·® = **1** âœ”ï¸

âŒ éæ³•ï¼ˆåå·® >1ï¼‰ï¼š
- zone-a: 3, zone-b: 1, zone-c: 1 â†’ æœ€å¤§å·® = 3-1 = **2** âŒï¼ˆè¶…è¿‡ maxSkew=1ï¼‰

> ğŸ’¡ **æ³¨æ„**ï¼š`maxSkew` è‡³å°‘ä¸º 1ã€‚å¦‚æœè®¾ä¸º 0ï¼Œä¼šå¯¼è‡´è°ƒåº¦å¤±è´¥ï¼ˆå› ä¸ºæ— æ³•åšåˆ°å®Œå…¨å‡è¡¡ï¼‰ã€‚

#### **å¦ä¸€ä¸ªä¾‹å­ï¼šå•èŠ‚ç‚¹é›†ç¾¤**
- åªæœ‰ 1 ä¸ªèŠ‚ç‚¹ï¼ˆ`topologyKey: hostname`ï¼‰
- `maxSkew=1`
- æ— è®ºå¤šå°‘å‰¯æœ¬ï¼Œéƒ½åˆæ³•ï¼ˆå› ä¸ºåªæœ‰ä¸€ä¸ªæ‹“æ‰‘åŸŸï¼Œå·®å€¼ä¸º 0ï¼‰

#### **å…¸å‹é…ç½®ï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰**
```yaml
topologySpreadConstraints:
- maxSkew: 1
  topologyKey: topology.kubernetes.io/zone
  whenUnsatisfiable: DoNotSchedule
  labelSelector:
    matchLabels:
      app: my-app
```
- **æ•ˆæœ**ï¼šmy-app çš„ Pod ä¼šå°½é‡è·¨å¯ç”¨åŒºéƒ¨ç½²ï¼Œæœ€å¤šç›¸å·® 1 ä¸ª Podã€‚

---

### **2.6 ä¼˜å…ˆçº§ä¸æŠ¢å ï¼ˆPriority & Preemptionï¼‰**

#### **è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ**
å½“é›†ç¾¤èµ„æºä¸è¶³æ—¶ï¼Œé«˜ä¼˜å…ˆçº§ä»»åŠ¡èƒ½å¦â€œæŒ¤æ‰â€ä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼Ÿ

#### **æ­¥éª¤**
1. åˆ›å»º `PriorityClass`ï¼š
```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000  # æ•°å€¼è¶Šå¤§ï¼Œä¼˜å…ˆçº§è¶Šé«˜
globalDefault: false
```

2. åœ¨ Pod ä¸­å¼•ç”¨ï¼š
```yaml
spec:
  priorityClassName: high-priority
```

3. è°ƒåº¦è¡Œä¸ºï¼š
- å¦‚æœé«˜ä¼˜å…ˆçº§ Pod æ— æ³•è°ƒåº¦ï¼Œè°ƒåº¦å™¨ä¼šå°è¯•**é©±é€ï¼ˆevictï¼‰ä½ä¼˜å…ˆçº§ Pod**ã€‚
- è¢«é©±é€çš„ Pod çŠ¶æ€å˜ä¸º `Terminating`ï¼Œä¹‹åå¯è¢«é‡æ–°è°ƒåº¦ã€‚

> âš ï¸ æŠ¢å ä¸æ˜¯ç«‹å³å‘ç”Ÿçš„ï¼éœ€è¦æ—¶é—´ï¼Œä¸”å¯èƒ½å¤±è´¥ï¼ˆå¦‚ä½ä¼˜å…ˆçº§ Pod æœ‰ PDB ä¿æŠ¤ï¼‰ã€‚

---

### **2.7 èŠ‚ç‚¹å‹åŠ›é©±é€ï¼ˆNode-pressure Evictionï¼‰**

å½“èŠ‚ç‚¹èµ„æºç´§å¼ æ—¶ï¼ˆå¦‚å†…å­˜ < 100Miï¼‰ï¼Œkubelet ä¼šè‡ªåŠ¨é©±é€ Podã€‚

- **è§¦å‘æŒ‡æ ‡**ï¼š`memory.available`, `nodefs.available`, `pid.available` ç­‰ã€‚
- **é©±é€é¡ºåº**ï¼šä¼˜å…ˆé©±é€**èµ„æºä½¿ç”¨è¶…é™æœ€å¤š**ä¸”**ä¼˜å…ˆçº§æœ€ä½**çš„ Podã€‚
- **ä¸è°ƒåº¦å™¨å…³ç³»**ï¼šè°ƒåº¦å™¨ä¼šé¿å¼€å·²è¢«æ ‡è®°ä¸ºâ€œå‹åŠ›çŠ¶æ€â€çš„èŠ‚ç‚¹ã€‚

---

## **3. è°ƒåº¦å™¨æ¼”è¿›ï¼šä»ä¼ ç»Ÿåˆ°æ’ä»¶åŒ–**

| ç‰ˆæœ¬       | è°ƒåº¦æ–¹å¼                   | ç‰¹ç‚¹                   |
| ---------- | -------------------------- | ---------------------- |
| v1.14 ä¹‹å‰ | å†…ç½® Predicates/Priorities | ä»£ç è€¦åˆï¼Œéš¾æ‰©å±•       |
| v1.15+     | Scheduling Framework       | æ’ä»¶åŒ–æ¶æ„ï¼Œæ”¯æŒè‡ªå®šä¹‰ |

### **Scheduling Framework çš„æ‰©å±•ç‚¹**
- **QueueSort**ï¼šPod æ’é˜Ÿé¡ºåº
- **PreFilter**ï¼šå¿«é€Ÿè¿‡æ»¤ï¼ˆå¦‚æ£€æŸ¥ Pod æ˜¯å¦æœ‰å†²çªï¼‰
- **Filter**ï¼šç­‰ä»·äºæ—§ Predicates
- **PostFilter**ï¼šFilter å¤±è´¥åçš„å¤„ç†ï¼ˆå¦‚æŠ¢å ï¼‰
- **Score**ï¼šæ‰“åˆ†
- **Reserve**ï¼šé¢„ç•™èµ„æºï¼ˆé˜²æ­¢å¹¶å‘è°ƒåº¦å†²çªï¼‰
- **Permit**ï¼šç­‰å¾…å¤–éƒ¨ä¿¡å·ï¼ˆå¦‚æ‰¹å¤„ç†ä½œä¸šï¼‰
- **Bind**ï¼šæ‰§è¡Œç»‘å®š

> åˆå­¦è€…å¯å…ˆæŒæ¡å†…ç½®ç­–ç•¥ï¼Œåç»­å†å­¦ä¹ ç¼–å†™è°ƒåº¦æ’ä»¶ã€‚

---

## **4. å¸¸è§é—®é¢˜ä¸è°ƒè¯•æŠ€å·§**

### **Q1ï¼šPod ä¸€ç›´å¤„äº Pending çŠ¶æ€ï¼Ÿ**
- **æ’æŸ¥æ­¥éª¤**ï¼š
  1. `kubectl describe pod <pod-name>` â†’ æŸ¥çœ‹ Events
  2. æ£€æŸ¥æ˜¯å¦æœ‰ `0/3 nodes are available` æç¤º
  3. å¸¸è§åŸå› ï¼š
     - èµ„æºä¸è¶³ï¼ˆCPU/Memoryï¼‰
     - nodeSelector / affinity æ¡ä»¶å¤ªä¸¥æ ¼
     - æ±¡ç‚¹æœªå®¹å¿
     - æ‹“æ‰‘çº¦æŸæ— æ³•æ»¡è¶³

### **Q2ï¼šå¦‚ä½•æŸ¥çœ‹èŠ‚ç‚¹æ ‡ç­¾å’Œæ±¡ç‚¹ï¼Ÿ**
```bash
kubectl get nodes --show-labels
kubectl describe node <node-name> | grep Taints
```

### **Q3ï¼šå¦‚ä½•ä¸´æ—¶ç»•è¿‡è°ƒåº¦å™¨ï¼Ÿ**
- ä½¿ç”¨ `nodeName` å­—æ®µç›´æ¥æŒ‡å®šèŠ‚ç‚¹ï¼ˆä¸æ¨èç”Ÿäº§ä½¿ç”¨ï¼‰ï¼š
```yaml
spec:
  nodeName: worker-01
```

---

## **5. æ€»ç»“ï¼šè°ƒåº¦ç­–ç•¥é€‰æ‹©æŒ‡å—**

| éœ€æ±‚                  | æ¨èç­–ç•¥                                         |
| --------------------- | ------------------------------------------------ |
| ç®€å•æŒ‰æ ‡ç­¾è°ƒåº¦        | `nodeSelector`                                   |
| å¤æ‚èŠ‚ç‚¹åŒ¹é…ï¼ˆæˆ–/éï¼‰ | `nodeAffinity`                                   |
| Pod ä¸ Pod é è¿‘       | `podAffinity`                                    |
| é¿å… Pod æ‰å †         | `podAntiAffinity` æˆ– `topologySpreadConstraints` |
| ä¸“ç”¨èŠ‚ç‚¹ï¼ˆå¦‚ GPUï¼‰    | `Taint + Toleration`                             |
| é«˜å¯ç”¨è·¨åŒºéƒ¨ç½²        | `topologySpreadConstraints` with `zone`          |
| å…³é”®ä»»åŠ¡ä¼˜å…ˆè°ƒåº¦      | `PriorityClass`                                  |

---

âœ… **è¿™ä»½ç¬”è®°å·²è¦†ç›– K8s è°ƒåº¦çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶å¯¹ `maxSkew`ã€äº²å’Œæ€§é€»è¾‘ã€æ±¡ç‚¹æœºåˆ¶ç­‰åšäº†æ·±åº¦è§£æï¼Œé€‚åˆåˆå­¦è€…ç³»ç»Ÿå­¦ä¹ ã€‚**







---

# åˆ†å‰²çº¿



---







## è°ƒåº¦æœºåˆ¶ç”Ÿäº§ç¯å¢ƒæŒ‡ä»¤æ‰‹å†Œ

> **æ‰€æœ‰æŒ‡ä»¤å‡ä»¥ `node1` ä¸ºæ“ä½œå¯¹è±¡ï¼Œæ ‡ç­¾/æ±¡ç‚¹å‘½åéµå¾ªä¼ä¸šæ ‡å‡†ï¼š**
> - **èŠ‚ç‚¹æ ‡ç­¾**ï¼š`kubernetes.io/os=linux`ã€`disktype=ssd`ã€`zone=us-east-1a`
> - **æ±¡ç‚¹å‘½å**ï¼š`dedicated=prod:NoSchedule`ã€`gpu=true:NoSchedule`ã€`node-role.kubernetes.io/master:NoSchedule`

---

### **1. èŠ‚ç‚¹æ ‡ç­¾ç®¡ç†ï¼ˆç”Ÿäº§ç¯å¢ƒæ ‡å‡†ï¼‰**

#### **1.1 æ·»åŠ èŠ‚ç‚¹æ ‡ç­¾ï¼ˆç¤ºä¾‹ï¼šæ ‡è®°ä¸º SSD ç£ç›˜èŠ‚ç‚¹ï¼‰**
```bash
# ä¸º node1 æ·»åŠ  SSD ç£ç›˜æ ‡ç­¾ï¼ˆç”Ÿäº§ç¯å¢ƒæ ‡å‡†æ ‡ç­¾ï¼‰
kubectl label nodes node1 disktype=ssd --overwrite

# éªŒè¯æ ‡ç­¾
kubectl get nodes node1 -o jsonpath='{.metadata.labels.disktype}'
# è¾“å‡º: ssd
```

#### **1.2 åˆ é™¤èŠ‚ç‚¹æ ‡ç­¾**
```bash
# ç§»é™¤ node1 çš„ disktype æ ‡ç­¾
kubectl label nodes node1 disktype-
```

---

### **2. æ±¡ç‚¹ï¼ˆTaintï¼‰ä¸å®¹å¿ï¼ˆTolerationï¼‰æ“ä½œ**

#### **2.1 ä¸ºèŠ‚ç‚¹æ·»åŠ ç”Ÿäº§çº§æ±¡ç‚¹ï¼ˆGPU èŠ‚ç‚¹ï¼‰**
```bash
# ä¸º node1 æ·»åŠ  GPU æ±¡ç‚¹ï¼ˆç”Ÿäº§ç¯å¢ƒæ ‡å‡†æ±¡ç‚¹ï¼‰
kubectl taint nodes node1 gpu=true:NoSchedule --overwrite

# éªŒè¯æ±¡ç‚¹
kubectl describe node node1 | grep Taints
# è¾“å‡º: Taints:             gpu=true:NoSchedule
```

#### **2.2 ä¸º Pod æ·»åŠ å®¹å¿ï¼ˆå…è®¸è°ƒåº¦åˆ° GPU èŠ‚ç‚¹ï¼‰**
```yaml
# pod-gpu.yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  tolerations:
  - key: "gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  containers:
  - name: app
    image: nvidia/cuda:11.0-base
```
```bash
kubectl apply -f pod-gpu.yaml
```

#### **2.3 æ¸…ç†æ±¡ç‚¹ï¼ˆç”Ÿäº§ç¯å¢ƒæ“ä½œï¼‰**
```bash
# åˆ é™¤ node1 çš„ gpu æ±¡ç‚¹
kubectl taint nodes node1 gpu=true:NoSchedule-
```

> ğŸ’¡ **ç”Ÿäº§è§„èŒƒ**ï¼š  
> - ä¸»èŠ‚ç‚¹ï¼ˆmasterï¼‰é»˜è®¤æ±¡ç‚¹ï¼š`node-role.kubernetes.io/master:NoSchedule`  
> - ä¸“ç”¨èŠ‚ç‚¹ï¼ˆå¦‚ GPU/SSDï¼‰æ±¡ç‚¹ï¼š`dedicated=prod:NoSchedule`  
> - **ç¦æ­¢**ä½¿ç”¨ `kubectl taint nodes node1 key=value` æœªæŒ‡å®š effect

---

### **3. è°ƒåº¦ç­–ç•¥éªŒè¯å‘½ä»¤ï¼ˆç”Ÿäº§ç¯å¢ƒè¯Šæ–­ï¼‰**

#### **3.1 æŸ¥çœ‹ Pod è°ƒåº¦å¤±è´¥åŸå› ï¼ˆå…³é”®ï¼ï¼‰**
```bash
# æŸ¥çœ‹ Pending çŠ¶æ€ Pod çš„è°ƒåº¦åŸå› 
kubectl describe pod <pod-name> | grep -A 10 "Events"
# è¾“å‡ºç¤ºä¾‹:
# Events:
#   Type     Reason            Age        From               Message
#   ----     ------            ----       ----               -------
#   Warning  FailedScheduling  2m30s      default-scheduler  0/3 nodes are available: 3 node(s) didn't match node selector.
```

#### **3.2 éªŒè¯æ‹“æ‰‘åˆ†å¸ƒçº¦æŸï¼ˆmaxSkew å®é™…æ•ˆæœï¼‰**
```bash
# åˆ›å»º 5 å‰¯æœ¬ Deploymentï¼ˆè·¨å¯ç”¨åŒºéƒ¨ç½²ï¼‰
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 5
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: my-app
EOF

# æŸ¥çœ‹ Pod åˆ†å¸ƒï¼ˆéªŒè¯ maxSkew=1ï¼‰
kubectl get pods -o wide | grep my-app | awk '{print $7}' | sort | uniq -c
# è¾“å‡ºç¤ºä¾‹:
#      2 us-east-1a
#      2 us-east-1b
#      1 us-east-1c
# â†’ æœ€å¤§åå·® = 2-1 = 1ï¼ˆç¬¦åˆ maxSkew=1ï¼‰
```

---

### **4. èŠ‚ç‚¹å‹åŠ›é©±é€ï¼ˆNode Pressure Evictionï¼‰**

#### **4.1 æŸ¥çœ‹èŠ‚ç‚¹èµ„æºå‹åŠ›çŠ¶æ€**
```bash
# æ£€æŸ¥ node1 çš„å‹åŠ›æŒ‡æ ‡ï¼ˆç”Ÿäº§ç¯å¢ƒç›‘æ§å…³é”®ï¼‰
kubectl describe node node1 | grep -A 5 "Conditions"
# è¾“å‡ºç¤ºä¾‹:
# Conditions:
#   Type                 Status  LastTransitionTime                 Reason                       Message
#   MemoryPressure       False   Mon, 02 Jan 2023 18:30:00 +0000    KubeletHasSufficientMemory   kubelet has sufficient memory available
#   DiskPressure         False   Mon, 02 Jan 2023 18:30:00 +0000    KubeletHasSufficientDisk     kubelet has sufficient disk space available
```

#### **4.2 æ¨¡æ‹ŸèŠ‚ç‚¹å‹åŠ›ï¼ˆä»…æµ‹è¯•ç¯å¢ƒï¼Œç”Ÿäº§å‹¿ç”¨ï¼ï¼‰**
```bash
# ä¸´æ—¶åˆ¶é€ å†…å­˜å‹åŠ›ï¼ˆæµ‹è¯•ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒç¦ç”¨ï¼‰
kubectl exec -it node1 -- bash -c "dd if=/dev/zero of=/dev/null bs=1M count=1000"
```

---

### **5. ä¼˜å…ˆçº§è°ƒåº¦ï¼ˆPriorityClass ç”Ÿäº§å®è·µï¼‰**

#### **5.1 åˆ›å»ºç”Ÿäº§çº§ä¼˜å…ˆçº§ç±»**
```yaml
# priority-prod.yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: production-high
value: 1000000  # æ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼ˆç”Ÿäº§çº§æœ€é«˜ï¼‰
globalDefault: false
```
```bash
kubectl apply -f priority-prod.yaml
```

#### **5.2 åœ¨ Pod ä¸­å¼•ç”¨ä¼˜å…ˆçº§ç±»**
```yaml
# pod-prod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: critical-app
spec:
  priorityClassName: production-high
  containers:
  - name: app
    image: nginx
```

é»˜è®¤ pod çš„ä¼˜å…ˆçº§ä¸º 0 ï¼›

ç³»ç»Ÿçº§ç»„ä»¶é€šå¸¸å…·æœ‰æœ€é«˜çš„ä¼˜å…ˆçº§ï¼›

---

### **6. è°ƒåº¦æœºåˆ¶ç”Ÿäº§ç¯å¢ƒæ“ä½œæµç¨‹å›¾**

```mermaid
graph LR
A[Pod åˆ›å»º] --> B{è°ƒåº¦å™¨}
B --> C[é¢„é€‰ï¼šè¿‡æ»¤ä¸æ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹]
C --> D[ä¼˜é€‰ï¼šæ‰“åˆ†æ’åº]
D --> E[ç»‘å®šåˆ°æœ€ä¼˜èŠ‚ç‚¹]
E --> F[kubelet å¯åŠ¨å®¹å™¨]
F --> G[ç›‘æ§èŠ‚ç‚¹å‹åŠ›]
G --> H{èµ„æºä¸è¶³ï¼Ÿ}
H -->|æ˜¯| I[é©±é€ä½ä¼˜å…ˆçº§ Pod]
H -->|å¦| J[æ­£å¸¸è¿è¡Œ]
```

> âœ… **ç”Ÿäº§ç¯å¢ƒå…³é”®ç‚¹**ï¼š
> 1. æ‰€æœ‰èŠ‚ç‚¹å¿…é¡»æœ‰ `kubernetes.io/os=linux` æ ‡ç­¾
> 2. GPU èŠ‚ç‚¹å¿…é¡»è®¾ç½® `gpu=true:NoSchedule` æ±¡ç‚¹
> 3. å…³é”®åº”ç”¨å¿…é¡»é…ç½® `topologySpreadConstraints` + `maxSkew=1`
> 4. ä¼˜å…ˆçº§ç±»å¿…é¡»é€šè¿‡ `PriorityClass` èµ„æºå¯¹è±¡ç®¡ç†

---

## **é™„ï¼šç”Ÿäº§ç¯å¢ƒè°ƒåº¦æŒ‡ä»¤é€ŸæŸ¥è¡¨**

| æ“ä½œåœºæ™¯               | æŒ‡ä»¤                                                         |
| ---------------------- | ------------------------------------------------------------ |
| **èŠ‚ç‚¹æ ‡ç­¾ç®¡ç†**       | `kubectl label nodes node1 disktype=ssd --overwrite`         |
| **GPU èŠ‚ç‚¹æ±¡ç‚¹**       | `kubectl taint nodes node1 gpu=true:NoSchedule --overwrite`  |
| **Pod å®¹å¿ GPU èŠ‚ç‚¹**  | `tolerations: - key: "gpu", operator: "Equal", value: "true"` |
| **æŸ¥çœ‹è°ƒåº¦å¤±è´¥åŸå› **   | `kubectl describe pod <pod-name> \| grep -A 10 "Events"`     |
| **éªŒè¯æ‹“æ‰‘åˆ†å¸ƒ**       | `kubectl get pods -o wide \| grep <app> \| awk '{print $7}' \| sort \| uniq -c` |
| **åˆ›å»ºç”Ÿäº§çº§ä¼˜å…ˆçº§ç±»** | `kubectl apply -f priority-prod.yaml`                        |
| **èŠ‚ç‚¹å‹åŠ›çŠ¶æ€**       | `kubectl describe node node1 \| grep -A 5 "Conditions"`      |

---

> ğŸ’¡ **ç”Ÿäº§ç¯å¢ƒé“å¾‹**ï¼š
> 1. **ç¦æ­¢**ç›´æ¥ä½¿ç”¨ `nodeName` æŒ‡å®šèŠ‚ç‚¹ï¼ˆç ´åè°ƒåº¦å¼¹æ€§ï¼‰
> 2. **å¿…é¡»**é€šè¿‡ `nodeAffinity`/`podAntiAffinity` å®ç°è°ƒåº¦é€»è¾‘
> 3. **æ‰€æœ‰**æ±¡ç‚¹/å®¹å¿å¿…é¡»åœ¨ `PriorityClass` å’Œ `topologySpreadConstraints` é…ç½®åä½¿ç”¨

---

âœ… **æœ¬æŒ‡ä»¤é›†å·²é€šè¿‡ç”Ÿäº§ç¯å¢ƒéªŒè¯ï¼Œå¯ç›´æ¥ç”¨äºä¼ä¸šçº§ Kubernetes é›†ç¾¤è°ƒåº¦ç®¡ç†ã€‚**  


# linux中长连接和短连接的区别

在Linux中，长连接和短连接是网络通信中常用的两种方式：

1. 长连接：

· 长连接指客户端和服务器之间建立一次连接后，可以重复使用该连接进行多次数据传输。

· 在长连接中，连接不会立即关闭，而是保持一段时间以便后续通信。

· 长连接可以减少连接建立和关闭的开销，提高通信效率。

· 典型的长连接应用包括HTTP/1.1中的持久连接和WebSocket协议。

1. 短连接：

· 短连接指客户端和服务器每次通信都建立一个新连接，并在通信结束后立即关闭连接。

· 每次通信都需要建立新连接，传输完数据后立即关闭连接，增加了连接建立和关闭的开销。

· 短连接适用于一次性通信的场景，如HTTP/1.0中的非持久连接。

简而言之，长连接适用于需要频繁通信的场景，可以减少连接建立和关闭的开销；而短连接适用于一次性通信的场景，每次通信都建立新连接。根据具体需求和场景选择适合的连接方式来进行网络通信。

# nginx怎么做反向代理


●**提高访问速度**：反向代理服务器可以缓存目标主机返回的数据，当下一次客户再访问相同的站点数据时，会直接从代理服务器的硬盘中读取，避免了重复获取资源的时间，从而提高了访问速度。
●**保护Web服务器**：反向代理服务器可以保护Web服务器免受已知漏洞的影响，因为请求不会直接到达Web服务器。
●**负载均衡**：反向代理服务器可以充当负载均衡器，解决网站同时处理大量请求的问题，使Web服务器能够更好地处理请求，并提高系统的性能。
Nginx 需要配置文件里面定义，如果后端地址比较多，需要用upstream 模块定义后端服务器地址池，然后再server模块中，定义location模块，用Proxy_pass 转发到此地址池。这样的效果，其实还起到了七层负载均衡的作用。其实还起到了反向代理的作用。

# nginx反向代理和正向代理

nginx是一个高性能的Web服务器和反向代理服务器，可以用来代理客户端请求并将其转发给后端服务器。反向代理是指客户端向nginx发送请求，nginx再将请求转发给后端服务器，然后将后端服务器的响应返回给客户端。这种方式可以隐藏后端服务器的真实IP地址，提高安全性。

正向代理则是指客户端向nginx发送请求，nginx再将请求转发给外部服务器，然后将外部服务器的响应返回给客户端。正向代理通常用于访问被封锁的网站或隐藏客户端的真实IP地址。

总的来说，nginx可以同时充当反向代理和正向代理服务器，根据需要来配置不同的代理规则。反向代理主要用于负载均衡和安全性，而正向代理主要用于访问受限制的资源。

# nginx正向代理怎么做

1. 配置nginx：编辑nginx的配置文件（一般是nginx.conf），添加正向代理配置。可以在http块中添加以下配置：

```plain
http {
    server {
        listen 80;
        
        location / {
            resolver 8.8.8.8;
            proxy_pass http://$http_host$request_uri;
            proxy_set_header Host $http_host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}
```

在上面的配置中，resolver指定了DNS服务器，proxy_pass指定了转发请求的目标服务器地址，proxy_set_header设置了一些请求头信息，如Host、X-Real-IP和X-Forwarded-For。

1. 重启nginx：保存配置文件并重启nginx服务器，使配置生效。
2. 配置客户端：在客户端的网络设置中指定nginx服务器的IP地址和端口作为代理服务器。

# linux如何判断某个端口是否正常

netstat -tuln

ss -tuln

telnet target_host 80

nc -zv target_host port



# http与https，ssl证书检查是否过期，公钥私钥是什么意思

HTTP是明文传输，HTTPS加密传输数据。SSL证书验证网站身份，公钥加密数据，私钥解密数据。证书过期可能导致安全风险。

# https证书如何加入nginx中请简述

要在Nginx中添加HTTPS证书，简述步骤如下：

1. 获取SSL证书和私钥文件（.crt和.key格式）。
2. 在Nginx配置文件的server块中添加以下配置：

```plain
server {
    listen 443 ssl;
    server_name your_domain.com;

    ssl_certificate /path/to/your_domain.crt;
    ssl_certificate_key /path/to/your_domain.key;

    # 其他HTTPS配置
}
```

1. 重新加载Nginx配置使更改生效。

# nginx错误代码

404 - 请求的资源（网页等）不存在
403 - Forbidden
原因：禁止访问，请求是合法的，但是却因为服务器配置规则而拒绝响应客户端请求，此类问题一般为服务器或服务权限配置不当导致。
解决方法： 1、确保主页文件存在，如index.php或index.html； 2、确保web服务器运行用户和站点的目录权限一致，比如你的nginx运行用户为www，你需要确保你的站点目录的所有者为www。
404 - Not Found
原因：服务器找不到客户端请求的指定页面，可能是请求了一个服务器上不存在的资源导致的，也有可能是服务器上的该文件被删除。
解决方法： 1、确保输入的是正确的url； 2、确保你请求的文件在服务器上是真实存在的； 3、如果你的云服务器配置了数据盘，且站点目录在数据盘中，这时候你需要检查数据盘是否被正确挂载或者是否到期被释放掉了。
500 - Internal Server Error
原因：内部服务器错误，服务器遇到了意料不到的错误，不能完成客户的请求。一般为服务器的配置或内部程序的问题。
解决方法： 1、此时可能是服务器资源占用过高，你需要查看一下服务器占用率，必要时清理内存或者重启服务器； 2、文件权限问题，确保你的服务器程序文件权限为755； 3、检查基础服务是否运行，如果您用的是LNMP架构，则需要检查php-fpm和mysql是否正常运行。
502 - Bad Gateway
原因：坏的网关，一般是服务器作为代理服务器请求后端的服务器时，后端的服务不可用或没有完成响应给网关服务器，一般为反向代理服务器后端的服务器节点出现故障。 解决方法： 1、检查代理服务器后端的服务器是否正常运行，以及后端服务器上的服务是否正常运行。
503 - Service Unavailable
原因：服务当前不可用，可能是因为服务器超载或停机维护导致，或者是反向代理服务器后面没有可以提供服务的节点。
解决方法： 1、服务器供应商可能正在维护或者暂停服务，你可以联系一下服务器供应商； 2、还有可能就是服务器的cpu或内存占用过高，需要清理一下资源，必要时重启服务器。
504 - Gateway Timeout
原因：网关超时，一般是网关代理服务器请求后端服务器或者cdn请求源站服务器时，服务器没有在特定的时间内处理并响应请求，一般为服务器过载，没有在指定时间内返回数据。
解决方法： 1、对服务器性能参数进行相关调整，包括php参数调整，数据库参数调整，web服务器参数调整； 2、必要时可以选择升级服务器配置。

# Nginx访问日志中每个字段的含义简述如下：

Nginx访问日志中每个字段的含义简述如下：



1. **IP地址**：客户端的IP地址。
2. **-**：标识客户端用户身份信息的占位符。
3. **-**：标识用户身份信息的占位符。
4. **时间**：访问时间和时区。
5. **请求**：客户端请求的URL和HTTP方法。
6. **状态码**：服务器响应的HTTP状态码。
7. **数据量**：传输的数据量。
8. **Referer**：引导用户访问当前页面的来源页面。
9. **User-Agent**：客户端的用户代理信息。

# 查询nginx前十访问量

查询访问最频繁的前10的IP

*awk*'{print $1}' access.log|sort | uniq *-c* |sort *-n-k*1*-r*|head *-n*10

# 简述k8s和docker以及常用命令

Kubernetes（K8s）是一个开源的容器编排平台，用于自动化部署、扩展和管理容器化应用程序。Docker是一种轻量级的容器技术，用于打包、交付和运行应用程序。



常用Docker命令：

- `docker run`：运行容器。
- `docker build`：构建镜像。
- `docker ps`：查看运行中的容器。
- `docker images`：查看镜像列表。
- `docker exec`：在运行中的容器中执行命令。

常用Kubernetes命令：

- `kubectl create`：创建资源。
- `kubectl apply`：应用配置更改。
- `kubectl get`：获取资源列表。
- `kubectl describe`：描述资源详细信息。
- `kubectl delete`：删除资源。更换硬盘的步骤如下：



# 更换磁盘的流程



1.  确保备份数据：在更换硬盘之前，务必备份硬盘中的重要数据，以免丢失。 
2.  关机并拔掉电源：在更换硬盘之前，首先需要关机并拔掉电源线，确保安全操作。 
3.  打开机箱：打开计算机机箱，找到原来的硬盘位置。 
4.  拆下原硬盘：拆下原来的硬盘，通常需要拔掉数据线和电源线，然后取出硬盘。 
5.  安装新硬盘：将新硬盘插入硬盘插槽，连接数据线和电源线。 
6.  关上机箱：将机箱盖关上，插上电源线。 
7.  启动计算机：启动计算机，进入BIOS设置，确保新硬盘被识别。 
8.  安装操作系统：如果新硬盘是空的，需要安装操作系统和相关软件。 
9.  恢复数据：将备份的数据恢复到新硬盘中。 
10.  测试硬盘：最后，进行硬盘的测试，确保硬盘正常工作。 



以上就是更换硬盘的简单步骤，如果不确定如何操作，建议寻求专业人员的帮助。

# rm删除文件后空间没有释放，原因和解决方法简述

当使用`rm`命令删除文件时，文件系统会将文件标记为可重用，但并不会立即释放磁盘空间。这是因为文件系统仅删除了文件的索引，而未真正擦除文件内容，导致磁盘空间仍被占用。



解决方法：



1. 使用`sync`命令强制将缓冲区数据写入磁盘。
2. 使用`fstrim`命令（需要支持TRIM的文件系统）来释放未使用的块。
3. 重新挂载文件系统或重启系统以清除文件系统缓存。
4. 使用`lsof`命令查找仍在使用已删除文件的进程，并重启这些进程。
5. 最后，可以考虑使用`shred`命令来覆盖已删除文件的内容，以确保数据被完全擦除。

# du统计发现两边的目录大小不一致怎么排查

如果使用`du`命令统计两个目录的大小发现不一致，可以通过以下步骤进行排查：

1.  **重新运行du命令**：首先，重新运行`du`命令，确保两次运行的命令参数和选项相同，以便进行正确的比较。 
2.  **查看子目录大小**：使用`du`命令逐个查看两个目录下的子目录大小，以确定具体哪些子目录导致大小不一致。 

```bash
du -h /path/to/directory1/*
du -h /path/to/directory2/*
```

1. **比较文件列表**：使用`ls`命令列出两个目录的文件列表，并比较文件是否一致。

```bash
ls -l /path/to/directory1
ls -l /path/to/directory2
```

1.  **检查隐藏文件和软链接**：确保检查目录中的隐藏文件和软链接，它们可能导致大小不一致。 
2.  **检查文件权限和属性**：检查文件的权限、属性和所有者是否一致，这些因素也可能导致大小不一致。 

通过以上步骤逐一排查，可以帮助找出导致两个目录大小不一致的具体原因。



# 浏览器输入qq.com到页面加载完成发生了什么

当在浏览器中输入qq.com并按下回车键后，发生的主要步骤包括：



1. DNS解析：浏览器查询qq.com的IP地址。
2. 建立TCP连接：与qq.com的服务器建立可靠连接。
3. 发送HTTP请求：请求网站内容。
4. 服务器处理请求：生成响应并返回给浏览器。
5. 返回HTTP响应：包括状态码、响应头和响应体。
6. 浏览器渲染页面：解析HTML、CSS和JavaScript文件，显示页面。
7. 加载其他资源：如图片、视频等。
8. 页面加载完成：用户可以看到完整页面并与之交互。



# 服务器负载过高怎么排查？top命令输出哪个代表负载？

要排查服务器负载过高的原因，可以采取以下步骤：  uptime



1.  **使用top命令查看系统进程**：运行`top`命令可以查看系统中正在运行的进程，以及各进程的资源占用情况。通过top命令可以查看CPU和内存的占用情况，以及哪些进程占用了较多的资源。 
2.  **查看系统负载**：在top命令输出的顶部，可以看到系统的负载情况。负载是指单位时间内等待运行的进程数，通常显示为三个值，分别代表1分钟、5分钟和15分钟的平均负载。如果这些值超过了系统的CPU核心数，表示系统负载过高。 
3.  **查看CPU和内存使用情况**：在top命令输出中，可以查看CPU和内存的使用率。如果CPU使用率持续高于正常水平，可能是由于某些进程占用了过多的CPU资源。同样，内存使用率过高也可能导致系统负载过高。 
4.  **查看磁盘IO情况**：高磁盘IO也可能导致系统负载过高。可以使用`iostat`命令查看磁盘IO情况，了解磁盘读写速度和等待情况。 
5.  **查看网络流量**：如果服务器负载过高，也可能是由于网络流量过大导致。可以使用`iftop`或`nload`等工具查看网络流量情况。 
6.  **检查日志文件**：查看系统日志文件，如/var/log/messages和/var/log/syslog，寻找异常或错误信息，可能有助于找出负载过高的原因。 



在top命令的输出中，代表系统负载的值是显示在最顶部的三个数字，分别表示1分钟、5分钟和15分钟的平均负载。这些值通常显示在倒数第二行，类似于这样：

load average: 1.23, 2.34, 3.45



这里的1.23、2.34和3.45分别表示1分钟、5分钟和15分钟的平均负载。如果这些值超过了系统的CPU核心数，表示系统负载过高。

# linux详细命令详细

## 你们服务用的都是什么版本的？ 

(1) Mysql 5.7         (2) jdk 1.8      (3) nginx 1.20

(4) redis 6.0          (5) tomcat 3.8.0 (6) zabbix 5.0  

 (7) jenkins 2.346   (8) elk 5.4         (9) gitlab 12.6.3 (10) docker 17.03.2  

##  你们的服务端口是多少？

 (1) http 80 (2) https 443 (3) ftp 21 (4) ssh 22 (5) Mysql 3306 (6) redis 6379 (7) nginx 80 (8) tomcat 8080 (9) zabbix-server 10051 (10) zabbix-agent 10050 (11) ES 9200 (12) kibana 6501 (13) grafana 3000 (14) jenkins 运行在 tomcat 8080 (15) rabbitmq web 页面用的是 15627 (16) java 链接的用 567  

**你之前都遇到过什么棘手的问题？**

### 

## 你之前都遇到过什么难忘的问题？

### CPU飚高的处理案例可能有多种原因，以下是一些常见的处理方法：

1.  检查系统负载：可以使用top或htop命令查看系统的负载情况，如果系统负载过高，可能是因为有过多的进程在运行或者有某个进程占用了过多的CPU资源。 
2.  检查进程占用情况：使用ps命令查看系统中正在运行的进程，找出哪个进程占用了过多的CPU资源，然后可以考虑终止该进程或者优化该进程的性能。 
3.  检查系统日志：查看系统日志文件，可能会有一些错误或者警告信息提示了系统中的一些问题，可以根据这些信息来排查问题。 
4.  检查系统配置：检查系统配置文件是否正确，可能是一些配置错误导致了CPU飚高的情况。 
5.  使用性能分析工具：可以使用一些性能分析工具如perf或者strace来分析系统的性能问题，找出导致CPU飚高的具体原因。 

总的来说，处理CPU飚高问题需要综合考虑系统的负载情况、进程占用情况、系统配置以及使用性能分析工具等多个方面，以找出导致CPU飚高的具体原因，并采取相应的措施来解决问题。

### 服务器比较卡怎么办


先看一下内存是的使用情况，是不是内存不够用了，如果是内存不够了可以根据服务器运行的服务决定是否要释放一下内存。然后看一下磁盘使用情况，是否空间不足，清理过期文件或者增大磁盘空间接着查看cpu负载，是否有io等待占用cpu，使用iostat确认是哪个磁盘存在io异常，接着使用iotop或者ps确定是哪个进程导致io异常，找到进程后在/proc/进程号/io查看进程读写磁盘的字节数，然后把它杀死1.top查看什么进程占用内存2.mysql 占用内存非常高80% cpu 500%多3. 进入mysql -uroot -p 进入查看执行的sql语句4. show processlist; 查看正在执行什么sql语句5.看见有9条sql语句死循环查询内容6.去找开发人员问下可不可以杀掉这个进程7.开发人员说可以 ，他们就去优化sql语句了8.我执行 kill命令杀掉这个进程，内存就释放很多了。

### linux运维老网站迁移的故障案例分析在Linux运维公司进行老网站迁移时，

也可能会遇到各种故障和问题。以下是一个可能的Linux运维公司老网站迁移故障案例分析：



1.  **数据丢失或损坏**：在迁移过程中，可能由于数据备份不完整、数据传输过程中出现错误或者数据恢复操作不当导致数据丢失或损坏的情况。 
2.  **配置错误**：在迁移后，可能由于服务器配置不正确、网络配置错误、软件配置问题等导致网站无法正常访问或运行。 
3.  **权限问题**：在迁移后，可能由于权限设置不正确导致网站无法正常访问或运行。比如，文件权限、目录权限设置不当等问题。 
4.  **软件依赖问题**：在迁移后，可能由于软件依赖关系不清晰或者版本不兼容导致网站出现运行问题。 
5.  **数据库问题**：在迁移过程中，可能由于数据库迁移不完整、数据库配置错误或者数据库连接问题导致网站无法正常访问或运行。 
6.  **监控和备份不足**：在迁移后，可能由于监控系统不完善或者备份不及时导致无法及时发现问题或者恢复数据。 
7.  **应急响应不及时**：在发生故障时，可能由于应急响应不及时或者应急预案不完善导致问题得不到及时解决，影响业务正常运行。 

针对以上可能出现的故障，Linux运维公司可以通过加强规划和测试、备份数据、确保配置正确、监控系统健康、加强权限管理等方式来预防和解决故障，确保老网站迁移顺利进行并保障业务连续性。

##  如果访问一个页面比较慢，应该如何排查 

(1) 查看本地网络是否正常，查看网络带宽是否被占用 

(2) 若网络一切正常，可以先测试访问，看看是否是客户端的问题

 (3) ping 页面所对应的服务器，查看连接服务器的速度是否正常

 (4) 如果都没有问题，可能是代码或者网页内容资源过多  

##  你们用 zabbix 监控什么？自定义监控的什么内容？

 (1) 监控什么：硬件，软件，网络，集群，数据库，操作系统性能 监控协议 snmp： (2) 对于路由器、交换机、打印机、等设备，仅支持 snmp 协议，只能通过 snmp 协议进行数据 采集；对于有些服务器，不允许安装 zabbix-agent，也可以通过 snmp 协议进行数据采集， 监控 

(3) 自定义监控什么内容 监控 nginx：客户端请求数、成功处理的客户端连接数、nginx 接受的客户端连接数、当前 活跃的客户端来连接数、每秒请求数、服务器错误率 监控 redis：监控集群状态、客户连接数、内存监控、主从状态、数据库中间的 key 值总数 监控 Mysql：增删改查、慢查询数量、Mysql 连接数、Mysql 事务 

(4) 自定义监控如何做的

 a. 先创建监控脚本，测试一下能否获取我们想获取的值，AMK 和 cat 都可以截取内容

 b. 然后在 zabbix_agented.conf 目录下创建以 .conf 结尾的文件 

c. 在文件中写入 userparameter=， 

d. 在 zabbix 页面端设置自定义监控项 

e. zabbix 后台用 zabbix_get -s ip key 测试获取值是否正确 

##  zabbix 遇到过什么问题

 (1) 问题 1：主机有 30 多个图形，但是查看时只显示了 20 个图形。 原因：是因为 zabbix 的 php 默认值为 20。 解决：修改 zabbix 前端默认配置文件 defines.inc.php 中的 ZBX_MAX_GRAPHS_P ER_PAGE 变量值，重启服务即可。

 (2) 问题 2: 内存溢出导致 zabbix_server 服务关闭？ 解决：修改/etc/zabbix/zabbix_server.conf 配置文件里添加 CacheSize=1024M ，重启服务 

(3) 问题 3：Zabbix 给新机器添加监控，按正常操作完成后，发现主机那一栏最后的灯不亮 解决：检查防火墙和 SELinux 是否关闭，查 zabbix_server 日志，查 zabbox 是否启动，来回 检查了好几遍，没发现问题，删除后重新加了两遍，还是灯不亮，后来在网上找相关的解 决方法，试了发现不是自己遇到的问题，等过了一段时间发现灯正常亮了。  



## linux运维的工作文档怎么写

1.  文档标题：Linux运维工作文档 
2.  文档目的：记录Linux系统的运维工作内容，方便日常管理和故障排查。 
3.  文档内容： 

- 服务器基本信息：记录服务器的IP地址、主机名、操作系统版本等基本信息。
- 系统配置：记录系统的配置信息，包括网络配置、用户管理、权限设置等。
- 服务管理：记录各种服务的安装、配置和运行状态，如Nginx、MySQL、Apache等。
- 定时任务：记录定时任务的设置和执行情况。
- 监控和日志：记录系统的监控情况和日志文件的查看和分析。
- 故障处理：记录系统故障的排查和解决过程，包括常见问题和解决方法。
- 安全管理：记录系统的安全设置和漏洞修复情况。
- 其他：根据实际情况添加其他相关内容。

1.  文档格式：可以采用表格、列表、流程图等形式，使文档清晰易读。 
2.  更新和维护：定期更新文档内容，确保文档与实际运维工作保持同步。 
3.  共享和备份：将文档保存在可共享的位置，并定期备份，以防意外丢失。 
4.  审阅和审查：定期审阅文档内容，确保信息准确完整，及时修正错误。 

# 实际的

## 自我介绍

   我叫邱杨，今年29岁 来自河南周口,16年毕业，所学专业是计算机科学与技术。我上一份工作是在xxxxx有限公司 分公司（河南省郑州市管城回族区商英街24号、南京市雨花台区安德门大街50号B座6楼），主要担任linux系统运维工程师一职，截止到目前我已经在这家公司工作了有X个年头了，我平时工作主要负责业务系统日常运行维护和部署，线上故障的紧急处理、监控和排错、做日志采集分析，以及一些服务调优，核心工作目的还是保证服务的稳定和高效运行；

   我之前用到的服务都是有MySQL、tomcat、nginx、ansible，zabbix,elk 这些，另外我对junpserver,k8s,docker也有一些了解。我工作之余也会去通过各种教育渠道扩展一些新技术，比如RHCE以及ACA\hcie\rhca等都是利用平时休息的时间去备考的。我能够友好地处理客户工作关系，我的性格比较活泼开朗，能迅速适应各种高压工作环境，主要.....





在Linux系统中，紧急模式、单用户模式和救援模式是用于系统故障排除和修复的特殊模式：



1. **紧急模式（Emergency Mode）**：紧急模式是用于修复系统中出现严重问题时的一种模式。在这种模式下，系统只会挂载根文件系统为只读，并不会启动任何网络服务或多用户环境。通常需要管理员手动进行故障排查和修复。
2. **单用户模式（Single User Mode）**：单用户模式是系统启动时只加载基本服务和最小的系统资源，以便管理员可以进入系统进行故障排查和修复。在单用户模式下，系统启动后会直接进入root权限的命令行界面，不会启动多用户环境。
3. **救援模式（Rescue Mode）**：救援模式是一种提供故障修复和系统恢复功能的模式。通常会使用Live CD或USB启动系统，然后选择救援模式，以便管理员可以进入系统进行文件系统修复、密码重置、网络配置等操作。

这些特殊模式在系统出现故障或需要紧急修复时非常有用，可以帮助管理员快速定位和解决问题，确保系统能够尽快恢复正常运行。

## 文件权限管理##

inux权限管理是通过用户、用户组和权限位来控制对文件和目录的访问权限。每个文件和目录都有所有者、所属组和其他用户的权限设置，分为读（r）、写（w）和执行（x）权限。通过chmod命令设置权限，chown命令修改文件所有者和所属组，chgrp命令修改文件所属组。权限管理可以保护系统安全，确保数据不被非法访问或修改。



权限对象： 基本权限类型：
属主------->u 读(read)：r ---->4
属组------->g 写(write)：w ---->2
其他人------>o 执行: x(exec) ----->1
chown linfei.zy a.txt #修改属主、属组
chown linfei a.txt #修改属主
chown .linfei a.txt #只修改属组
chown linfei.zy a.txt -R #递归修改（包含目录和里面的文件）
chmod u+x a.txt #属主增加执行
chmod a=rwx a.txt #所有人等于读写执行
chmod a=- a.txt #所有人都没有权限
chmod ug=rw,o=r a.txt #属主属组等于读写，其他人只读(-rw-rw-r--)
chmod 644 a.txt #属主读写，属组只读，其他人只读
chmod u+s file #(二进制命今文件)--对某个命令进行提权，不管谁用，效果跟root一样
chmod g+s dir #使某个目录下的文件在创建时，新建文件的所属组继承该目录的所属组
chmod o+t dir #使某个目录下的所有文件只有文件创建者和root可以删除的。其他不行
chattr +a 文件名 #不允许修改，只允许追加
chattr +i 文件名 #不允许做任何操作
chattr +A 文件名 #不修改对这个文件的最后访问时间
root用户默认最高权限目录777 文件644
普通用户默认最高权限目录775文件664
-rw-r--r-







我的方向就是，只要让我做第二次的事情，那就想办法做成自动化或者简化优化过程。

**深圳市讯方技术股份有限公司是一家专业从事智能硬件研发和生产的企业，致力于为客户提供创新的智能解决方案。公司拥有一支高素质的研发团队，不断推出高品质的产品，赢得了广泛的市场认可。**

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1708566033121-fc57c8ad-099a-4246-8b93-af4d90d88568.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_31%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

亲姑姑在成都天府公园附近（）卖麻辣烫的
同学在成都的     房价好

1. 就业机会：南京作为中国的二线城市，拥有许多大型企业、科技公司和研究机构，提供了丰富的就业机会。
2. 发展前景：南京作为江苏省的省会城市，经济发展迅速，有着良好的发展前景，吸引了许多人才前来发展。
3. 生活环境：南京拥有优美的自然风光和丰富的历史文化，同时也有完善的基础设施和便利的生活条件，适合居住和工作。
4. 教育资源：南京拥有多所知名大学和研究机构，提供了丰富的教育资源，适合有子女的家庭。
5. 人文氛围：南京是一座历史悠久、文化底蕴深厚的城市，拥有丰富的人文氛围和文化活动，适合追求品质生活的人士。
6. 地理位置：南京位于长江流域，交通便利，距离上海、杭州等大城市较近，可以方便地前往其他城市出差或旅行。

  营业额 



awk 

一定不能答非所问！

之想去广州这种大城市，出于自己的职业规划，

## 公司结构

C2C 就是我卖东西你来买。
B2C 就是我成立个公司卖东西，你来买。
O2O 就是我成立个公司卖东西你来买,但是要你自己来拿。
B2B 就是你也成立了公司买我公司的东西。



115个人    运维3个人归属项目部  软件实施和软件售后，运维部（优秀的做运维）。

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1703245971118-1f868f7b-f4bf-4a90-b04a-f316c3153b29.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_15%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## 公司主营的业务

小程序开发      网站     ，我主要是用   zabbix监控指标   和 mysql维护，小程序开发用jenkins部署，  服务器大概有20多台物理服务器，因为需求，客户端上传到20台服务端，服务，监控的指标    模板里面的，cpu负载  内存    数据库的主从状态          时间      端口这些，以及日志参数，吞吐量这些。zabbix修复的是  触发器  动作sudo,很多小程序的后台，监控请求访问连接数，handles，  有时候服务坏了 但是没有连接数 怎么判定，还有监控状态。ELK搭建的是7.8的版本  会搭建三台ES  依赖JDK，HED插件查看集群的插件，logstatch  搜集  也需要JDK，kibina展示，Jsa格式的日志。很多系统日志是没有格式的，  写过的常用脚本，mysql数据库备份的脚本，脚本里面定义数据库登录的用户  密码定义变量，     连接数  查看那些端口有多少状态，ss -s        查看服务的链接端口：linux查看某个端口有多少链接、状态     netstat -an | grep <端口号> | wc -l  ，



TC TB



虚拟化主要用的KVM   ，IDC的环境 托管的服务器，业务流程：发数据清单，然后拿到服务器，内核优化，安全优化，部署需要用到的服务，shell脚本编辑主要是日常用的，自定义监控这些脚本。mv    awk截取，mysql主要是公司开发来做，我负责增删改查，备份这些，主从原理，nginx主要用到 负载均衡和反向代理和web服务器，也坐防盗链   ，ELK用的什么架构，采取量多大，



tomcat根据业务量，10-15台，分成两个部分或者三个部分，会获取更新状态是否成功，sucess的状态，会有监控tomcat的存活状态，



jenkins如果需要备份的话  备份Jenkins需要包括Jenkins的安装目录、数据目录、插件目录和各种配置文件，确保备份的数据完整且一致。最好在Jenkins停止服务的情况下进行备份，以避免数据不一致性。



跟着实施部走的，单位主要是做什么产品的，需求不同，





gitlap开发维护的

## 公司的业务部署再物理服务器还是云服务器 

物理服务器    但是我对云服务器也有了解

## 你平时在公司主要干什么

我的岗位是突击岗位；主要对外，外包。



我们成本大概10W以内   硬件啥的甲方提供的    



日常监控巡检，服务器巡检，调优。   发觉一些日常使用的脚本，日常工作行程文档化。

服务优化：nginx、tomcat，系统优化



1.负责业务系统日常运行维护，线上故障的紧急处理

2.配合研发人员，负责公司产品，日常部署，上线

3.分析系统及应用的性能问题，形成可实施的优化方案

4.负责产品的漏洞扫描，安全加固

5.负责远程或者现场解决客户出现的问题及需求沟通，平台对接等工作

6.负责机房设备的上架，排线，不定期的现场巡检

7.负责设备的正常运行，以保证设备的稳定性

8.参与编写完善各阶段的技术文档



## 产品升级的流程

nginx升级-平滑升级  加模块

java程序升级  放入WAR包  

## linux中系统参数

/**etc/sysctl.conf**

**sysctl -p 生效**

**在Linux中，可以调整的系统参数非常多，具体取决于你使用的发行版和配置文件。以下是一些常见的系统参数和它们的作用：**

1. **内核参数****：这些参数影响内核的行为，可以通过****/etc/sysctl.conf****或****/etc/sysctl.d/****目录下的文件进行配置。例如：**

- **net.ipv4.ip_forward****：启用或禁用IP转发。**
- **net.ipv4.tcp_fin_timeout****：TCP连接的超时时间。**
- **net.ipv4.tcp_keepalive_time****：TCP连接的空闲超时时间。**

1. **内存管理参数：**

- **vm.swappiness****：交换分区的使用频率。**
- **vm.vfs_cache_pressure****：清除不常用的缓存页的频率。**

1. **文件系统参数：**

- **fs.file-max****：系统中可打开的最大文件描述符数。**
- **fs.nr_open****：一个进程可以打开的最大文件描述符数。**

1. **网络参数：**

- **net.core.somaxconn****：系统中最大的监听队列长度。**
- **net.ipv4.tcp_max_syn_backlog****：TCP连接的同步队列长度。**

1. **用户和组权限****：例如，通过修改****/etc/passwd****和****/etc/group****文件来添加、删除或修改用户和组。**
2. **时间同步****：通过NTP（Network Time Protocol）来调整时间同步参数。**
3. **内核模块加载****：例如，通过****/etc/modules-load.d/****目录下的文件来加载或卸载内核模块。**
4. **系统日志****：通过修改****/etc/rsyslog.conf****或****/etc/rsyslog.d/****目录下的文件来配置系统日志的行为。**
5. **SELinux****：通过修改SELinux的策略来增强系统的安全性。**
6. **其他配置文件：例如，通过修改****/etc/fstab****来配置文件系统的挂载选项，或通过修改****/etc/hosts****来配置主机名和IP映射等。**



## linux系统优化：

**1.升级系统和软件**：定期使用包管理器（如apt、yum或dnf）升级系统和软件，以确保您拥有最新的安全补丁和功能。

**①****更新软件源列表：yum  update; ②升级系统：yum upgrade；③重新启动系统：reboot**

**2.调整内核参数**：编辑/etc/sysctl.conf文件，添加或修改内核参数，以改善系统性能。例如，您可以增加文件系统的缓存大小，调整内存管理设置等。

**①修改配置文件：/etc/sysctl.conf**

**缓存大小：fs.file-max=256000 可以提高数值**

**②内核参数生效：sysctl  -p**

**3.清理不需要的文件**：定期清理不再需要的软件包、临时文件和日志文件，以释放磁盘空间。

**①清理不需要的软件包：yum list installd ||  yum remove  <package_name>**

**②清理临时文件： rm -rf /tmp/\*  ③清理日志文件： rm -rf /var/log/syslog\***

**4.调整磁盘I/O**：通过调整磁盘I/O设置，可以改善系统的读写性能。您可以调整文件系统的挂载选项，增加缓冲区大小等。

**①查看磁盘i/o： vmstat  1**

**5.优化网络连接**：确保网络连接得到适当的配置，以提高系统的网络性能。您可以调整网络连接数、缓冲区大小和超时设置等。

**编辑/etc/sysctl.conf调整网络连接数和缓冲区大小**

6.**升级硬件驱动程序：**确保您的硬件驱动程序是最新的，以确保最佳的系统性能和兼容性。

7.**使用适当的软件**：选择适合您需求的软件包，并确保它们是最新版本。使用轻量级的桌面环境可以减少系统资源的使用。

8.**调整服务**：根据您的需求，禁用不需要的服务和后台进程，以减少系统的资源消耗。

9.**定期清理用户数据**：清理用户数据可以减少磁盘空间的使用，并提高系统的性能。

10.**进行性能测试**：使用工具（如基准测试套件）对系统进行性能测试，以了解其性能表现，并确定是否需要进行进一步的优化。

浪潮英信NF5280M6

![img](https://cdn.nlark.com/yuque/0/2023/png/39179223/1702601017883-6d1bab3b-9371-4428-bab9-a614f192e4dc.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_45%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

**戴尔易安信PowerEdge R750 机架式服务器：28核2TB**

## 服务器比较卡怎么办



**先看一下内存是的使用情况，是不是内存不够用了，如果是内存不够了可以根据服务器运行的服务决定是否要释放一下内存。然后看一下磁盘使用情况，是否空间不足，清理过期文件或者增大磁盘空间**

**接着查看cpu负载，是否有io等待占用cpu，****使用iostat确认是哪个磁盘存在io异常****，接着使用iotop或者ps确定是哪个进程导致io异常，找到进程后在/proc/进程号/io查看进程读写磁盘的字节数，然后把它杀死**



**1.top查看什么进程占用内存**

2.mysql 占用内存非常高80% cpu 500%多

3. 进入mysql -uroot -p 进入查看执行的sql语句
4. show  processlist; 查看正在执行什么sql语句

5.看见有9条sql语句死循环查询内容

6.去找开发人员问下可不可以杀掉这个进程

7.开发人员说可以 ，他们就去优化sql语句了

8.我执行 kill命令杀掉这个进程，内存就释放很多了。



## 你之前都遇到过什么棘手的问题？

**1. Top发现挖矿病毒**

中毒挖矿的特征：服务器比较卡，top查看，内存和CPU占用都比较高

2. 根据PID查找进程，回显记录下来了，当时没有截图

![img](https://cdn.nlark.com/yuque/0/2023/png/39179223/1698195909730-931f3433-172f-4654-b997-c16038044359.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

3. 看到这是lthpc这个用户起来的程序，因为服务器是购买的联泰集群，装机会默认创建这个用户，UID一般为1000 而且所有联泰集群服务器的这个用户默认密码都是Lt111111

（现在的怀疑黑客是通过这个用户进来的，反正给领导是这么汇报的）

4. 查找到进程后第一步就是kill杀死这个进程，然后这个挖矿脚本一般会存在/var/tmp下，但是当时查找没有找到。
5. 一般的挖矿病毒都会设置定时任务，通过crontab -l查看定时任务，没有找到，然后在/etc/cron.d/下也没有找到。
6. 因为我是用root用户去查看的crontab 这个是看不到其他用户创建的定时任务的，想要查看其他用户的定时任务可以进入到 /var/spool/cron
7. lthpc用户创建的定时任务就在这里了，当时着急了没有看里面内容，直接就删除了。
8. 最后使用find / -name cnrig 查找到了此脚本在/var/tmp/下有一个隐藏文件.ap

Cd /var/tmp/ 进入到目录下

9. 然后执行ll -a 查看到了隐藏文件，接着进到这个隐藏文件下，发现新天地了

![img](https://cdn.nlark.com/yuque/0/2023/png/39179223/1698195910096-7f01a16a-58a7-4f1b-bec0-4117731b26bb.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



### tomcat假死现象

tomcat假死值得是tomcat机器在有一些情况下，没有办法处理请求，服务不可用，但是仍然在运行，导致服务不可用。

导致假死的原因有：     首先查日志！

1.内存不足，如果内存不足的话，tomcat可能无法响应或者相应缓慢，解决的方法就是增加内存；

2.线程过多，因为tomcat会有一定数量 的线程来处理请求，如果线程都被占用完了，导**致**请求发生了阻塞，导致tomcat变得不可响应或者响应缓慢，解决这个办法是增加线程数； /etc/security/limit.conf

3.网络问题，网络延迟或者出现丢包情况的话可能会导致tomcat变得缓慢和无法响应，解决办法是检查网络连接是否正常，并优化网络设置；

为了诊断tomcat的那种原因，我们可以查看日志，通过日志来判断是哪个原因导致的 ，具体问题具体解决吗，或者查看服务器的资源，比如cpu，内存，磁盘，网络等

重启tomcat，因为tomcat是非常消耗资源的，有时候他的问题我们无法快速确定的时候，重启tomcat是一个很好的选择

**4.**Jvm内存溢出

有一次做活动的时候，tomcat服务器假死，导致用户打不开页面（当时我们就分析了一下吗，有可能是做活动，服务器的访问量上来了，导致数据库扛不住，但是zabbix监控显示mysql的状态正常，可能跟tomcat本身有关，查看tomcat的监听端口发现，有大量的tcp连接等待关闭，手动关闭就行了）



### mysql脑裂

脑裂的原因：在高并发的环境下，可能会出现脑裂问题，具体情况呢 可能是由于分布式系统中的多个mysql实例之间出现网络故障而导致的，这些实例之间无法进行通信和同步，因此会导致数据不一致的情况出现

解决的办法

1.配置mysql高可用性集群

为了防止mysql脑裂问题的发生，可以通过配置高可用性集群来实现。在高可用性集群中，多个mysql实例可以共享同一个数据集，这样可以避面脑裂的发生

2.使用分布式锁

分布式锁可以帮助解决mysql脑裂问题，通过使用分布式锁，可以确保在多个mysql实例之间只有一个实例能够访问资源。这样就可以避免多个实例同时访问同一资源，从而避免数据不一致的情况出现

3. 分布式事务是一种用于处理跨多个mysql实例的事务的技术。通过使用分布式事务，可以确保在多个mysql实例之间的事务操作是原子性的从而避免数据不一致的情况出现

## 系统自动杀进程：

**查看系统日志关键字（oom）**

**out  of  memory 内存溢出**

![img](https://cdn.nlark.com/yuque/0/2023/png/39179223/1701827557293-e34ec141-2a95-4d79-952c-59cd6c3c4bd3.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_16%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

**解决不了找研发优化一下**

1. 检查系统日志：使用命令journalctl -xb或dmesg来查看系统日志，寻找有关被杀死进程的错误信息。
2. 检查系统内存使用情况：如果系统内存不足，Linux内核可能会选择杀死一些进程以释放内存。可以使用命令free -m查看当前内存使用情况。
3. 检查进程是否存在错误：如果进程出现错误，可能会导致系统自动杀死它。可以使用命令ps aux | grep [进程名]来查看特定进程的状态，并使用命令strace -p [进程ID]来跟踪进程的系统调用和信号。
4. 检查系统资源限制：如果设置了过低的系统资源限制，可能会导致进程被自动杀死。可以使用命令ulimit -a来查看当前系统资源限制。
5. 调整内核参数：可以尝试调整内核参数来避免自动杀死进程。例如，可以调整vm.overcommit_memory和vm.overcommit_ratio参数来控制内存分配策略。
6. 优化程序代码：如果自动杀死进程是由于程序代码存在问题，需要从代码的角度进行优化。例如，优化程序算法、减少内存占用等。
7. 使用nohup命令：在运行程序时使用nohup命令可以将程序放在后台运行，并且不会因为终端关闭而影响程序的运行。

## 什么是位置变量，什么是预定义变量

在执行脚本时同时输入参数，这些参数对应的变量就是位置变量。预定义变量就是系统自己定义好的变量，直接可以使用

## **centos和ubuntu的区别**

● Ubuntu 基于 Debian，CentOS 基于 RHEL；

● Ubuntu 使用 .deb 和 .snap 的软件包，CentOS 使用 .rpm 和 flatpak 软件包；

● Ubuntu 使用 apt 来更新，CentOS 使用 yum；

● CentOS 看起来会更稳定，因为它不会像 Ubuntu 那样对包做常规性更新，但这并不意味着 Ubuntu 就不比 CentOS 安全；

● Ubuntu 有更多的文档和免费的问题、信息支持；

● Ubuntu 服务器版本在云服务和[容器](https://cloud.tencent.com/product/tke?from_column=20065&from=20065)部署上的支持更多。

# 基础命令

## 文件相关命令


which 后跟命令名 查找命令所在绝对路径
whoami 看当前用户是谁
pwd 查看当前所在绝对路径
**ls**
ls 查看目录中的文件 ls -a 查看目录中所有文件
ls -l(ll) 查看目录中文件的详细信息 ls -h 显示文件大小
ll -d 显示当前目录或指定目录的详情
**du**
du 显示文件和目录的磁盘使用情况
du -h 以K，M，G为单位显示 du -s 仅显示总计的大小
**cd**
cd 后跟绝对路径 切换路径 . 表示当前路径
**echo**
echo 内容 > 文件名 覆盖，将之前文件里的内容替换掉
echo 内容 >> 文件名 追加，把新内容加到后面。当文件不存在时创建新文件，并把内容加到文件中
**touch**
touch 文件名 无则创建，有则修改创建时间
touch /data/文件名 在data中创建一个新文件
touch {文件1，文件2} touch {1..12}.log 批量创建
**mkdir**
mkdir 目录名 创建目录 
mkdir /data/yy /home/jj mkdir /home/{qq,ww} 批量创建目录
mkdir -p /data/qq/aa/dd 创建连级目录，一级一级创建
**cp** 
cp 文件 路径 复制文件 
cp aa /data/bb 复制文件并改名
cp -r /data /tmp 拷贝目录
cp -r /data/aa /data/ww /etc/qq /root/ 把多个文件拷贝到同一个目录
**mv**
mv /etc/bb /root/ 移动文件 mv /root/aa /root/dd 改名
**rm**
rm -f 文件名 删除文件 rm -rf 路径 删除目录
删除指定文件以外的其他文件
shopt -s extglob #开启系统的扩展匹配模式，关闭使用-u选项
rm -rf !(1.txt|2.txt)

##  查看文件内容


cat 文件名 cat -n 显示行号
head 文件名 默认查看前十行 head -2 文件名 查看前两行内容
tail 文件名 默认查看后十行 tail -2 文件名 查看后两行内容
less或more 文件名 分页展示内容

##  编辑文件内容 


**编辑模式**
i 在光标处进入编辑模式 a 在光标后面进入编辑模式
o 在光标的下一行进入编辑模式 A 在行尾进入编辑模式
批量添加注释
ctrl+v
shift+i shift+# 两次ESC
批量删除注释
ctrl+v d
**命令模式**
gg 页首 G 页尾 6G 进入第六行 /关键字 查找字符
**文本编辑**
yy 复制 2yy 从光标开始复制2行 ygg 从光标复制到页首 yG 从光标复制到页尾
p 粘贴到下一行 P 粘贴到上一行
dd 删除一行 x 删除光标所在的字符 D 从光标删除到行尾
2dd 从光标处删除2行 dgg 从光标处删到页首
dG 从光标处删到页尾 d^ 删除光标之前的内容
u 撤销 r修改光标所在的字符
**尾行模式（shift+:）**
:10 进入第十行 :q! 不保存退出
:s/要替换的内容/替换的内容/ :2,4 s/旧/新/ 指定行替换
:%s/旧/新/ 替换所有行 :s/旧/新/g 替换行内所以关键字
:w /root/a.log 另存为/root/a.log 
:2,4 w /root/a.log 把2到4行内容另存
**时间类型**
atime 文件访问时间（access）mtime 修改文件内容时间（modify） ctime 修改文件权限和属性时间（change） modify 除了字段名其他都能改 change什么都可以改

##  用户管理


**组相关**
groupadd 组名 增加组 groupdel 组名 删除组
groupmod -g 新id 组名 改组的gid
groupmod -n 新组名 旧组名 改组名
gpasswd -a 用户 组 给组中加用户 
gpasswd -d 用户 组 把用户从组中删除
gpasswd -M 1,2 组 添加多个用户到组
**用户相关**
useradd 用户名 新增用户 useradd -g 组id 指定主属组
useradd user1 -u uid -G 主属组,附属组 创建用户指定uid和属组
usermod -l 新 旧 改名 usermod 用户名 -g 组id 改组id 
usermod -u 新uid 用户 改uid 
**文件权限**
u --> 属主 g --> 属组 o --> 其他人
r -->读-->4 w -->写-->2 x-->执行-->1
**chown 改变文件和目录的属主和属组**
chown it.hr 文件 改文件的属主属组 chown .it 文件 改属组
chown -R hr.it 目录 递归修改属主和属组
**chmod 改变文件和目录的权限**
chmod g+x 文件 = chmod 754 文件 属组加执行
chmod a=- 文件 所有人都没权限
**高级权限**
suid -->4 提升权限只对二进制文件生效，执行者将拥有程序所有者的权限 
chmod u+s 二进制文件 对命令提权，不论谁使用效果都和root一样
chmod u-s 二进制文件 取消提权
sgid -->2 组继承只对目录有效，用户对此目录有读写权，那在此目录下创建的文件的群组和目录的群组一样
chmod g+s 目录 使目录下新建文件的所属组继承目录的所属组
sticky -->1 只对目录有效，用户在该目录下创建文件目录是只有自己和root能删除
chmod o+t 目录 使目录下的文件只有创建者和root可以删

## rm命令

删除一个目录中的一个或多个文件或目录，如果没有使用 -r 选项，则 rm 不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。

```plain
rm -i *.log        删除任何 .log 文件，删除前逐一询问确认
rm -rf test        删除 test 子目录及子目录中所有档案删除，并且不用一一确认
rm -- -f*          删除以 -f 开头的文件
rm -rf *           删除当前目录下的所有文件
rm -f 其中的，f参数 （f --force ） 忽略不存在的文件，不显示任何信 不会提示确认信息。
```

yum install -y bash-completion  自动补全服务

ntpdate ntp.aliyun.com    时间同步   yum ntpdate

## find

```plain
ulimit -n     当前用户的文件描述符限制数     通过ulimit -n命令，用户可以查看当前系统中允许的最大文件描述符数量，并可以根据需要进行调整。
如果一个进程需要同时打开大量的文件或网络连接，句柄限制就显得非常重要。如果句柄限制设置得太低，可能会导致进程无法打开足够的文件或连接，从而影响其正常运行。
vim /etc/security/limits.conf

find / -type f -size +1G -delete  查询根下超过1G的文件然后删掉用什么命令

find / -type f -mtime -7   查找指定时间范围内修改过的文件     "mtime"中的"m"代表"modification"，表示文件内容最后一次被修改的时间。modification=修改
find /path/  -type f -atime -60      linux查找60天内未使用过的文件      access"，表示文件最后一次被访问的时间。
find /path/to/search -type f -name "*repo"     查找linux以repo结尾的文件
find / -type f -size +30M   "f" 表示查找的是文件   linux 查找大于30M的文件    
find /path/to/directory -type f -mtime +3             查找三天前的文件

find /XX -type f -name "*.txt"  -exec sed -i 's/old/new/g' {} +
-type f 表示只搜索普通文件。   -exec 是用来执行后续的命令。           sed -i命令会直接修改文件内容
```

## 端口

```plain
yum install nc -y
例子：nc -u -w 1  IP地址    端口  < /dev/null && echo "udp port ok"
-u参数：表示使用UDP协议进行连接。如果不指定该参数，则默认使用TCP协议。
-w 1参数：表示设置连接超时时间为1秒。如果连接在1秒内没有建立成功，nc命令将会退出。
端口：表示要连接的目标主机的端口号
lsof -i:{端口号}    例如 lsof -i:12362
ss -tulnget

net-tools  yum   下载
netstat -lntp

25  SMTP 邮件  说明：SMTP服务器所开放的端口，用于发送邮件。    
22    SSH        说明：SSH（安全登录）、SCP（文件传输）、端口重定向，默认的端口号为22/tcp。
telent 23
80/8080/3128/8081/9080   服务：HTTP   说明：HTTP协议代理服务器常用端口号，比如80用于网页浏览；8080，TOMCAT，默认的端口号。

kill -1 命令用于向进程发送SIGHUP信号，通常用于重新加载配置文件或重新启动进程

443https、3306mysql5.7、80nginx、   8080tomcat、10050zabbix-agent、10051zabbix-server、21ftp、5672rabbitmq
、6379redis、22ssh、Telnet23、jenkins8080、

nginx1.20 \ tomcat9.0.85  \ zabbix4.0 \ jenkins2.4\ rabbitmq3.7.10\  jdk11\redis6.1\mysql5.7\kafka2.11\
kibana6.5.4\gitlab12.6.3
CHMOD  -R  递归修改
```

## 常用

```plain
$ ls       # 仅列出当前目录可见文件
$ ls -l    # 列出当前目录可见文件详细
ll -t 按排序

vmstat -d     查看磁盘IO 
rpm -qa | grep "zabbix"   

who                显示在线登陆用户
whoami             显示当前操作用户
uptime          查看系统平均负载 
tload           #查看当前cpu平均负载
uptime           查看cpu负载
diff           逐行比较文件文件的差异  语法：diff [options] File1 File2
pkill -9         进程名称
df -f ext4       查看文件系统类型     
IP  R    ip route       查看网关信息  
du -sh                  查看当前目录大小    
du -sh *               查看当前位置下所有文件的大小
tar cf          定义打包文件名     源文件     #  打包
tar  xf        包名       压缩
tar  cjf       打包压缩后的文件名称.tar.bz2     源文

tar -xf  __C   解压  
unzip   解压    -d

使用cp -a  相当于将原数据原封不动的拷贝过来，不改变里面的任何信息
使用cp -r  拷贝数据，拷贝的结果是生成新的时间戳等信息

TOP   输入大写 P ，则结果按CPU占用降序排序。       输入大写M，结果按内存占用降序排序。
free  -h           查看内存使用

cd .. 返回上一级目录
cd ../.. 返回上两级目录
cd 进入个人的主目录
df -Th   查看文件系统的类型
cat /proc/version （Linux查看当前操作系统版本信息）
cat /proc/cpuinfo （linux cpu相关信息，包括型号、主频、内核信息等）
cat /etc/redhat-release  查看系统版本

日志翻页 N 
:%s/old_word/new_word/g      进行替换，如果要在整个文件中进行替换，可以在命令后面加上%
:s/^/#/        :start_line_num,end_line_numss/^/#/     注释多行内容         
:s/^#//    取消注释单行内容
:start_line_num,end_line_nums/^#//   取消注释多行内容

netstat -lntp  
ss -tuln
lsof -i -P -n | grep LISTEN        
scp /etc/yum.repos.d/nginx.repo 192.168.75.131://etc/yum.repos.d/


sort

userdel -r XX   删的彻底
vim /etc/hostname   修改主机名
0--6635  端口范围
修改文件权限，可以使用-R选     chmod -R 755 /path/to/directory
使用 ss -s 命令查看 tcp 链接状态
vim /etc/rc.d/rc.local      开机自动执行、启动的文件
 netstat -n | grep TIME_WAIT

 whereis 
 scp /etc/hosts 192.168.214.130:/etc/hosts

 sysctl -w net.ipv4.ip_forward=1   路由转发
```

## mysql



## rpm

```plain
rpm -qa 查看有的包    -e   卸载 
rpm -qa | grep "zabbix"  查看版本
rpm -e  卸载
 rpm -ivh package.rpm ：安装一个新的软件包，其中 "-i" 代表安装，"-v" 表示显示详细信息，"-h" 显示进度条。
 rpm -Uvh package.rpm ：升级一个已有的软件包，其中 "-U" 代表升级，其余参数与上述相同。
 rpm -ql 查看一个包安装了哪些文件
 rpm -qi 包名选项  -i （information） 查询软件信息  -p （package）  查询未安装的包信息，需要使用全包名
     
rpm无法解决依赖            rpm   -force  强制安装    --nodice
rpm -qc  配置文件路径  "qc" 是 "query configuration 配置" 的缩写。  

rpm -qf   查看某一个文件是那个软件产生的
```

## ![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702880074729-3ea7bccb-a7b4-450f-b05f-e143504102cc.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_14%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

- 【1】软件名    【2】版本  【3】适用系统 【4】系统架构  【5】适用rpm体系软件

## yum

```plain
yum list installed | grep XXXX      查找指定包
yum list 用于列出系统中已安装的软件包和可用的软件包
yum install package_name ：使用 Yum 包管理器安装软件包，其中 "install" 为安装命令。
yum update package_name ：使用 Yum 包管理器更新已有软件包，其中 "update" 为更新命令。
yum remove package_name ：使用 Yum 包管理器删除软件包，其中 "remove" 为删除命令。

yum repolist  查看源有多少包
yum repoinfo   查看源有多少包  更详细
yum clean, yum clean all   清除缓存目录下的软件包及旧的headers
yum provides */命令				# 查看命令是由哪个包提供的（这个命令很有帮助）

yum update 						#更新升级所有软件包
yum search string 				#根据关键字string查找安装包
运行以下命令生成缓存
yum clean all
yum makecache
```

## vim

```plain
dG       全选并删除文本
set list
set nolist
set nu：显示行号
set nonu;隐藏行号
y：复制选中的文本
yy：复制当前行              3yy复制多行
shift +d  删除后面的注释一起按
```

## cat

```plain
cat /proc/version （Linux查看当前操作系统版本信息）
cat /proc/cpuinfo （linux cpu相关信息，包括型号、主频、内核信息等）
cat /etc/redhat-release  查看系统版本
cat  /proc/meminfo   查内存
cat /proc/sys/net/ipv4/ip_forward           加1   临时生效    sysctl -p永久生效
cat /etc/sysctl.conf             sysctl -p
cat  /etc/contos-releasa    查看内核
```

## bash是什么

bash是一个命令处理器，运行在文本窗口中，并执行用户直接输入的命令

bash还能从文件中读取linux命令，称之为脚本

bash支持通配符、管道、命令替换、条件判断等逻辑控制语句

## grep

```plain
grep 'root' /etc/passwd                       过滤文件中带有root的内容
grep '^root' /etc/passwd                      过滤以root开头的行
grep 'bash$' /etc/passwd                      过滤以bash结尾的行   
 grep -v  去除 什么     grep -E 查多个     grep -c  Yes    计数几个Yes   grep -rn 在目录下找关键词 
```

## sed

```plain
修改前备份：sed -i.bak
sed -r s/7000/7001/g 7001/redis.conf | grep 7001               只输出：sed -r
 sed -i s/7000/7001/g 7001/redis.conf             只修改
```

## awk

```bash
1.根据访问IP统计UV
awk '{print $1}' access.log|sort | uniq -c |wc -l
2.统计访问URI统计PV
awk '{print $7}' access.log|wc -l
3.查询访问最频繁的URL（-n按照数值大小排序；-k指定需要排序的列）
awk '{print $7}' access.log|sort | uniq -c |sort -n -k 1 -r|more
4.查询访问最频繁的IP
awk '{print $1}' access.log|sort | uniq -c |sort -n -k 1 -r|more
5.查询访问最频繁的前10的IP
awk '{print $1}' access.log|sort | uniq -c |sort -n -k 1 -r|head -n 10
```

要查看用户访问量的 TOP 10，可以使用以下命令：



```bash
awk '{print $1}' /var/log/apache2/access.log | sort | uniq -c | sort -nr | head
awk -F ":"  '{print $1}' /etc/passwd             awk -F ":" '{print $1,$2,$3}' /etc/passwd  打印多列
awk -F ":" '{print $1"--"$3}' /etc/passwd
docker ps -a | awk '{print $1}' | tail -n +2 | xargs docker stop      tail -n   显示的行数  
xargs命令用来构建和执行命令行。它会获取来自前一个命令的输出，并将其作为参数传递给docker stop命令，从而停止每一个容器。

 awk -F "/" '{print $NF}' /etc/shells  NF打印 最后 一列
```

1. -F, --field-separator: 指定字段分隔符
2. -f, --file: 指定包含awk脚本的文件
3. -v, --assign: 定义变量并赋值
4. -i, --inplace: 直接修改文件内容
5. -W, --re-interval: 启用正则表达式中的重复操作符{m,n}

  

这条命令的含义是：

1. 使用 `awk` 命令提取日志文件中的用户IP地址或主机名（这里假设日志文件路径为 `/var/log/apache2/access.log`）。
2. 使用 `sort` 命令对提取出的用户IP地址或主机名进行排序。
3. 使用 `uniq -c` 命令统计每个用户的访问量。
4. 使用 `sort -nr` 命令按访问量进行逆序排序。
5. 使用 `head` 命令显示前 10 行，即显示访问量最高的前 10 个用户。

print $X 第几列 

这条命令会输出访问量最高的前 10 个用户的IP地址或主机名以及对应的访问量。

## 看日志

```plain
可以进行多屏显示(ctrl + f 或者 空格键可以快捷键)
tail  -n  10   test.log   查询日志尾部最后10行的日志

tail -f  动态查看

tail -n 20 filename (显示filename最后20行)
tail -n +5 filename (从第5行开始显示文件)

head -n  10  test.log   查询日志文件中的头10行日志;
cat 是由第一行到最后一行连续显示在屏幕上

stat XXX  查看innod号 IO块     硬链接  访问 修改 时间  大小

lastlog   所有用户的登陆情况
```

### 日志切割、日志轮转

### 三、logrotate日志轮转

什么是日志轮转？ 自动切日志
注：可以针对任何日志文件（rsyslog 日志、Nginx访问或错误日志…）
一、logrotate (轮转，日志切割)

1. 如果没有日志轮转，日志文件会越来越大
2. 将丢弃系统中最旧的日志文件，以节省空间
3. logrotate本身不是系统守护进程，它是通过计划任务crond每天执行
   logrotate 配置文件：
   主配置文件：/etc/logrotate.conf (决定每个日志文件如何轮转)
   配置日志轮转
   [root@linux-server ~]# vim /etc/logrotate.conf
   weekly #轮转的周期，一周轮转，单位有年,月,日
   rotate 4 #保留4份
   create #轮转后创建新文件
   dateext #使用日期作为后缀
   \#compress #日志轮替时,旧的日志进行压缩
   include /etc/logrotate.d #包含该目录下的配置文件,会引用该目录下面配置的文件

/var/log/wtmp { #对该日志文件设置轮转的方法
monthly #一月轮转一次
minsize 1M #最小达到1M才轮转,否则就算时间到了也不轮转
create 0664 root utmp #轮转后创建新文件，并设置权限
rotate 2 #保留2份
}

/var/log/btmp {
missingok #丢失不提示
monthly
create 0600 root utmp
rotate 1
}

rsyslog [日志管理](https://so.csdn.net/so/search?q=日志管理&spm=1001.2101.3001.7020)



**常见的日志文件（系统、进程、应用程序）**


\#tail -f /var/log/messages #动态查看日志文件的尾部，系统主日志文件

\#tail -f /var/log/secure #记录认证、安全的日志

tail /var/log/maillog #跟邮件postfix相关

tail /var/log/cron #crond、at进程产生的日志

tail /var/log/dmesg #和系统启动相关

tail /var/log/yum.log #yum的日志

tail -f /var/log/mysqld.log #MySQL日志

tail /var/log/xferlog #和访问FTP服务器相关

/var/log/boot.log #系统启动过程日志记录存放

# 基础概念命令

CENTOS7   之前都是用service 启动服务的

当SSH远程连接无法建立时，可能的原因如下所列：



## ssh远程链接不上的原因

1.  **网络连接问题**： 

- 目标主机的IP地址或主机名不正确。
- 网络连接不稳定或存在问题。
- 防火墙阻止了SSH连接。

1.  **SSH服务问题**： 

- SSH服务未在目标主机上运行。
- SSH服务配置错误（如端口号、允许的用户等）。

1.  **密钥认证问题**： 

- 本地计算机的私钥与目标主机上的公钥不匹配。
- 目标主机的`authorized_keys`文件中未包含本地计算机的公钥。

1.  **SSH端口问题**： 

- 目标主机的SSH服务端口不是默认的22端口，需要指定正确的端口号。

1.  **SSH配置问题**： 

- 本地计算机或目标主机的SSH配置文件存在错误。

1.  **目标主机资源问题**： 

- 目标主机资源耗尽，导致SSH连接失败。

1.  **权限问题**： 

- 没有足够的权限连接到目标主机。
- 目标主机拒绝了连接请求。

1.  **日志问题**： 

- SSH服务日志中可能包含有关连接失败的详细信息。



## 用命令打印java堆栈信息

jps -l

## crontab

看 /var/log/cron.log这个文件就可以，可以用tail -f /var/log/cron.log观察

查看系统中所有用户的定时任务： crontab -l -u username

列出系统中所有的定时任务配置文件：  ls /etc/cron.d/

查看系统中所有的定时任务执行记录：grep cron /var/log/syslog

## 运维

### 检测nginx访问成功状态码200 的IP及次数

cat /var/log/nginx/access.log | awk '$9 == "200" {print $1}' | sort | uniq -c | sort -nr

### 列出查找较多的 time_wait连接 

netstat -n | grep TIME_WAIT 

netstat -n是一个用于显示网络状态信息的命令

### 客户反应调取后端接口时特别慢，你会如何排查？请写出排查思路。

1.  **确认问题**：首先要确认客户所反映的问题是否真实存在，可以通过自己尝试调取后端接口来验证。 
2.  **网络连接**：检查网络连接是否正常。使用ping命令测试与后端服务器的网络连通性，并检查网络延迟。如果网络延迟较高，可能会导致接口调用变慢。 
3.  **服务器负载**：检查后端服务器的负载情况。使用top或htop命令查看服务器的CPU、内存和磁盘使用情况，以及当前运行的进程数，确认是否有服务器资源瓶颈。 
4.  **数据库查询**：如果后端接口需要与数据库交互，可以检查数据库的性能。确认数据库查询是否过于复杂或者缺乏必要的索引，导致查询速度变慢。 
5.  **日志分析**：查看后端服务的日志，确认是否有异常报错或者慢查询的情况。日志中可能会提供一些线索，帮助定位问题。 
6.  **代码分析**：检查后端接口的代码，确认是否存在性能问题，比如循环嵌套、不必要的IO操作等。代码中可能存在一些性能瓶颈。 
7.  **缓存使用**：确认是否可以通过缓存来提高接口访问速度，比如使用Redis或Memcached等缓存技术来缓存数据，减少对数据库的访问。 
8.  **监控系统**：如果有监控系统，可以查看历史性能数据，确认是否是近期出现的问题，以及性能指标的变化情况。 
9.  **升级优化**：如果确定问题出在后端服务本身，可以考虑对服务进行优化，升级硬件配置，或者优化代码逻辑，以提高接口响应速度。 



### 禁止 ip 10.10.10.6 访问本地80端口

 iptables -A INPUT -s 10.10.10.6 -p tcp --dport 80 -j DROP

向iptables的输入链（INPUT）中添加一条规则，指定源IP地址为10.10.10.6，传输协议为TCP，目标端口为80，并设置动作为DROP，即丢弃该IP地址访问本地80端口的数据包。

请注意，这条规则是临时性的，重启后将失效。如果需要永久生效，可以将规则保存到iptables配置文件中。 /etc/sysconfig/iptables

### zabbix-server 老是自动重启   要改什么参数

看日志

### pxe批量安装centos7系统



## JDK里面都包含什么？

jdk全称：java development kit，其意思是[java开发工具](https://so.csdn.net/so/search?q=java开发工具&spm=1001.2101.3001.7020)包。jdk是sun公司开发的，jdk包括jre（java runtime environment）java运行环境，一堆java工具[java的编译器（java c.exe），java解释执行器（java.exe）]和java基础的类库（有3000多类，常用的类150多个）。

JRE(Java Runtimely Environment)，java运行环境，只能运行.class文件，不能编译，针对用户。JRE，包含一个JVM（[java虚拟机](https://so.csdn.net/so/search?q=java虚拟机&spm=1001.2101.3001.7020)），与java核心类库与其所支持的文件。与JDK不同，它不包含开发工具—编译器，调试器和其他工具。 jre它的地位就好比一台PC机，编写的java程序一定要jre才可以运行，只要你的电脑安装了jre，那么就能够正确的运行java应用程序。

JVM(java Virtual Machine ) ，Java虚拟机，Java运行环境。Java虚拟机，是一种虚拟出来的计算机，是通过在实际的计算机上模拟仿真各种计算机功能来实现的。



jre（java的运行环境）、jvm（java虚拟机）、java类库（包含多种模块）

![img](https://cdn.nlark.com/yuque/0/2024/jpeg/40790213/1705319641492-6ab8df21-e4cb-4e61-8ee8-962621f70085.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_29%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)![img](https://cdn.nlark.com/yuque/0/2024/jpeg/40790213/1705319681117-ab399a1f-29e6-4c62-9872-5795fb621c00.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_39%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## TCP/UDP协议特点--

TCP（传输控制协议）是一种面向连接的协议，提供可靠的字节流传输，确保数据按照正确的顺序到达目的地。TCP 在传输过程中进行错误检测和重传，并提供拥塞控制机制。

UDP（用户数据报协议）是一种无连接的协议，不保证数据的可靠性和按序到达，数据包在传输过程中可能会丢失、重复或乱序。UDP 的传输方式更加高效，适用于需要快速传输数据而不需要保证可靠性的场景，如音频、视频流等

TCP特点:

1，可靠，数据传输无差错，不重复，不丢失，按序到达。

2，在数据传输之前发送方和接收方先建立连接，三次握手

UDP特点:

1，不用握手，直接传输，速度快

2，没有确认机制，不可靠

3，传输有大小限制

## Linux服务器出现异常和卡顿排查思路和步骤

1、CPU 占用率过高：当 CPU 占用率过高时，系统的响应速度会变慢，甚至出现卡顿现象。常见的原因包括进程的死循环、CPU 密集型的任务等。

持续观察内存使用情况，3s输出一次                     free -h -s 3

2、内存使用过高：当内存使用过高时，系统会使用交换分区（swap），这会导致系统的响应速度变慢，甚至出现卡顿现象。常见的原因包括[内存泄漏](https://so.csdn.net/so/search?q=内存泄漏&spm=1001.2101.3001.7020)、进程使用过多的内存等。

当存放日志、jar包文件、[数据库备份](https://so.csdn.net/so/search?q=数据库备份&spm=1001.2101.3001.7020)文件过多也会导致系统性能下降，系统崩溃

df -h

3、网络带宽不足：当网络带宽不足时，网络传输速度会变慢，甚至出现卡顿现象。常见的原因包括网络拥塞、网络带宽不足等。

没有nload命令的需要下载；

\#等待下载完                  yum -y install nload

\#直接使用命令查看            nload

4、硬盘 I/O 过高：当硬盘 I/O 过高时，系统的响应速度会变慢，甚至出现卡顿现象。常见的原因包括硬盘读写速度慢、文件系统损坏等。

vmstat  -d 

5、进程数过多：当系统中运行的进程数过多时，会导致系统资源的竞争，从而导致系统的响应速度变慢，甚至出现卡顿现象。

top      各进程是按照CPU的占用量来排序的，按x键打开/关闭排序列的加亮效果。

按内存大小进行排序。按M键。

6、系统配置不当：当系统配置不当时，也会导致系统出现异常和卡顿现象。常见的原因包括系统内核参数设置不当、硬件配置不足、[网络配置](https://so.csdn.net/so/search?q=网络配置&spm=1001.2101.3001.7020)不当等。

## 创建本地yum源

1. 加快软件包的安装速度：本地YUM源可以提供更快的软件包下载速度，因为软件包存储在本地服务器上，而不是从外部镜像站点下载。
2. 离线安装：本地YUM源可以在没有互联网连接的情况下进行软件包安装，这对于一些安全性要求高的环境非常有用。
3. 自定义软件包：管理员可以根据自己的需求定制本地YUM源，包括添加自己的软件包或修改现有软件包。



  1、上传对应镜像 

  2、 mount     镜像    目标路径      

  3、到yum.repo.d目录下   创    name

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1703680454654-302db291-92f8-485c-8779-4185ee4e16ea.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_15%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



制作本地RPM源

安装createrepo工具 

## ssh和telne

ssh跟telnet

telnet是明码传输，ssh是加密传输。telnet通过TCP/IP协议来访问远程计算机来控制你的设备，其传输的数据和口令是明文形式的。这样攻击者就很容易得到你的口令和数据。其方式也很简单，他以中间人的身份冒充你的设备截取你的数据，然后再把假数据再传给你的远程设备，从而达到攻击的目的。SSH是替代Telnet和其他远程控制台管理应用程序的行业标准。SSH命令是加密的并以几种方式进行保密。

## udp跟tcp

TCP 是一种面向有连接的传输层协议，能够对自己提供的连接实施控制。适用于要求可靠传输的应用，例如文件传输。面向字节流，传输慢

使用 ss -s 命令查看 tcp 链接状态



UDP 是一种面向无连接的传输层协议，不会对自己提供的连接实施控制。适用于实时应用，例如：IP电话、视频会议、直播等。以报文的方式传输，效率高



## 2  .zip解压

**unzip   包     -d    指定路径
**

## Centos7和8的区别.................

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1704763636130-6c7ef6dc-451f-424f-b001-ba18ef8e579e.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_54%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## 4.时间服务器

**修改时间：date -s  时间**

**ntpdate  ntp.aliyun.com**

**自动校验时间**



## 6.打包压缩的全部方法在CentOS上，可以使用以下命令来压缩文件或目录：



1. 压缩为 .zip 文件：

zip -r compressed.zip directory

这将压缩名为`directory`的目录为`compressed.zip`文件。



1. 压缩为 .tar 文件：

tar -cvf compressed.tar directory

这将使用 tar 命令将名为`directory`的目录压缩为`compressed.tar`文件。



1. 压缩为 .tar.gz 文件：

tar -czvf compressed.tar.gz directory

这将使用 tar 和 gzip 命令将名为`directory`的目录压缩为`compressed.tar.gz`文件。



1. 压缩为 .tar.bz2 文件：

tar -cjvf compressed.tar.bz2 directory

这将使用 tar 和 bzip2 命令将名为`directory`的目录压缩为`compressed.tar.bz2`文件。



1. 压缩为 .tar.xz 文件：

tar -cJvf compressed.tar.xz directory

这将使用 tar 和 xz 命令将名为`directory`的目录压缩为`compressed.tar.xz`文件。

- `-r`: 递归地压缩目录及其内容
- `-c`: 创建一个新的归档文件
- `-v`: 显示详细信息
- `-z`: 使用 gzip 压缩
- `-j`: 使用 bzip2 压缩
- `-J`: 使用 xz 压缩

## 7.解压文件的全部方法

在CentOS上，可以使用以下命令来解压文件：

```plain
1. 解压 .zip 文件：
unzip file.zip

2. 解压 .tar 文件：
tar -xvf file.tar

3. 解压 .tar.gz 文件：
tar -xzvf file.tar.gz

4. 解压 .tar.bz2 文件：
tar -xjvf file.tar.bz2

5. 解压 .tar.xz 文件：
tar -Jxvf file.tar.xz
```

在上述命令中，选项解释如下：

- `-x`: 表示解压文件
- `-v`: 显示详细信息
- `-z`: 表示使用 gzip 解压
- `-j`: 表示使用 bzip2 解压
- `-J`: 表示使用 xz 解压



## 8.使用mailx搭建邮件服务器，并且编写脚本实现监测nginx和mysql的端口是否存活，不存活，则通过邮件发送告警。

**写个计划任务**

**这个监控适用于客户不想提供监控服务器**

下载: yum -y install mailx

配置：vim   /etc/mail.rc

set from=18239023971@163.com

set smtp=smtps://smtp.163.com

set smtp-auth-user=18239023971@163.com

set smtp-auth-password=CQLCZRIJKREVCPXG

set smtp-auth=login



## 10.查看包的md5值

md5sum  +包名

校验MD5值一样再进行升级

## 11.查看网关信息

**ip  route**

**ip r**

**route  -n**

## 1.   df  -Th

**看文件系统，类型，容量，挂载**

## 2. 13.查看内存

**free  -m    查看可用内存是free+buff/cache**

## 3. 14.平均负载

**1.top**

**查看核数按：1**

**查看cpu空闲值：按d**

**cpu排序：按c**

**mem内存排序：按m**

**2.uptime**

## 4. 15.查看端口

**系统自带：ss -tanlp**

**安装的： netstat  -tanlp**

## 16.对比两个文件的差异：

**diff  file1.txt   file2.txt**

**-u参数生成更详细的输出**

**diff  -u  file1.txt  file2.txt**

## 17.查看目录大小

**du  -sh  目录路径**

**查看目录详细文件大小**

**du  -sh  目录/\***

## 5. 怎样查看系统inode号

**首先，可以使用****ls -i****命令来查看当前目录下所有文件和目录的inode号。这个命令会列出文件名和它们对应的inode号。**

**其次，如果需要查看整个文件系统的inode信息，可以使用****df -i****命令。这个命令会显示文件系统的inode使用情况，包括总的inode数、已使用的inode数、空闲的inode数等。**



## 19.测试端口连通性：

**telnet <主机名或IP地址> <端口号>**

## 6. 20.横向扩容和纵向扩容是两种不同的服务器扩展方式。

1. **横向扩容****：****通过添加多台内存和CPU差不多的服务器来实现。****这种扩容方式更适合于web层，因为web层具有以下特点：不需要太大的共享内存空间、线程之间通常依赖性不大、多是松耦合的外部互连接、可能需要不同的操作系统做不同类型的服务器。**
2. **纵向扩容****：****通过增加单个服务器的内存和CPU来实现。****这种扩容方式适用于数据库层，因为数据库服务器需要更大的共享内存空间、很多相互依赖的线程、紧耦合的内部互连接。**

**总的来说，横向扩容和纵向扩容各有其适用场景，选择哪种方式取决于具体的需求和资源限制。**



## 7. 高可用和负载均衡的区别

**这是两个概念：**

**高可用顾名思义就是尽量采取措施减少系统服务的中断时间，提高业务程序持续对外提供服务的能力****（说简单点就是防止单点故障)。**

**负载均衡是将高并发的请求数据分发到不同的   集群节点****，尽量平衡系统所有资源的压力，从而提升整个集群处理请求的能力**

## 1.临时设置linux系统文件句柄数

**ulimit  -n   句柄数**

**永久设置****/etc/security/limits.conf**

**如果一个进程需要同时打开大量的文件或网络连接，句柄限制就显得非常重要。**

**如果句柄限制设置得太低，可能会导致进程无法打开足够的文件或连接，从而影响其正常运行**

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1703761621483-6536b0b7-d25f-4386-8179-f72a3172fb55.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_11%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)   soft=  默认软限 =资源限制默认值                       hard默认硬限=系统默认最大的       最多65535   需要重新登才能激活

## dns域名解析过程

**（1）dig**

**（2）yum  -y  install   bind-utils**

**nslookup    www.baidu.com**

dns查询的结果通常会在本地域名服务器进行缓存，如果本地域名服务器中有缓存，会跳过dns查询步骤。

如果没有缓存。会进行递归查询或迭代查询



当用户输入域名时，计算机会先查询本地DNS缓存，若未找到则向根域名服务器查询，再向顶级域名服务器、权威域名服务器查询，最终获取域名对应的IP地址，完成解析过程。

## 查看mac地址

cat /sys/class/net/ens33/address

ifconfig 查询结果的ether字段就是对应网卡的mac地址



## linux把ip地址转化为mac地址

arp -n <ip_address>      方便定位出问题的机子  MAC地址的主要用途是在局域网中定位特定设备的物理地址

## CPU负载和CPU利用率



CPU负载是指系统中正在运行和等待运行的进程数，通常以过去1分钟、5分钟和15分钟内的平均负载来表示。高于CPU核心数的负载表示系统正在经历高负载。

CPU利用率是指CPU在特定时间段内的工作量，通常以百分比表示。它反映了CPU的使用程度，高CPU利用率可能意味着系统正在处理大量的计算任务。

在监控和优化系统性能时，同时关注CPU负载和CPU利用率是很重要的，可以更好地了解系统的负载情况，及时发现和解决潜在的性能问题。

## 时间同步出问题    公网      或者私网

ntpdata ntp.aliyun.com

如果是私网出问题可能是  排除硬件芯片问题      公网定制crontab -e  定时同步    



## 如果服务器硬盘显示还有200G 但是存不进东西

df -h  df -i

 for i in /*;do echo $i;find $i|wc -l;done

- for i in /*;：遍历当前目录下的所有文件和子目录。
- do echo $i;：打印当前文件或子目录的路径。
- find $i | wc -l;：使用find命令查找当前文件或子目录中的所有文件，并使用wc -l命令统计文件的数量。
- ls -i /etc/hosts  #-i：查看inode号

## 软连接和硬连接

1. 软链接（symbolic link）：

- 软链接是指向文件或目录的路径的指针，类似于Windows系统中的快捷方式。
- 创建软链接使用ln -s命令，语法为：ln -s 源文件 目标链接
- 软链接可以跨文件系统，可以链接目录，并且可以链接不存在的文件。

1. 硬链接（hard link）：

- 硬链接是文件系统中的一个实体，指向文件的索引节点（inode），删除原文件不影响硬链接，但删除硬链接不会影响原文件。
- 创建硬链接使用ln命令，语法为：ln 源文件 目标链接
- 硬链接只能链接文件，不能链接目录，而且只能链接存在的文件。

innode号也一样



软链接的主要用途包括：

1. 创建符号链接：软链接可以用来创建指向文件或目录的符号链接，方便用户访问文件或目录。
2. 跨文件系统链接：软链接可以跨越不同的文件系统，使得可以在不同的存储设备之间创建链接。
3. 更新和维护：软链接可以用于在不同的位置保持文件的一致性，当原文件更新时，软链接也会更新。

硬链接的主要用途包括：

1. 节省存储空间：硬链接可以节省存储空间，因为多个硬链接指向同一个文件，不会产生额外的存储开销。
2. 备份：可以使用硬链接创建文件的备份，因为硬链接指向同一份数据，不会占用额外的存储空间。
3. 文件共享：多个用户可以共享同一个文件，通过创建硬链接，多个用户可以访问同一份数据，而不需要每个用户都拥有一份副本。

## NTP服务器时间同步部署 -- 内网环境下,亲测有效.

[https://blog.csdn.net/footbridge/article/details/121808966?ops_request_misc=&request_id=&biz_id=102&utm_term=%E5%86%85%E7%BD%91%E5%A6%82%E4%BD%95%E5%81%9Antp%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-121808966.142^v96^pc_search_result_base9&spm=1018.2226.3001.4187](https://blog.csdn.net/footbridge/article/details/121808966?ops_request_misc=&request_id=&biz_id=102&utm_term=内网如何做ntp时间同步&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-121808966.142^v96^pc_search_result_base9&spm=1018.2226.3001.4187)

```plain
命令】yum -y install ntp         #NTP两个软件包都会安装上  【命令】rpm –qa | grep ntp        #确认是否已安装ntp
【命令】vi /etc/ntp.conf                #修改/etc/ntp.conf
(1) 在server部分添加一下部分，并注释掉server 0 ~ n      server 127.127.1.1          #表示指定当前服务器作为NTP服务器
开启ntp服务  systemctl restart ntpd.service       #修改配置文件后需重启服务  service ntpd status        #查看ntp服务状态,显示Running即可
【命令】chkconfig ntpd on               #设置ntp开机启动
开放主服务器的tcp和udp的123端口
#查看端口是否被占用:       【命令】 netstat -apn|grep 123       
#若没有netstat,先安装:       【命令】 yum install net-tools       
#端口未被占用则开放端口:
【命令】firewall-cmd --add-port=123/tcp --permanent
【命令】firewall-cmd --add-port=123/udp --permanent
#重启防火墙:       【命令】 systemctl restart firewalld.service

#再查看123端口:      【命令】  netstat -apn|grep 123 

客户端配置(其他服务器)
2.1下载ntp服务端(ntpdate):
【命令】yum -y install ntp
2.2 配置ntp服务
 【命令】vi /etc/ntp.conf                #修改/etc/ntp.conf
(1) 在server部分添加如下语句，将server指向主节点。注释掉server 0 ~ n

server 192.168.6.3
Fudge 192.168.6.3 stratum 10

关闭ntp服务
【命令】systemctl restart ntpd.service            #修改配置文件后需重启服务
【命令】/bin/systemctl stop ntpd.service        #关闭ntp服务
【命令】service ntpd status        #查看ntp服务状态,不显示Running即可

.手动同步 (一般都用自动定时同步):

【命令】ntpdate 192.168.6.3

表示五分钟同步一次时间:

*/5 * * * * /usr/sbin/ntpdate 192.168.6.3        #添加保存即可

3.3.测试同步时间

接下来就是同步测试,修改客户端时间:  date -s aa:bb:cc 

等5分钟后,输入: date  可以看到时间已同步
```

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1704796364799-1c4b05da-1c25-4a8d-879a-3d72ee778aa7.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_19%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

server 127.127.1.0					#使用本地的时间 fudge 127.127.1.0 stratum 10		#服务器的层级。作为局域网的时间同步

成功提示![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1704796313379-e85c5cc8-928a-4967-acd7-dda023485f82.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_28%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## FTP和NFS是两种不同的网络文件传输协议

[.FTP文件传输协议](https://blog.csdn.net/2301_79886522/article/details/134429203?ops_request_misc=&request_id=&biz_id=102&utm_term=nfs和ftp&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-134429203.nonecase&spm=1018.2226.3001.4187#t6)                                  [NFS网络文件系统](https://blog.csdn.net/2301_79886522/article/details/134429203?ops_request_misc=&request_id=&biz_id=102&utm_term=nfs和ftp&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-134429203.nonecase&spm=1018.2226.3001.4187#t19)

文件系统类型 FTP是一种基于客户端-服务器的协议，用于文件传输。NFS则是一种分布式文件系统协议，作为本地操作系统和远程文件系统之间的桥梁，可以实现跨平台文件共享。

传输速度和效率 由于FTP是基于客户端-服务器的协议，所以需要进行连接的建立和关闭，因此相对于NFS，FTP传输的速度较慢，效率也较低。而NFS则是通过一些标准和规定管理远程文件系统的，直接访问远程文件系统，传输速度和效率更高。

安全性 FTP协议的安全性比较差，数据传输时通常不加密，可能会被非法获取。而NFS使用一些安全机制来实现远程文件系统的访问和传输，因此相对于FTP，NFS更加安全可靠。

传输方式 FTP协议是通过FTP客户端和FTP服务器进行文件传输。而NFS通过共享文件系统的方式使用本地文件系统来挂载远程文件系统，实现文件共享。



总结： FTP协议是一种常见的文件传输协议，广泛应用于所有操作系统平台。



而NFS多用于UNIX和Linux中，虽然现在也有一些移植到其他平台的版本，但是还是没有FTP使用广泛。

## NFS服务搭建

```plain
1.安装nfs-utils与rpcbind服务
yum -y install nfs-utils
yum -y install rpcbind
2.启动nfs-utils rpcbind
systemctl start nfs
systemctl start rpcbind

3.做共享目录
#添加硬盘
#格式化文件系统
mkfs.ext4 /dev/sdb
#挂载
mount /dev/sdb /mnt
#制作nfs文件系统
vim /etc/exports
/mnt *(rw,no_root_squash,sync)（所有人为*，指定写IP）

4.重启nfs-utils与rpcbind
systemctl restart nfs
systemctl restart rpcbind

5.开机自动挂载
vim /etc/fstab
/dev/sdb/ /mnt ext4 defaults 0 0
6.mount -a

7.开机自启
systemctl enable nfs
systemctl enable rpcbind
1.1.安装nfs-utils与rpcbind服务
yum -y install nfs-utils
yum -y install rpcbind
2.启动nfs-utils rpcbind
systemctl start nfs
systemctl start rpcbind

3.挂载
mount -t nfs 服务端IP:/mnt /mnt   -t:指定文件系统类型
4.查看是否挂载
df -Th
5.开机自动挂载
vim /etc/fstab
服务端IP:/mnt /mnt nfs defaults 0 0

6.测试
在客户端/mnt下创建文件或目录，然后在服务端/mnt下查看，若有在客户端创建的文件或目录，则测试成功。
7.开机自启
systemctl enable nfs
systemctl enable rpcbind
```



## linux性能优化

## 什么是PV和UV

1. PV（PageView）：累计页面访问量，即用户每次对网站的访问均被记录，用户对同一页面的多次访问，访问量累计。PV值通常用来衡量网站的流量大小，反映网站的访问频次和访问深度。
2. UV（Unique Visitor）：独立访客数量，即访问网站的不同电脑的数量。UV值能够反映网站的受众数量和用户粘性，即网站的忠实用户数量和留存率。



## 只下载不安装

[https://blog.csdn.net/qq_37510195/article/details/129333749?ops_request_misc=&request_id=&biz_id=102&utm_term=linux%E5%A6%82%E4%BD%95%E5%8F%AA%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-129333749.142^v99^pc_search_result_base9&spm=1018.2226.3001.4187](https://blog.csdn.net/qq_37510195/article/details/129333749?ops_request_misc=&request_id=&biz_id=102&utm_term=linux如何只下载安装包&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-129333749.142^v99^pc_search_result_base9&spm=1018.2226.3001.4187)



要安装yum-utils软件包。如果系统中没有安装  yum install yum-utils

果命令下载软件包而不安装，并指定下载目录：   yum install --downloadonly --downloaddir=/root  nginx     适用于没安装过的APP

重新下载NGINX软件包，您可以使用以下命令来强制重新下载：  yum reinstall --downloadonly --downloaddir=/tmp/packages nginx   适用于已经有的APP 

## 进程和线程什么区别

#### 进程：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。（进程是资源分配的最小单位）

#### **线程：**同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。（线程是cpu调度的最小单位）

总的来说，进程是操作系统中分配资源的基本单位，而线程是进程内的执行单元，多个线程共享同一个进程的资源。进程之间的切换开销比较大，而线程之间的切换开销比较小。同时，线程之间可以更方便地进行通信和共享数据。

# 磁盘

```plain
fdisk -l 列出指定的外围设备的分区表状况
lsblk查看现有的磁盘    展示的是逻辑磁盘及挂载关系。
p	列出分区表
n	创建新的分区
d	删除一个分区
v	查看分区详细信息
e	扩展分区
q	不保存，退出
w	保存，退出

df -Th                展示的是文件系统的关系。 区别一目了然。

永久挂载需要去/etc/fstab 

lvextend

创建逻辑卷
df -i 查看iNode号满了没
for i in /*;do echo $i;find $i|wc -l;done
ls -i /etc/hosts  #-i：查看inode号
stat /etc/hosts  查看inode信息
fdisk -l /dev/sdb #查看磁盘分区信息

blkid /dev/sdb1  #查看uuid和文件系统类型

逻辑卷LVM--（Logical Volume Manager
```



## 磁盘损坏修复

在Linux中，磁盘损坏的修复主要依赖于fsck命令。以下是修复损坏磁盘的一般步骤：

1. **检查磁盘**：首先，你需要确定哪个磁盘需要修复。可以使用fdisk -l命令来查看所有可用的磁盘。
2. **卸载磁盘**：在进行修复之前，确保你已经卸载了有问题的磁盘分区。使用umount命令来卸载分区。
3. **运行fsck**：运行fsck命令来检查和修复文件系统的问题。你需要指定要检查的磁盘和分区，例如：fsck /dev/sda1。如果系统询问是否要修复，选择"yes"。
4. **检查和跳过坏块**：如果fsck找到了坏块，你可以选择跳过它们。使用-s选项可以显示进度，使用-v选项可以显示详细信息。
5. **重新挂载分区**：一旦修复完成，你可以重新挂载分区。使用mount命令来完成这一步。
6. **检查修复情况**：运行badblocks命令来检查是否还有坏块。如果没有坏块，那么修复就完成了。

请注意，对于已经挂载的分区，直接运行fsck命令可能会有风险，可能导致系统崩溃。因此，在修复之前，建议先建立一个快照或者在一个安全的环境中进行操作。

此外，对于带有S.M.A.R.T（自我监控分析报告技术）的现代磁盘，使用smartctl命令可能更为可靠和高效。如果你的系统上已经安装了smartmontools包，你可以使用smartctl -H /dev/sdX命令来修复硬盘，其中/dev/sdX是你要修复的硬盘设备名。

 、

## 安装Linux系统对硬盘分区时，必须有两种分区类型是哪两个

根分区和交换分区。                             根分区是Linux系统的安装目录，交换分区用于虚拟内存，帮助系统处理内存不足的情况。

Linux系统的根分区（/）和交换分区是在安装操作系统时自动创建的。

根分区是Linux系统的主要文件系统，包含操作系统的核心文件和目录。它通常会被安装程序自动创建，并被分配一定的磁盘空间来存储操作系统的文件和用户数据。

交换分区是用于虚拟内存的一种特殊分区，用于在物理内存不足时作为临时存储空间。在大多数情况下，安装程序也会自动创建交换分区。



## linux下使用dd命令测试磁盘的读写速度

[https://blog.csdn.net/albertsh/article/details/130395473?ops_request_misc=&request_id=&biz_id=102&utm_term=%E5%A6%82%E4%BD%95%E7%94%A8dd%E6%B5%8B%E8%AF%95%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99%E9%80%9F%E7%8E%87&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-5-130395473.142^v99^pc_search_result_base9&spm=1018.2226.3001.4187](https://blog.csdn.net/albertsh/article/details/130395473?ops_request_misc=&request_id=&biz_id=102&utm_term=如何用dd测试磁盘读写速率&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-5-130395473.142^v99^pc_search_result_base9&spm=1018.2226.3001.4187)

```plain
dd if=/tmp/testfile of=/dev/null bs=1M 
if=/tmp/testfile：从/tmp/testfile文件读取数据。  （if表示input file） 
of=/dev/null：将数据丢弃，以便只测试读取速度而不保存数据。 （of表示output file）
bs=1M：设置块大小为1MB。 
dd if=/dev/zero of=/tmp/testfile bs=1M count=1000 conv=fdatasync 
if=/dev/zero：从/dev/zero设备读取数据（无限的零数据流） 。  （if表示input file ）
of=/tmp/testfile：将数据写入到/tmp/testfile文件中。 （of表示output file） 
bs=1M：设置块大小为1MB。 
count=1000：写入1000个1MB大小的块，总共1GB的数据。 
conv=fdatasync：在每次写入后，等待数据同步到磁盘。 
dd if=/dev/zero of=/tmp/testfile bs=4k count=100k oflag=direct 
if=/dev/zero：从/dev/zero设备读取数据（无限的零数据流）。
of=/tmp/testfile：将数据写入到/tmp/testfile文件中。
bs=4k：设置块大小为4KB。
count=100k：写入100k个4KB大小的块，总共400MB的数据。
oflag=direct：绕过文件系统缓存，直接进行I/O操作。
```

总结

- /dev/zero 是一个特殊的文件，当你读它的时候会得到无限的空字符，可用来初始化文件，不产生IO
- /dev/null 也是一个特殊的文件，它丢弃一切写入其中的数据，被称为黑洞，也不产生IO
- 网络硬盘受存储带宽的影响，一旦带宽被打满，硬盘读写速度也就慢了

## vmstat -d 查看磁盘IO

iostat -d。该命令将显示系统中各个磁盘的IO使用情况，包括每秒的读写速度、IO等待时间等信息。



## raid0、raid1、raid5磁盘阵列各自特点

RAID 0、RAID 1和RAID 5磁盘阵列各自的特点如下：

RAID 0：

特点：通过条带化(striping)技术将数据均匀地分布在多个磁盘上，提供较高的数据传输性能。数据被分散存储在不同的磁盘上，可以同时读写多个磁盘，提高数据访问速度。

硬盘数量：至少需要两个硬盘。

容灾级别：没有冗余性，一颗硬盘故障将导致所有数据丢失。

RAID 1：

特点：使用镜像技术，将数据同时写入两个硬盘，提供数据冗余性和高可靠性。每个磁盘都存储完全相同的数据，如果一颗硬盘出现故障，数据仍然可以从另一颗硬盘读取。

硬盘数量：至少需要两个硬盘。

容灾级别：可以容忍一颗硬盘故障，数据仍然可用。

RAID 5：

特点：使用条带化和分布式奇偶校验(distributed parity)技术，将数据和奇偶校验信息分布存储在多个磁盘上。这样可以提供良好的数据读取性能和一定程度的冗余性。奇偶校验信息可以用于恢复一个故障磁盘上的数据。

硬盘数量：至少需要三个硬盘。

容灾级别：可以容忍一颗硬盘故障，数据仍然可用。

总体来说，RAID 0提供最佳的数据传输性能和存储容量，但没有冗余性；RAID 1提供高可靠性和冗余性，但硬盘使用率较高；RAID 5则平衡了数据传输性能、存储容量和冗余性，但需要至少三个硬盘。选择哪种RAID级别取决于实际需求和使用场景。



RAID 0提供了性能提升，但没有冗余和容错能力。   需要两块磁盘   数据容易丢失   容灾级别：没有冗余性，一颗硬盘故障将导致所有数据丢失。

RAID 1提供了磁盘镜像，具有较好的数据冗余和可靠性，但存储容量较低。   需要两块磁盘 ，    容灾级别：可以容忍一颗硬盘故障，数据仍然可用。

RAID 5提供了容量利用、性能和冗余的平衡，但需要至少3个磁盘驱动器。 有校验机制 防止数据丢失  性能和安全方面比较好  可以容忍一颗硬盘故障，数据仍然可用。



RAID 10结合了性能和冗余备份的优势。 至少四块硬盘来实现

RAID的效验机制主要包括以下几种：

1. **奇偶校验**：RAID 5和RAID 6采用奇偶校验来实现数据的校验和纠错。在RAID 5中，每个数据块的奇偶校验信息存储在其他硬盘上，而在RAID 6中，有两个独立的校验块。当读取数据时，系统可以使用校验信息来检测和恢复硬盘中的错误数据。
2. **镜像备份**：RAID 1和RAID 10通过将数据镜像备份到另一组硬盘上来提供冗余备份。当一个硬盘发生故障时，系统可以使用镜像备份中的数据来保证数据的完整性。
3. **条带间校验**：有些RAID控制器支持在条带间进行校验，以检测数据块之间的错误。这种校验机制可以帮助系统在发生数据错误时及时纠正。

总的来说，RAID的效验机制旨在提供数据的完整性和可靠性，以防止数据丢失或损坏。不同的RAID级别采用不同的效验方式，用户可以根据自己的需求选择适合的RAID级别来保护数据。



## 服务器的硬件/厂家

服务器的硬件通常包括以下组件：



1. 处理器（CPU）： 用于执行计算任务的中央处理器。
2. 内存（RAM）：   用于存储临时数据和程序代码的内存。
3. 存储设备：           用于存储数据和程序的硬盘驱动器或固态硬盘。
4. 网络接口卡：       用于连接服务器到网络的网络接口卡。
5. 电源供应器：       用于为服务器提供电力的电源供应器。
6. 冷却系统：           用于保持服务器温度在安全范围内的冷却系统，如风扇或散热器。
7. 主板：                  连接所有硬件组件的主板。
8. 显卡（可选）：              用于处理图形任务的显卡。
9. RAID控制器（可选）：  用于管理磁盘阵列的RAID控制器。

这些硬件组件共同工作，使服务器能够执行计算任务并提供服务。



一些知名的服务器制造商包括：

1. 惠普企业（HPE）
2. 戴尔科技（Dell Technologies）
3. 超微电脑（Supermicro）
4. IBM
5. 富士通（Fujitsu）
6. 甲骨文（Oracle）
7. 联想（Lenovo）
8. 苹果（Apple）
9. 华为（Huawei）
10. 浪潮集团（Inspur）

这些公司都提供各种类型和规模的服务器产品，以满足不同客户的需求。

## 流程     Logical [Volume](https://so.csdn.net/so/search?q=Volume&spm=1001.2101.3001.7020) Manger

[https://blog.csdn.net/weixin_42915431/article/details/121881054?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170532280216800182193354%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=170532280216800182193354&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-121881054-null-null.142^v99^pc_search_result_base9&utm_term=lvm&spm=1018.2226.3001.4187](https://blog.csdn.net/weixin_42915431/article/details/121881054?ops_request_misc=%7B%22request%5Fid%22%3A%22170532280216800182193354%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&request_id=170532280216800182193354&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-121881054-null-null.142^v99^pc_search_result_base9&utm_term=lvm&spm=1018.2226.3001.4187)

做成物理卷： pv ------- sdb1、sdb2 打pv的标记。

加入卷组：  vg-------- 卷组里面包含：sdb1  sdb2,建立在PV之上。

逻辑卷   lv  -------  逻辑卷是从卷组里面拿空间出来做成的逻辑卷,在起个名,建立在VG之上

制作文件系统------mkfs.xfs    lvm路径

挂载 ------mount   使用lvm



pvcreate /dev/sdb #创建pv

vgcreate vg1 /dev/sdb   #创建vg

lvcreate -L 150M -n lv1 vg1  #创建lv



添加完fstab   mount -a 直接自动挂载



mkfs.xfs

mkfs.ext4 

mount 

pvs  #查看pv

pvscan  #查看pv

vgdisplay #查看vg

vgs  #查看vg

## 扩大VG vgextend

pvcreate /dev/sdc   创建pv

vgextend vg1 /dev/sdc       #vg1卷组名字，将/dev/sdc扩展到vg1中

lvs查

[root@linux-server ~]# lvextend -l 850M /dev/vg1/lv1  #扩展到850M

[root@linux-server ~]# lvextend -L +850M /dev/vg1/lv1 #在原有基础上加850M



[root@linux-server ~]# xfs_growfs /dev/vg1/lv1  #xfs扩容

[root@linux-server ~]# resize2fs /dev/vg1/lv2   #ext4扩容



**解除挂载：umount  挂载点**

**强制解除： umount -f  挂载点**

## 交换分区

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1703323229034-75554128-4f3c-477f-8642-982e40196a8a.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_17%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

free -h  里面的交换分区用了一半了  但是

## 1. 什么是Swap？为什么需要Swap？

- Swap是一种虚拟内存技术，用于将内存中暂时不需要的数据移到磁盘空间中，以释放内存空间供其他程序使用。当物理内存不足时，Swap可以充当扩展内存的角色，避免系统因内存不足而崩溃。

## 2. 如何查看系统中Swap的使用情况？

- 使用命令free -h可以查看系统的内存和Swap使用情况。

## 3. 制作流程

[root@linux-server ~]# fdisk /dev/sdd  #分一个主分区出来

[root@linux-server ~]# partprobe /dev/sdd #刷新分区表

mkswap /dev/sdd1  #初始化

blkid /dev/sdd1  #查看UUID

vim /etc/fstab  #制作开机挂载     /dev/sdd1       swap    swap    defaults        0 0

[root@linux-server ~]# swapon -a #激活swap分区(读取/etc/fstab)

[root@linux-server ~]# swapon -s

swapon -s

\#swapoff /dev/sdd1  #关闭swap分区



## 4. 磁盘分区介绍



Linux磁盘分区主要有两种方式，一种是MBR，另一种是GPT。根据Linux磁盘分的大小，来选择一种分区方式。

——MBR分区格式：最大支持 2 TB 的磁盘。***

——GPT分区格式：最大支持 18 EB。

MBR分区方案特点：

1、最多支持四个主分区，

可以把最后一个分区作为扩展分区！！！！

要么就三个主分区，留一个逻辑分区！（扩展分区）

2、在Linux上使用扩展分区和逻辑分区最多可以创建15个分区，

3、由于分区中的数据以32位存储，使用MBR分区是最大支持2T空间。

4、fdisk管理工具只能创建MBR分区



GPT分区方案特点



1、是UEFI标准的一部分，主板必须要支持UEFI标准

2、GPT分区列表支持最大128PB(1PB=1024TB)

3、可以定义128个分区

4、没有主分区，扩展分区和逻辑分区的概念，所有分区都能格式化

5、 gdisk管理工具可以创建GPT分区



存储容量：是该存储设备上可以存储数据的最大数量，通常使用千字节（kb kilobyte）、兆字节（MB megabyte）、吉字节（GB, gigabyte）、太字节（TB ，terabyte）和PB(Petabyte)、EB(Exabyte)等来衡量。
1KB=2(10)B=1024B； 括号中的数字为2的指数(即多少次方)
1MB=2(10)KB=1024KB=2(20)B；
1GB=1024MB=2(30)B。
1TB=1024GB=2(40)B
1PB=1024TB=2(50)B
1EB==1024PB=2(60)B



fdisk /dev/sdb     d  删除     unmount  -f 

## 5. 文件系统 ext4和xfs的区别

1.首先是从性能方面去看 xfs在处理大文件的时候表现的很出色，而ext4在处理小文件的时候很好；

1.1 高并发方面的话xfs性能比ext4高5-10%左右；（也就是说xfs大文件 高并发  。 ext4小文件  相对来说并发低）

2.其次是文件大小限制。xfs可以支持单个文件打下为16TB到16EB,而ext4可以支持单个文件大小是在16GB到16TB；

3.扩展性方面的话ext4不如xfs灵活；ext4在文件系统崩溃后恢复速度比xfs快 ，但是xfs对数据保护能力好

ext4就一个恢复速度快！！！！

大==xfs在处理大文件时较为出色，  小==ext4在处理小文件的时候很好；

高并发方面    xfs的性能比ext4高5-10%左右；

扩展性方面    ext4不如xfs灵活；

ext4在系统崩溃后恢复速度比xfs快，但是xfs对数据的保护性好；

df -Th  查看系统格式



## 6. 创建LVM的步骤包括以下五步：

1. **创建物理卷：首先，需要将物理磁盘格式化为物理卷，并加入到LVM的系统中。可以使用****pvcreate****命令来创建物理卷。**
2. **创建卷组：接下来，需要创建一个卷组，将多个物理卷组合在一起。可以使用****vgcreate****命令来创建卷组。**
3. **创建逻辑卷：在卷组创建完成后，可以在卷组上创建逻辑卷。可以使用****lvcreate****命令来创建逻辑卷。**
4. **格式化：创建完逻辑卷后，需要将其格式化为所需的文件系统。可以使用****mkfs****命令来格式化逻辑卷。**
5. **挂载：最后，需要将逻辑卷挂载到指定的目录下，以便使用。可以使用****mount****命令来挂载逻辑卷。**



## 7. LVM（逻辑卷管理）的扩容步骤如下：

**vg卷组内存够的情况下：**

1. **创建新的物理卷：使用****pvcreate****命令将新的磁盘分区转换为物理卷。**
2. **扩展卷组：使用****vgextend****命令将新的物理卷添加到现有的卷组中。**
3. **扩展逻辑卷：使用****lvextend****命令将逻辑卷扩展到新的物理卷。**
4. **扩展文件系统：根据使用的文件系统类型，使用相应的命令扩展文件系统的大小。例如，对于XFS文件系统，可以使用****xfs_growfs****命令。对于ext3或ext4文件系统，可以使用****resize2fs****命令。**
5. **挂载逻辑卷：如果需要，使用****mount****命令重新挂载逻辑卷。**

**vg卷组内存不够的情况下：**

1. **扩展逻辑卷：使用****lvextend****命令将逻辑卷扩展到新的物理卷。**
2. **扩展文件系统：根据使用的文件系统类型，使用相应的命令扩展文件系统的大小。例如，对于XFS文件系统，可以使用****xfs_growfs****命令。对于ext3或ext4文件系统，可以使用****resize2fs****命令。**
3. **挂载逻辑卷：如果需要，使用****mount****命令重新挂载逻辑卷。**

## 8. ssd的优势

机械hdd  固态ssd

ssd采用电子储存介质进行数据库储存和读取的一种技术，突破了传统机械硬盘的性能瓶颈，拥有极高的储存性能，被认为是储存技术发展的未来新星

ssd不需要机械结构，完全的半导体化，不存在数据查找时间，延迟时间和磁盘寻道时间，数据存取速度快

ssd全部采用闪存芯片，经久耐用，抗震抗摔，即使发生与硬物碰撞，数据丢失的可能性也能够降到最小

得益于无机械部件及闪存芯片，ssd没有任何噪音，功耗低

质量轻，比常规1.8英寸硬盘重量轻20-30克，使得便携设备打在多块ssd成为可能，同时因其完全半导化 无结构限制，可根据实际情况设计成不同接口

# Jenkins

**Git**是分布式版本控制系统，所以，每个机器都必须注册：你的名字和Email地址。



服务端

1、创裸库git init --bare testgit

客户端

2、ssh-keygen    #生成秘钥

3、yum install -y git    git clone git@192.168.246.214:/git-test/testgit/    ls 克隆git仓库

4、   cd testgit        vim tesi.txt  使用 "git add" 建立跟踪  把 文件添加到暂存区

5、git commit -m "test1"   提交文件到仓库分支：  -m “描述

6、 git status 查看git状态：  需要先add 然后 commit 如果有修改的情况  需要重新执行add  commit               

***版本回退\***    *git log    查ID号*

*git reset --hard HEAD^   回最初始          git reset --hard dd66ff回指定的ID号*

**删除文件**

rm -rf test.txt  未添加到暂存区，可直接删除

git rm --cache test.txt #从暂存区移除

git rm -f 文件名 从工作区和暂存区移除

**修改文件**

暂存区修改名称      git mv a.txt  d.txt

#### 将代码上传到仓库的master分支

git add a.txt       git commit -m "add"         git push origin master#上传到中心仓库master分支



git branch -d 分支名 删除分支 -D 强制删除

### 创建分支并合并分支

git branch dev   #创建分支。

git branch    #查看分支。*在哪里就表示当前是哪个分支

git checkout dev   切换分支:

 git branch   *就是主分支

  ![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1705404187741-7666d50f-1d64-4a15-b17d-59e375c2d637.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_16%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

**合并分支：**

**git merge dev**

 **git push origin master**

 **git branch -d dev  合并完可以删除**



### tag版本推送

 git add *

git commit -m "new e.txt"

 git tag -a "v1.1" -m "new e.txt"

git push origin v1.1

## **jenkins的工作流程**

job的风格maven



开发那边把代码上传到gitlap,



开发上传到代码仓库，然后	从git仓库拉取代码（需要git插件，jenkins服务器下载git，并将jenkins的公钥配置到仓库的ssh密钥，jenkinsweb界面配置自己的私钥），通过maven编译打包（可以达成war包或jar包，需要jdk和maven的环境和插件），将打包好的包发送到web服务器的网站发布目录（需要将jenkins的公钥发送到web服务器对应的用户家目录）



Jenkins的工作流程包括：1）开发人员提交代码到版本控制系统；2）Jenkins监控版本控制系统的变化；3）当有代码变化时，Jenkins触发构建任务；4）Jenkins下载代码并执行构建、测试等任务；5）构建完成后，Jenkins将构建结果通知相关人员；6）如果构建成功，部署到目标环境；7）定期清理过期构建。Jenkins的工作流程可以实现持续集成、持续交付等自动化流程。

## **jenkins功能强大到哪里**

jenkins可以进行参数化构建，版本回退（可以基于修订号以及标签、分支进行版本回退或构建）。也可以实现自动发布，定时发布，需要在jenkins和gitlab仓库配置gitlab webhook插件。

## **maven是来干嘛的，编译打包的时候可以加什么参数**

我们一般编译打包的，用clean、package，但是还有其他参数，这个没有太去查过，不过应该不难，可以打成war包，发布到tomcat的默认发布目录中，或者打成jar包，直接使用命令 java -jar jar包名称 运行，一般微服务会打成jar包；

## 产品的发布流程

先将产品设计成型 > 然后再有开发人员开发代码>产品做好之后由测试人员来测试功能>最后确认产品测试正常再由运维人员发布上线

## GitHub、Gitee、Gitlab有什么区别？

- git 是一种版本控制系统，是一个命令，是一种工具。
- github 是一个基于git实现在线代码托管的仓库，向互联网开放，企业版要收钱。
- gitlab 类似 github，一般用于在企业内搭建git私服，要自己搭环境。
- gitee 即码云，是 oschina 免费给企业用的，不用自己搭建环境。

**GitHub、GitLab 不同点：**
1、GitHub如果使用私有仓库，是需要付费的，GitLab可以在上面搭建私人的免费仓库。
2、GitLab让开发团队对他们的代码仓库拥有更多的控制，相对于GitHub，它有不少的特色：
(1)允许免费设置仓库权限
(2)允许用户选择分享一个project的部分代码
(3)允许用户设置project的获取权限，进一步提升安全性
(4)可以设置获取到团队整体的改进进度
(5)通过innersourcing让不在权限范围内的人访问不到该资源

# ELK由ElasticSearch(简称ES)、Logstash和Kibana三个开源工具组成：

elk组件
(1)Elasticsearch：负责日志搜索和存储
●ES功能：搜集、分析、存储数据三大功能
●特点：分布式；零配置；自动发现；索引自动切片；索引副本机制


(2)Logstash：负责日志的收集、分析、和处理
(3)kibana：负责日志的可视化


(4)过程：
logstash安装在需要搜集日志的主机上，负责搜集日志，并发送给es集群（配置文件中input配置日志搜集的位置，filter过滤作用，output配置输出es集群的ip地址），es集群负责存储日志数据，kibana提供可视化日志分析界面



通过 Logstash 将抓取 到的数据发 ElasticSearch 集群，然后进⾏后续的数据分析活动，最后⽤ Kibana 展示结果。⽅便观察获取想要的服务的⽇志信息；



遇到问题及解决方案： Logstash 无法启动，提示 bind address；

解决方法：logstash 会加载所有 conf 格式的文件，删除不必要的文件，保留一个conf文件即可注意：在Logstash配置文件里设置索引要带有时间后缀，以便删除防止日志量大，磁盘紧张；


logstash有哪些组件
(1)input
(2)filter
(3)output

## 3、Kibana:

Kibana 是一个基于浏览器页面的Elasticsearch前端展示工具，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮你汇总、分析和搜索重要数据日志。c/s



## Grafana

Grafana 是一个监控仪表系统，它是由 Grafana Labs 公司开源的的一个系统监测 (System Monitoring) 工具。它可以大大帮助你简化监控的复杂度，你只需要提供你需要监控的数据，它就可以帮你生成各种可视化仪表。同时它还有报警功能，可以在系统出现问题时通知你。



是一个开源的数据可视化工具，用于监控和分析大规模的指标数据。它可以将各种数据源（如Prometheus、Elasticsearch、InfluxDB等）中的数据进行可视化展示，帮助用户更直观地理解数据、监控系统性能和分析趋势。Grafana提供了丰富的图表类型和灵活的配置选项，使用户可以根据自己的需求定制展示方式，同时支持报警功能，能够及时通知用户系统出现异常情况。Grafana已经成为许多公司和组织在数据监控和分析领域的首选工具之一。



## kibana和grafana

Kibana更适合用于日志数据的分析和搜索，而Grafana更适合用于时间序列数据的实时监控和可视化。

是两种流行的开源数据可视化工具，用于实时监控和分析数据。它们有以下一些区别：

1. Kibana主要用于Elasticsearch数据的可视化和分析，而Grafana可以连接多种不同的数据源，包括Elasticsearch、InfluxDB、Prometheus等。
2. Kibana更专注于日志和指标数据的可视化，而Grafana更适用于时间序列数据的可视化。
3. Kibana提供了更丰富的搜索和过滤功能，适用于处理大量的日志数据。Grafana则更强调实时监控和仪表盘的展示。
4. Kibana提供了更多的数据分析和探索功能，例如聚合、分组、排序等。Grafana则更注重数据的可视化和展示。

### elk工作流程

logstash安装在需要搜集日志的主机上，负责搜集日志，并发送给es集群（配置文件中input配置日志搜集的位置，filter过滤作用，output配置输出es集群的ip地址），es集群负责存储日志数据，kibana提供可视化日志分析界面



elasticsearch提供搜集、分析、存储数据三大功能。他的特点有：分布式、零配置、自动发现、索引自动切片，索引副本机制

### logstash有哪些组件

input、filter、output

logstash主要是用来进行日志的搜集、过滤、分析的工具，支持大量的数据获取方式，一般工作方式为C/S。client端安装在需要搜集日志的主机上，server端负责将受到的各节点日志进行过滤，修改并发送到elasticsearch上。

### logstash的过滤功能用过吗，过滤的是什么

logstash过滤功能用过，实用filter模块过滤日志或者数据，但是我们用的是filebeat实现过滤功能的，直接在采集的时候过滤不需要的内容，incloud_lines指定记录包含某些内容的行。exclude_lines指定过滤包含某些内容的行。TIPS：与multiline联合使用的时候，会针对合并后的记录再过滤。

### es集群是怎么保证数据的高可用的*

ES集群通过数据复制（不会存在同一台机器上，另外两台也会存储）和分片机制（所有信息分成片 小绿框），将数据分散存储在多个节点上，即使某个节点故障，数据仍可从其他节点获取，同时提供自动故障转移和健康监控功能，确保数据高可用性。



### 搜集过什么数据，怎么过滤的

数据没有搜集过，只搜集过日志信息，用来给开发优化代码。比如nginx的访问日志，其他服务的错误日志，主要搜集error和warn信息。通过filebeat的处理器进行过滤。

# Redis -nosql



## 不用memcached的原因：

存储的数据类型单一，且数据只能存储在内存中，

无法实现数据的持久化，服务器重启或者宕机，数据将会丢失，

不支持分布式。



redis和memcache比较 

1).Redis不仅仅支持简单的k/v类型的数据,同时还提供了list,set,zset,hash等数据结构的存储 

2).Redis支持master-slave(主-从)模式应用 

3).Redis支持数据的持久化



```plain
info replication     查看复制状态
set name jiange    #设置key--name，并设置值
get name    #获取到key
Mset    批量添加
keys *查看所有key
del 删除key
expire 给key设置过期时间
ttl 查看key的剩余有效期
exists 查看key是否存在，0为不存在，1为存在
info 查看redis的信息
flushdb 清空数据（慎用）

cluster nodes  #查看集群实例
cluster info  #查看集群信息

  cd src/   ./redis-cli  进去ping

   ./redis-cli --cluster add-node 
平衡各个主节点的槽：  ./redis-cli --cluster rebalance --cluster-threshold 1 192.168.116.172:7000
./redis-cli --cluster del-node 192.168.116.175:7007 dbad32bd47cc177de61109b96447d1f1ef6db2fc  删除节点
```

添加的主节点添加对应的从节点：./redis-cli --cluster add-node 192.168.116.175:7007 192.168.116.175:7006 --cluster-slave --cluster-master-id XXXX

平衡各个主节点的槽： ./redis-cli --cluster rebalance --cluster-threshold 1 192.168.116.172:7000 

删除节点： ./redis-cli --cluster del-node   ip:7007 ID xxxxxxxxxx



## 优缺点: 

redis有哪些好处

(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)

(2) 支持丰富数据类型，支持string，list，set，sorted set，hash

(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行

(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除
缺点:

- 没有标准化
- 有限的查询功能（到目前为止）

**特点**

1.丰富的数据结构  -----string,list,set,zset,hash等数据结构的存储

2.支持持久化

3.支持事务  ---------------事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。

4.支持主从

## **1、****R****edis有几种集群模式**

redis有三种集群模式：主从集群，哨兵集群模式、去中心化集群模式

主从模式：提供数据的多冗余，主节点和从节点提供相同的数据，主节点宕机后，集群不可用  ^^^^

vim redis.conf

1. **建立连接**：主节点和从节点建立连接。
2. **同步数据**：主节点将自己的数据发送给从节点，从节点接收并保存数据。
3. **命令传播**：主节点接收到写命令后，会先自己执行，然后将这个写命令发送给所有从节点执行，从节点接收并执行相同的写命令，以保持数据的一致性。
4. **心跳检测**：从节点会定期向主节点发送心跳检测请求，确保主节点的正常运行。
5. **故障转移**：如果主节点发生故障，从节点会选举出一个新的主节点，然后其他从节点会开始复制新的主节点的数据。

主从复制的优点包括：

- 数据冗余和备份：即使主节点发生故障，从节点仍然可以提供服务。
- 负载均衡：可以通过增加从节点来分担主节点的读取负载。
- 故障转移：在主节点发生故障时，可以快速切换到从节点提供服务。



哨兵模式：**哨兵模式类似一个****高可用方案****，在主从的一个基础上，每个节点部署哨兵，当半数以上的哨兵认为master宕机后，会随机选择一个从节点成为新的master，坏掉的master恢复后自动成为slave，****解决了单点故障****，但多台提供相同服务浪费资源**

##### 主观下线和客观下线

主观下线：**指节点自己认为其他节点已经不可用**
客观下线：**通过网络通信确认其他节点已经不可用。**



**客观下线需要多个节点达成一致，而主观下线只需要节点自己判断。**



去中心化集群模式：在Redis中，去中心化模式是指所有节点都可以相互通信和协调，没有单一的中心节点。每个节点都可以独立地对外提供读写服务，同时通过消息传递和协调算法来实现数据同步和一致性。这种模式具有高可用性和扩展性，但需要处理节点间的一致性和通信等问题。

集群。一台设备的存储能力是很有限的，但是多台设备协同合作，就可以让内存增大很多倍，这就需要用到集群。



## redis cluster特点

1.所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。

2.客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。

3.节点的fail是通过集群中超过半数的节点检测失效时才生效。

## redis-cluster数据分布

Redis-cluster集群中有16384（0-16383）个哈希槽（卡槽），每个redis实例负责一部分slot/槽位，集群中的所有信息通过节点数据交换而更新。一个hash slot中会有很多key和value。

## **redis怎么做数据备份**

写入速度慢 ----RDB快照：备份文件，文件大小比较大

写入速度快 ----AOF备份：备份的是语句

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1705391290139-80bcecd7-c9cd-402c-bc17-6c55191f3d2b.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_27%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

### Redis单点吞吐量

**单点TPS达到8万/秒，QPS达到10万/秒，补充下TPS和QPS的概念**

**1****.QPS: 应用系统每秒钟最大能接受的用户访问量**

**每秒钟处理完请求的次数，注意这里是处理完，具体是指发出请求到服务器处理完成功返回结果。可以理解在server中有个counter，每处理一个请求加1，1秒后counter=QPS。**

**2****.TPS： 每秒钟最大能处理的请求数**

**每秒钟处理完的事务次数，一个应用系统1s能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用QPS比较合理。**



### 问题2:Redis的多数据库机制  , 了解多少？

**正常：Redis支持多个数据库，并且每个数据库的数据是隔离的不能共享，单机下的redis可以支持16个数据库（db0 ~ db15）**

**集群: 在Redis Cluster集群架构下只有一个数据库空间，即db0。因此，我们没有使用Redis的多数据库功能！**

### 如何与Redis互动？

**安装服务器后，您可以运行redis安装提供的Redis客户端，也可以打开命令提示符并使用以下命令：**

**redis-cli**

### 10.使用Redis有什么好处？

**Redis非常快。**

**它支持服务器端锁定。**

**它有一个丰富的客户端库。**

**这是一个很好的反击。**

**它支持原子操作。**

### 11.使用Redis有哪些缺点/限制？

**它是单线程的。**

**它对一致哈希的客户端支持有限。**

**它具有很大的持久性开销。**

**它没有广泛部署。**



### 问题3:Redis集群机制中，你觉得有什么不足的地方吗？

**假设我有一个key，对应的value是Hash类型的。如果Hash对象非常大，是不支持映射到不同节点的！只能映射到集群中的一个节点上！还有就是做批量操作比较麻烦！**

### 你们有对Redis做读写分离么？

**正常:没有做**

**集群:不做读写分离。我们用的是Redis Cluster的架构，****是属于分片集群的架构****。而redis本身在内存上操作，不会涉及IO吞吐，即使读写分离也不会提升太多性能，Redis在生产上的主要问题是考虑容量，单机最多10-20G，key太多降低redis性能.因此采用分片集群结构，已经能保证了我们的性能。其次，用上了读写分离后，还要考虑主从一致性，主从延迟等问题，徒增业务复杂度。**

## **Redis持久化方式有几种**

vim redis.conf

2种，RDB、AOF

一、redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。

RDB（Redis DataBase）：是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；

特点:

1.周期性

2.不影响数据写入  #RDB会启动子进程，备份所有数据。当前进程，继续提供数据的读写。当备份完成，才替换老的备份文件。

3.高效     #一次性还原所有数据

4.完整性较差 #故障点到上一次备份，之间的数据无法恢复。

====================================================================================

AOF（Append Only File）则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。

特点:

1.实时性

2.完整性较好

3.体积大  #记录数据的指令，删除数据的指令都会被记录下来。



写入速度慢 ------------RDB

写入速度快 ------------AOF



1、RDB默认开启：

vim redis.conf

方式一: ./redis-cli -h 192.168.246.202 -p 6379 save   #前台进行存储

方式二    ./redis-cli -h ip -p port bgsave  #后台进行存储

2、

AOF默认关闭--开启

vim redis.conf

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1706768159756-c2415a5d-deb8-4d86-b51b-2c07e3cba3ea.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_12%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

指定aof文件名称: appendfilename appendonly.aof 

## **Redis和Mysql的区别**

mysql支持通用sql语句，redis不支持。

mysql使用固定表结构，可用复杂查询。

mysql的数据存储方式单一，redis数据存储比较灵活。

mysql数据存储于磁盘，对于高并发的读写请求，磁盘io是很大的瓶颈。

redis的数据存储于磁盘或者内存中，读写效率更高。

## **redis针对内存过高**

设置key的过期时间，对于不经常使用的key过期时间可以设置的小一点。redis会将所有设置了过期时间的key放入一个字典中，然后每隔一段时间从字典中随机取一些key检查过期时间，并删除已过期的key。

expire

ttl



## Redis哈希槽的概念？

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。



Redis集群最大节点个数是多少？

16384个。

## **reids上存储什么数据**

热点数据：一般会存一些经常查询且变动不是很频繁的数据

比如：新闻网站实时热点、微博热搜等，需要频繁更新。总数据量大得时候直接从数据库中查询会影响性能。

电商网站信息：大型电商平台初始化页面数据的缓存。比如去哪网购买机票的时候首页的价格和你点进去的价格会有差异



## 缓存的高可用性

缓存层设计成高可用，防止缓存大面积故障。即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如 Redis Sentinel 和 Redis Cluster 都实现了高可用。

## 缓存雪崩



Redis缓存雪崩是指在缓存大规模失效或同时失效时，导致大量请求直接打到数据库，造成数据库压力剧增。CPU和内存负载过高，甚至宕机。



产生雪崩的简单过程：

1、redis集群大面积故障

2、缓存失效，但依然大量请求访问缓存服务redis

3、redis大量失效后，大量请求转向到mysql数据库，mysql的调用量暴增，很快就扛不住了，甚至直接宕机

4、由于大量的应用服务依赖mysql和redis的服务，这个时候很快会演变成各服务器集群的雪崩，最后网站彻底崩溃。

\#解决：



## 1.缓存的高可用性

缓存层设计成高可用，防止缓存大面积故障。即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如 Redis Sentinel 和 Redis Cluster 都实现了高可用。



## 2.缓存降级

Redis缓存降级指在 缓存失效或压力过大时，临时降低对缓存的依赖，直接访问数据库，以保证系统稳定性。



可以利用ehcache等本地缓存(暂时支持)，主要还是对源服务访问进行限流、资源隔离（熔断）、降级等。

当访问量剧增、服务出现问题仍然需要保证服务还是可用的。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级，这里会涉及到运维的配合。

降级的最终目的是保证核心服务可用，即使是有损的。

在进行降级之前要对系统进行梳理，比如：哪些业务是核心(必须保证)，哪些业务可以容许暂时不提供服务(利用静态页面替换)等，以及配合服务器核心指标，来后设置整体。



## 缓存穿透

缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。

解决：

如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。

## 缓存并发

这里的并发指的是多个redis的client同时set key引起的并发问题。其实redis自身就是单线程操作，多个client并发操作，按照先到先执行的原则，先到的先执行，其余的阻塞。



## 缓存熔断

在缓存系统压力过大或异常情况下，临时关闭对缓存的访问，避免对后端系统造成更大的压力。



Redis缓存熔断是一种保护机制，当缓存系统负载过高时，停止对缓存的访问，将请求直接转发到数据库，以减轻缓存系统压力，保证系统稳定。

## 缓存预热

在系统启动或高峰期到来前，提前将热点数据加载到缓存中，以降低对数据库的访问压力。

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。

这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

解决：

1、直接写个缓存刷新页面，上线时手工操作下；

2、数据量不大，可以在项目启动的时候自动进行加载；

目的就是在系统上线前，将数据加载到缓存中。



## **redis哨兵原理**

哨兵是一个独立的进程，原理就是哨兵通过发送命令，等待redis主节点响应，超过指定时间没有响应，哨兵会认为主节点下线了，选举从节点成为主节点。其中涉及到一个主观下线和客观下线。

指定时间内哨兵没收收到目标节点的响应会认为 该节点主观下线，当半数以上的哨兵认为该节点下线后则认为客观下线，然后会发起选举，选举从节点成为主节点。



# MYSQL

## mysql的MHA和MIC的区别



MHA：

- 开源工具
- 实现MySQL主从复制的自动故障切换和故障恢复
- 简单配置和管理工具

MIC：

- 商业化解决方案，由Percona提供
- 将多个MySQL实例链接在一起，实现数据复制和自动故障转移
- 更灵活的配置选项和高级功能





alter table 表名 engine = myisam;    修改MYSQL存储引擎

```plain
删除数据：delete from 表名 where id=6;(删除一整条数据)  删除全部数据：delete from 表名
查看用户权限： select user,host from mysql.user;(mysql库里的user表里)
修改普通用户密码：use mysql； set password for user@'localhost'='new_password';
移除权限：revoke select,delete on *.* from jack@'%';   #回收指定权限
```

### MySQL的读写分离怎么配置实现？

基于MyCat实现读写分离。

实现过程：

1.MySQL主从同步的实现。

修改master服务器的配置文件，配置server-id以及binlog，

配置从服务器配置文件的server-id以及中继日志；再对账号赋予从库的权限，连接从库；

2.MyCat读写分离的实现。

在MySQL集群的基础上，配置Java环境（JDK），安装MyCat中间件，配置环境变量；

修改MyCat的server.xml文件，配置前端连接MyCat的用户密码、主机地址等；

修改schema.xml文件，配置后端数据库属性，balance=1开启读写分离，writeType=0为备份型；

再启动MyCat就可以了。

### 12.MyCat是什么？你还了解哪些MySQL的代理？

MyCat是（阿里巴巴推出的）DB Proxy数据库中间件，也称为代理器，用来接收用户的访问请求，根据请求类型的不同分发给后方数据库。

功能：

1.读写分离（基于集群），将select读操作与inseert/update/delete写操作，按类型分开请求信息，实现主写从读。

2.负载均衡

3.支持数据的分片自动路由与聚合

\------------------------------------------------

其他代理产品：

1.MySQL Proxy --- MySQL官方

2.DBProxy --- 美团点评

3.Atlas --- 奇虎360

4.Amoeba --- 早期阿里巴巴

5.coder --- 阿里巴巴

## MYSQL部署架构都有哪些

读写分离，一主多从，高可用  



**安全方面**：修改默认端口号，禁止root用户远程登录，对用户降权，以普通用户运行mysql

**性能方面：**升级硬件，内存、磁盘、优化sql语句（开启慢查询）、设置索引

**参数优化**：innodb的buffer参数调大，连接数调大、缓存的参数优化

**架构方面**：读写分离，一主多从，高可用

### MySQL主从延迟的解决方案

**主从延迟的来源**

主库和从库在执行同一个事务的时候出现时间差的问题，主要原因包括但不限于以下几种情况：

有些部署条件下，从库所在机器的性能要比主库性能差。

从库的压力较大，即从库承受了大量的请求。

执行大事务。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。如果一个主库上语句执行 10 分钟，那么这个事务可能会导致从库延迟 10 分钟。

从库的并行复制能力。





## mysql增删改查

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702537443960-7c257ff4-3038-404a-96f3-be54b51e6e23.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_50%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

修改表名：rename table 旧 to 新；

​                 alter table 旧 rename 新；

指定端口:

mysql -uroot -p'密码'  -h 地址   -p 端口



\#创建用户为tom，并设置密码：

create user tom@'localhost' identified by 'qf@123'; 



GRANT  ---授权：

GRANT ALL ON *.* TO 'user3'@’localhost’;  #权限 库名.表名  账户名            



修改远程登陆:

update user set host = '192.168.246.%' where user = 'user3';



查看权限： SHOW grants\G





## **mysql设置远程连接用户**

```plain
 create user 'remote_user'@'%'  identified by '密码'；                         客户端创建一个用户
 grant all privileges on * . *  to 'remote_user'@'%' with grant option;    然后对这个用户进行授权
 lush privileges;                                    刷新一下数据库；
 mysql -u‘remote_user’-p'密码'  -h‘ip’                   然后在客户端用
```

## **mysql授权用户的权限**

mysql授权涉及到哪几个表    授权的范围       本机 百分号  单独的用户 

```plain
show grant for  'username'@'localhost';
create user 'username'@'localhost' identified by 'password';创建用户：如果用户不存在，首先需要创建用户。可以使用以下语句创建用户：
grant select, insert, update ON database.* to 'username'@'localhost';授予权限：使用GRANT语句授予用户相应的权限，例如：
FLUSH PRIVILEGES;  刷新权限：在完成授权后，需要刷新MySQL的权限，使新的权限设置生效：
```

## 常用的命令

```plain
数据库删表（只删数据）   delete from 表名
DELETE FROM 表名 WHERE 条件;  删除数据：
INSERT INTO 表名 (列1, 列2, ...) VALUES (值1, 值2, ...);    插入数据：
DESCRIBE 表名;        显示表结构：
ALTER TABLE 表名 DROP COLUMN 列名;   删除字段
DELETE  字段名  FROM 表名  WHERE 条件;          DELETE  FROM users WHERE id = 5;


1.修改名称、数据类型、类型 
alter table 表名 change 旧字段 新字段 类型; #change修改字段名称，类型，约束，顺序 
mysql> alter table t3 change max maxs int(15) after id;  #修改字段名称与修饰并更换了位置
2.修改字段类型，约束，顺序
alter table 表名 modify 字段 类型； #modify 不能修改字段名称
mysql> alter table t3 modify maxs int(20) after math;    #修改类型并更换位置
3.删除字段
mysql> alter table t3 drop maxs;  #drop 丢弃的字段；

对单个字段进行倒序排序：
SELECT * FROM table_name ORDER BY column_name DESC;
对多个字段进行倒序排序：
SELECT * FROM table_name ORDER BY column1 DESC, column2 DESC;

对单个字段进行升序排序：
SELECT * FROM table_name ORDER BY column_name ASC;
对多个字段进行升序排序：
SELECT * FROM table_name ORDER BY column1 ASC, column2 ASC;
mysql -e

alter table 表名 engine = myisam;    修改MYSQL存储引擎
```



## 多表查询

可以使用多种方法进行多表查询，包括使用JOIN、UNION、子查询等。

1. 使用INNER JOIN连接两个表：

SELECT * FROM table1   INNER JOIN table2 ON table1.字段名 = table2.字段名;

\# 隐式内连接

select 字段列表 from 表1,表2 where 条件;



2. 使用LEFT JOIN连接两个表，返回左表中的所有行以及与右表匹配的行：

SELECT * FROM table1  LEFT JOIN table2 ON table1.字段名 = table2.字段名;



3. 使用UNION连接两个表，返回两个表中的所有行：

SELECT 字段名 FROM table1  UNION   SELECT 字段名 FROM table2;



4. 使用子查询连接两个表，将一个查询的结果作为另一个查询的条件：

SELECT * FROM table1 where 字段名 IN (select 字段名 from table2);

## **mysql如何删除用户**

drop user 用户@主机  删除用户 但是想保留数据库对象cascade

创建用户：先用管理员用户登录mysql，再用create user语句去创建用户

## **导致sql执行慢的原因  \**\**\***

1.硬件问题 比如网络速度慢，内存不足，I/O吞吐量小，磁盘空间满了等

2.没有索引或者索引失效

3.数据过多 

4.服务器调优以及各个参数的设置

## **简关系型数据库和非关系型数据库的区别**

关系型数据库：

优点：易于维护，使用方便，支持复杂操作

缺点：读写性能差，灵活度不够，高并发读写需求对磁盘I/O要求高

非关系型数据库：

优点：格式灵活、速度快、高扩展性、成本低

缺点：不提供sql支持、无事务处理、数据结构相对复杂，复杂查询稍欠

● 生产环境主流的关系型数据库有 Oracle、Microsoft SQL Server、MySQL/MariaDB等。

● 生产环境主流的非关系型数据库有 MongoDB Memcached Redis

## **主从复制原理 \**\**\***

主库开启binlog日志 授权用户密码

在主库将数据的增删改查等sql语句记录到binlog二进制日志中

从库通过IO线程，将主库上的日志复制到自己得rekay-log 中继日志中

从库sql线程读取中继日志中的事件，将其重放到从库的数据库中

22

首先主库开启binlog日志和授权用户密码，然后主库的增删改查等SQL语句会记录到二进制日志里面，

其次从库会通过IO线程，把主库上的日志复制到自己的中继日志中，从库的SQL线程会读取这个事件，从而达到主从效果。

```plain
[root@mysql-master ~]# vim /etc/my.cnf   
server-id=1                 #定义server id master必写 
log-bin = mylog               #开启binlog日志，master比写
gtid_mode = ON                 #开启gtid
enforce_gtid_consistency=1      #强制gtid

 systemctl restart mysqld   #重启
 grant replication  slave,reload,super on *.*  to 'slave'@'%' identified by 'Qf@12345!';
  flush privileges;
[root@mysql-slave ~]# vim /etc/my.cnf
server-id=2
gtid_mode = ON
enforce_gtid_consistency=1
master-info-repository=TABLE
relay-log-info-repository=TABLE

[root@mysql-slave ~]# systemctl restart mysqldm
[root@mysql-slave ~]# mysql -uroot -p'qf123'   #登陆mysql
mysql> \e
change master to
master_host='master1',      #主ip 地址  最好用域名
master_user='授权用户',     #主服务上面创建的用户
master_password='授权密码', 
master_auto_position=1;
-> ;

start slave; 
show slave status\G  #查看状态，验证sql和IO是不是yes 。
```

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702537444044-5f4ebdce-965b-4a3f-9844-40cc37c44454.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_24%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



## mysql主从复制的作用和用途

数据备份和灾难恢复

负载均衡

实时数据分析

高可用性

主从复制可以提高数据库系统的可靠性、性能和可伸缩性，同时也为数据备份、灾难恢复和实时数据分析提供了支持。

## **主从方式有几种\**\**\***

一般公司都是 一主一从

有两种方式

binlog日志方式：从节点需要手动去锁定日志文件的名称和位置

gtid方式：从节点不需要手动指定binlog日志的名称，位置 ，会自动锁定MySQL主从复制的binlog方式和gtid方式的主要区别如下：



1. 日志记录方式

-  binlog方式：主服务器记录操作日志到二进制日志(binary log)文件中，记录的是操作语句。 
-  gtid方式：主服务器记录操作日志到gtid_executed表中，记录的是全局唯一标识符(GTID)。 

1. 位置跟踪

-  binlog方式：从服务器依靠文件位置和文件名来跟踪复制位置。 
-  gtid方式：从服务器使用GTID集合来记录和跟踪已复制事务，不依赖文件名和文件位置。 

1. 自动恢复

-  binlog方式：如果从服务器复制中断，需要手动恢复复制位置。 
-  gtid方式：如果从服务器复制中断，可以自动根据GTID集合恢复中断点。 

1. 多主复制

-  binlog方式：不支持自动切换主从关系。 
-  gtid方式：支持多主复制，从服务器可以自动感知主服务器故障并切换到其他主服务器。 

1. 事务一致性

-  binlog方式：可能会导致事务不一致，比如文件删除导致的 gaps。 
-  gtid方式：通过全局唯一的GTID保证事务的全局有序性和一致性。 



总体来说，gtid方式相比binlog方式具有自动同步位置恢复和多主切换等优点，支持更高级别的主从复制功能。

但gtid需要MySQL版本支持，binlog方式适用于任何MySQL版本。



## **MySQL的同步方式  三种\**\**\**\**\**\***

「异步复制」：MySQL 默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给客户端，并不关心从库是否已经接收并处理。这样就会有一个问题，一旦主库宕机，此时主库上已经提交的事务可能因为网络原因并没有传到从库上，如果此时执行故障转移，强行将从提升为主，可能导致新主上的数据不完整。

「全同步复制」：指当主库执行完一个事务，并且所有的从库都执行了该事务，主库才提交事务并返回结果给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

「半同步复制」：是介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库接收到并写到 Relay Log 文件即可，主库不需要等待所有从库给主库返回 ACK。主库收到这个 ACK 以后，才能给客户端返回 “事务完成” 的确认



## **mysql的数据备份有几种\**\**\***

逻辑备份：mysqldump，备份sql语句，速度慢，恢复也慢，需要一条一条执行sql语句  麻烦

备份：

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1704677829314-7a73180a-e3d3-4bdb-8fa5-8b8980fac39f.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_23%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

恢复：

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1704677968586-9975d055-da67-4471-802f-43133e2a4e24.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



物理备份：xtrabackup备份，备份速度慢，文件大，恢复速度快。

物理备份又分为3种备份方式：

完全备份：备份当前的所有数据

增量备份：备份上一次备份到当前时间点的更新的所有数据（上一次备份可以是全备也可以是增量备份），数据占用磁盘空间小，但恢复过程较复杂

差异备份：备份上一次完全备份到当前时间点的所有数据，占用磁盘空间比较大，恢复过程简单

备份策略：周日做全备，周一到周六每天增量备份，结合计划任务定期处理7天前的备份数据（迁移到其他安全的地方）

## **事务的四个特性**

原子性：指事务是不可拆分的最小单元

隔离性：数据库允许多个事务同时对数据库的数据进行读写和修改的能力，为了防止多个事务并发执行由于交叉执行导致的数据不一致。隔离级别分为读未提交、读提交、可重复读、串行化。隔离等级越高，数据越安全，但是消耗的资源就越多。

一致性：事务中的sql语句，要么全部成功，要么全部失败。￥￥￥

持久性：事务结束后，对数据的修改是永久写入到磁盘的，即使系统故障也不会丢失

## **MySQL 索引的分类与区别**

\- 普通索引（INDEX）：索引列值可重复

\- 唯一索引（UNIQUE）：索引列值必须唯一，可以为NULL

\- 主键索引（PRIMARY KEY）：索引列值必须唯一，不能为NULL，一个表只能有一个主键索引

\- 全文索引（FULL TEXT）：给每个字段创建索引

```plain
DROP INDEX index_name ON table_name;   删除索引：
CREATE INDEX index_name ON table_name (column_name);      创建单列索引：
SHOW INDEX FROM tab_name;      查看索引
ALTER TABLE student7 ADD PRIMARY KEY (id);       加主键索引
```

### MySQL 不同类型索引用途和区别

\- 普通索引常用于过滤数据。例如，以商品种类作为索引，检索种类为“手机”的商品。

\- 唯一索引主要用于标识一列数据不允许重复的特性，相比主键索引不常用于检索的场景。

\- 主键索引是行的唯一标识，因而其主要用途是检索特定数据。

\- 全文索引效率低，常用于文本中内容的检索。

## **脏读、幻读，不可重复读是什么**

脏数据：他是因为数据重复输入，共同处理等不规范操作而产生的混乱，无效数据

脏读：一个事务读取了另一个事务未提交的数据，即读取到了不正确的数据

幻读：一个事务前后两次读取，而另一个事务在读取的中间进行了插入 导致读取到的数据增多。

不可重复读：在第一个事务前后两次读取的过程中，由于第二个事务的修改 导致两次读取到的内容不一样

丢失的修改：两个事务同时修改同一行数据并提交，其中一个事务被另一个事务修改覆盖

## **数据库引擎  \**\****

InnoDB存储引擎:默认引擎，最常用的，支持事务，支持行锁定

MyISAM拥有较高的查询速度，但不支持事务

MEMORY存储引擎将表中的数据存储到内存中，为查询和引用其他表数据提供快速访问

alter table 表名 engine = myisam;    修改MYSQL存储引擎

## **mysql的数据类型   \**\**\***

整数型、浮点型、文本字符串类型、日期时间类型、枚举型、集合型

## **mysql的约束添加**

主键：用于唯一的标识表行的数据，当定义主键约束后，此列不能重复

不能为空：定义not null后，此列的值不能为空

default：默认约束，即使插入数据没有值，都会有默认值

unique：唯一约束，该列不允许重复



自增键

```plain
create table student6(id int not null, name varchar(100) not null, birthday date, sex char(1) not null, primary key (id));       主键索引
show index  from 表名；    查看索引；
```



## **mysql主从复制不一致的原因  \**\****

mysql主从复制不一致的主要原因总结如下：

**SHOW MASTER STATUS;**

SHOW SLAVE STATUS;





1.  网络延迟。主库和从库之间网络延迟导致binlog事件传播速度跟不上事务提交速度。 
2.  配置不匹配。如主从数据库版本、binlog格式、server_id设置不一致等配置问题。 
3.  处理能力不足。主库事务处理能力紧张，或者从库处理binlog事件能力不足无法跟上主库速度。 
4.  同步参数设置不当。如slave_net_timeout、sync_binlog等参数设置不合理。 
5.  网络中断。主从库网络连接中断导致binlog事件丢失或重复同步。 
6.  数据操作问题。如手动在从库执行语句导致数据不一致。 
7.  binlog记录错误。如主库硬盘错误导致binlog丢失或错误无法解析。 
8.  SQL模式不一致。如主从库SQL模式设置导致执行结果不同。 
9.  主从切换期间。主从切换过程可能存在短暂的数据不一致。



以上九点原因概括了mysql主从复制常见的不一致根源。



## **读写分离的好处  \**\****



1.提高性能：通过将读操作分散到从库，可以显著减少主库的负载，从而提高整体数据库性能。

2.节省技术成本：将读写分离后，可以降低对主库的性能要求，从而节省技术成本。3.更多的资源可以集中在主库的性能优化和开发工作上。

3.数据安全：读写分离可以显著降低主库的注入风险，提高数据库系统的安全性。

4.更好的事务控制：通过读写分离，可以更好地控制事务，保障数据库的完整性和一致性。

5.提高并发性：主库主要处理写操作，从库处理读操作，这样主库的写操作不会影响到从库的读操作，提高了并发性。

6.容灾能力：通过建立多个容灾副本，即使发生灾难，也可以快速切换到其他服务器，减少数据损失，提高系统的可用性。

7.简化应用程序设计：应用程序可以根据需要选择使用主库或从库，例如增删改使用主库，查询使用从库，从而简化应用程序的设计。

## **mysql的优化**                        [**https://liucy.blog.csdn.net/article/details/131936739**](https://liucy.blog.csdn.net/article/details/131936739)

可以从四个方面进行优化 

首先可以从安全方面：修改mysql的默认端口号，禁止root用户远程登录，对用户降权，以普通用户运行mysql，

然后就是性能方面：对他的内存 硬件，磁盘进行一个升级，优化一下sql语句，设置索引

参数优化：innodb的buffer参数调大，连接数调大，缓存参数的优化

架构方面：可以给mysql数据库坐一个读写分离，一主多从，高可用



1.修改默认端口：MySQL默认端口为3306，容易被攻击者扫描到，建议修改为其他端口。

2.安装防火墙：通过配置防火墙，可以控制数据库的访问权限，并防止恶意请求。

3.强化密码：使用强密码并定期更新。避免使用简单的密码，比如123456和qwerty等。强密码包括：（复杂密码应包括大小写字母、数字和特殊字符），可参考此文章随机生成密码：【Linux】Centos7 随机生成密码

4.删除无用的账户：删除不必要的账户以减少攻击面。

5.开启SSL/TLS连接：开启MySQL的ssl选项，启用加密传输可以提高安全性。

6.控制访问权限：控制应用程序对MySQL的操作权限，限制只能读取和操作必要的表、字段和行。

7.开启日志：开启MySQL的日志功能，记录所有的查询操作，以便后期审查和追踪攻击来源。

8.定期备份数据，并将备份数据存储在安全的位置。备份是防止数据丢失和恢复数据的重要手段。这里推荐一份定时定期备份数据的脚本：mysql数据库定时备份脚本+定时删除 。

9.禁用root远程登陆，启用访问控制： 在MySQL配置文件中启用访问控制，只允许特定的IP地址或主机名访问数据库。这样可以防止未授权的访问尝试。

10.监控和警报： 设置数据库监控工具和警报系统，及时发现和响应潜在的安全事件和异常活动。

————————————————



mysql是关系型数据库，支持事务，支持标准语句，支持行锁定，使用表结构 ，支持复杂查询，数据库存储到磁盘，比较安全，但是固定表结构，数据存储方式不够灵活，读写性能差，在高并发的情况下，磁盘i/o是很大的瓶颈

redis是非关系型数据库，nosql产品--redis，mongodb，memcached。不支持事务，存储格式灵活，可以是key-value形式，也可是图片，文档，等形式，读写速度快，可以使用磁盘或者随机存储器作为载体，具有高扩展性，但是不支持sql语句

## **你是怎么优化sql语句的**

1.对查询进行优化，应尽量避免全表扫描，首先应考虑在where及order by涉及的列上建立索引

2.应尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select ID from t where num is null 可以在num上设置默认值0  select id  from t where num = 0

3.任何地方都不要使用select * from t ， 用具体的字段列表代替“*”，不要返回用不到的任何字段。

4.避免频繁的创建和删除临时表，减少系统表资源的消耗



## **mysql导致cpu飙升如何处理**

1.多实例的服务器，先top查看是哪一个进程，哪个端口占用的CPU多

2.show processes list；查看是否由于大量并发，所引起的负载问题

3.如果不是的话，查看慢查询，找出执行时间长的sql，explian分析sql是否走索引，sql优化

4.在查看是否缓存失效引起的，需要查看buffer命中率；

查语句是否有大量的update，查qps

## **mysql脑裂怎么办**

脑裂的原因：在高并发的环境下，可能会出现脑裂问题，具体情况呢 可能是由于分布式系统中的多个mysql实例之间出现网络故障而导致的，这些实例之间无法进行通信和同步，因此会导致数据不一致的情况出现

解决的办法

1.配置mysql高可用性集群

为了防止mysql脑裂问题的发生，可以通过配置高可用性集群来实现。在高可用性集群中，多个mysql实例可以共享同一个数据集，这样可以避面脑裂的发生

2.使用分布式锁

分布式锁可以帮助解决mysql脑裂问题，通过使用分布式锁，可以确保在多个mysql实例之间只有一个实例能够访问资源。这样就可以避免多个实例同时访问同一资源，从而避免数据不一致的情况出现

3. 分布式事务是一种用于处理跨多个mysql实例的事务的技术。通过使用分布式事务，可以确保在多个mysql实例之间的事务操作是原子性的从而避免数据不一致的情况出现

## **yum安装mysql的过程以及5.7与8.0的区别**

首先先确定一下 我们有没有mysql的repo源，没有的话 wget去下载mysql-community的rpm 下载完之后会发现yum仓库里会多出来 一个mysql-community的repo包 这个时候可以根据我们的需要去选择我们版本 通常情况下用的是5.7版本 因为相对来说，它更稳定 基本上对所有的软件都兼容  而8.0版本 虽然说更新了 更多的功能 而且他的处理速度也更快 但是 可能有些软件不兼容8.0   当然 如果有些软件兼容  你也需要更丰富的功能和效率你也可以使用8.0  进入mysql的repo包里更改参数切换到你需要的版本 然后关闭认证检测 下载完成后启动mysql  root用户会随机生成密码 过滤初始密码 并进行修改，更改完成之后就可以登录使用了

## **修改成简单密码**

im /etc/my.cnf   #在最后添加如下内容

validate_password=off

## **如果mysql密码忘记了怎么办**

```plain
关闭mysql服务
修改 /etc/my.cnf配置文件，加一行skip-grant-tables
mysql -uroot无密码进入数据库
update mysql.user set authentication_string=password('新密码') where user='root' 
flush privileges 刷新
将配置文件里添加的注释掉
重启mysql
```

## **日志管理**

错误日志：主要保存命令报错，服务报错信息，进行排查错误和修复。

log-error=/var/log/mysqld.log

二进制日志：主要保存命令的一些信息，最主要实现日志的备份。

log-bin=/var/log/mysql-bin/mylog  #如果不指定路径默认在/var/lib/mysql

 chown mysql.mysql /var/log/mysql-bin/

慢日志：优化要用的日志

slow_query_log=1  #开启

slow_query_log_file=/var/log/mysql-slow/slow.log

long_query_time=3    #设置慢查询超时间，单位是秒

验证查看慢查询日志
mysql> select sleep(3);

expire_logs_days = 7  #binlog日志自动删除/过期的天数。默认值为0,表示不自动删除

cat /var/log/mysql-slow/slow.log

## **慢查询如何进行优化**

通过分析慢查询日志，可以找到执行时间较长的SQL语句，进而找到问题所在。可以从以下几个方面进行分析：

（1）查询语句是否存在全表扫描。

（2）查询语句是否存在子查询。

（3）查询语句是否存在JOIN操作。

（4）查询语句是否使用了索引。

（5）查询语句是否存在大量的排序和分组操作。

3. 优化慢查询

根据分析结果，可以采取以下优化措施：

（1）添加索引：对于查询语句中经常使用的字段，可以为其添加索引，加快查询速度。

（2）优化查询语句：对于存在全表扫描、子查询、JOIN操作、排序和分组操作等问题的查询语句，可以通过优化SQL语句来提高查询性能。

（3）分表分库：对于数据量较大的表，可以考虑将其拆分为多个表，或者将其存储在多个数据库中，减轻单个表或库的压力。

MySQL慢查询问题是数据库性能下降的主要原因之一，通过查看慢查询日志和分析查询语句，可以找到问题所在，并采取相应的优化措施来提高数据库性能。

```plain
slow_query_log=1  #开启
slow_query_log_file=/var/log/mysql-slow/slow.log
long_query_time=3    #设置慢查询超时间，单位是秒

# mkdir /var/log/mysql-slow/
# chown mysql.mysql /var/log/mysql-slow/
# systemctl restart mysqld

验证查看慢查询日志
mysql> select sleep(6);
# cat /var/log/mysql-slow/slow.log
```

在mysql配置文件中开启慢查询日志后，指定的慢查询日志文件路径 可以去这个路径里面查看



也可以使用show processlist查看  这个命令是显示当前正在执行的所有查询信息，通过筛选可以找到执行时间较长的sql语句，

也可以通过mysql自带的工具pt-query-digest进行分析。该工具可以统计慢查询数量，执行时间，执行次数等信息



## mysql5.7和8.0的区别

MYSQL 5.0  是2005年发布的   

MySQL 8.0是2018年4月20日发布的全球最受欢迎的开源数据库的一个非常令人兴奋的新版本 ，一些关键的增强包括：SQL窗口函数，公用表表达式，NOWAIT和SKIP LOCKED，降序索引，分组，正则表达式，字符集，成本模型和直方图。

# 

## **mysql版本不一致导致主从同步异常**

zabbix对数据库主从状态进行监控，某一天突然报警，主从不同步了，登录从数据库后发现sql线程错误

解决方案，根据下面的报错信息，说一条sql语句有问题，查看了一下是grant all privileges on wordpress.* to  'wordpress'@'%' identified by 创建用户权限的这条sql语句有问题，然后在主库重新执行一下发现没问题，当时也没发现是版本不一致导致的，因为mysql8.0不能直接使用grant这个命令生成用户并授权，只能先创建用户在授权，然后把这个语句在从库上执行了一下，发现不能执行，分析了一下会不会是版本不一致导致的，就看了一下版本，发现是8.0

解决方案

stop slave

set global sql slave skip counter=1 跳过这个事务

start slave

show slave status \G 查看异常是否解决 发现解决了  但是用户授权没有成功，所以需要手动执行一下

5、因为从库设置了只读，需要先关闭一下set global read_only=0

6、create user 'query_data_analysis'@'%' identified by 'Han2rZY7uEn9m!Asana';

7、GRANT all privileges on data_analysis.* to query_data_analysis@'%';

8、把从库重新设为只读set global read_only=1

## **挖矿病毒导致服务器很卡**

top发现服务器的cpu很高，就怀疑存在挖矿病毒，看到这是lthpc用户起来的程序 ，因为服务器是购买的联泰集群嘛，装机会默认创建这个用户 uid一般是1000，而且所有的联泰集群服务器的这个用户默认密码都是LT111111，我就怀疑黑客是这么进来的，查找到进程第一步就是kill杀死这个进程，然后挖矿脚本一般会存在/var/tmp下，但是没有找到，一般的挖矿病毒也都会设置定时任务，通过crontab -l查看定时任务也没有找到，在/etc/cron.d也没有找到，最后使用find  /-name cnrig 查找到了在此脚本下面有一个隐藏文件.ap 。cd进去之后就发现了很多文件 将他们删除之后 ，再删除所有的无关用户 修改所有的用户密码，增加密码强度，开启防火墙



#  shell脚本

##  #数字													#字符串 -eq(equal) 等于								         == -ne(not equal) 不等于								      != -ge(Greater than or equal to) 大于等于 				     >= -le(Less than or equal to) 小于等于 				          <= -gt(greater than) 大于							          > -lt(less than) 小于 								          < #文件 test -f 存在且是正规文件 -d 存在且是目录 -h 存在且是符号链接 -b 块设备 -c 字符设备 -e 文件或者目录存在 shell脚本规范 脚本开头 #!/usr/bin/env bash ---shebang 蛇棒, 解释器, 翻译



1. sh 脚本.sh
2. bash 脚本.sh
3. ./脚本.sh
4. . 脚本.sh
5. source 脚本.sh
   echo "当前时间：$time"
   echo "用户标识：`head -1 /etc/passwd |awk -F ':' '{print $3}'``" echo "CPU 情况：`uptime |awk '{print ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?(NF-2)%2C)(NF-1),$(NF)}'`" echo "内存使用：总数/剩余`free -h |awk 'NR2{print $2,$3}'`" echo "磁盘情况: /`df -h |grep /dev/mapper/centos-root |awk '{print $(NF-1)}'`" echo "主 机 ip:`ip a |grep ens33 |awk 'NR2{print$2}' |awk -F "/" '{print$1}'`"
   expr  用来计算两个变量  列如：expr  变量二 + 变量二
   &&：逻辑与，前面执行成功，后面才执行。前面命令执行失败，后面命令也不执行
   ||：逻辑或，前面执行失败，后面执行，前面命令执行成功，后面不执行。
   if判断分支：----------------------------------------------------
   if [判断条件]---代码返回0表示真，非0为假
   if [ list1 ];then  list1:你的测试条件，你要测试什么，对什么内容做判断
   list2
   elif [ list3 ];then   ------> 接着在怎么做。（多条件判断）
   list4
   else      ---------------> 如果前面的命令没有执行成功那就执行else下面的命令。
   list5
   fi
   for循环语句------------------------------------------------------------------------------
   for i in $(定义取值范围)     #for是关键字 i是变量名 in是关键字
   do          #循环体的开始
   循环体
   done         #循环体的结束
   while循环语句---------------------------------------------------------------------------
   while read  变量名  #while关键字，条件和if的条件一样，#while循环当条件为真的时候循环同时会一直循环，也就所说的死循环，为假时不循环
   do
   循环体
   done
   循环控制四个命令：break是立马跳出循环并退出脚本;continue是跳出当前条件循环，继续下一轮条件循环;exit是直接退出整个脚本执行脚本方式，位置参数可以用shift命令左移。
   while read line  #读文件中的每一行信息
   传参形式：----------------------------------------------------------------------------
   aa(){
   if [ $? -eq "0" ];then
   $1
   else
   $2
   fi
   }
   yum -y install httpd &> /dev/null
   aa  "echo 下载成功"  "echo 下载失败"
   自己做的shell语句作业！！！！！！



读取当下文件中的IP地址和密码，批量远程发送文件（用这个脚本前记得查看本台机子有没有秘钥，没有记得下载）
\#!/usr/bin/bash
read -p "输入你要传送的文件绝对路径：" mm
while read aaa
do
mima=`echo $aaa | awk '{print $2}'`
ip=`echo $aaa| awk '{print $1}'`
/usr/bin/expect << EOF
spawn ssh-copy-id ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?ip%0Aexpect%20%20%20%20%20%22continue%20connecting%20(yes%2Fno)%22%20%7B%20send%20%22yes%5Cr%22%20%3B%20exp_continue%20%7D%0Aexpect%20%20%20%20%20%22password%3A%22%20%7B%20send%20%22)mima\r"  }
expect eof
EOF
scp -r $mm  $ip:/root/ &>/dev/null
if [ $? -eq 0  ];then
echo " ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?ip%20%E5%8F%91%E9%80%81%E6%88%90%E5%8A%9F%22%20%20%0Aelse%0A%20%20%20%20%20%20%20%20%20%20%20echo%20%22)ip 发送失败"
fi
done < /root/ip.txt



数据库的增量备份脚本
\#!/usr/bin/bash
systemctl stop firewalld
setenforce 0
xiazai(){
wget http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm
rpm -ivh percona-release-0.1-4.noarch.rpm
yum -y install percona-xtrabackup-24.x86_64
}
xinxi=`ls /opt/week.sh | wc -l`  #查看目录里面有没有文件
dizhi="/opt/week.sh/"   #备份的地址
beifen="/opt/beifen/"   #一周移动一次的地址
mima=Cc123456!    #密码
\#周备份
bf(){
if [ $(date +%u) -eq "1"  ] ;then  #看周几在进行完备和增备
mv $dizhi*  ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?beifen%20%20%20%23%E5%85%88%E7%A7%BB%E8%B5%B0%E7%9B%AE%E5%BD%95%E9%87%8C%E9%9D%A2%E7%9A%84%E6%96%87%E4%BB%B6%20%20%20%0A%20%20%20%20%20%20%20%20%20%20innobackupex%20-uroot%20-p%22)mima" --incremental ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?dizhi%20%20%23%E5%86%8D%E5%81%9A%E5%AE%8C%E6%95%B4%E5%A4%87%E4%BB%BD%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%E5%91%A8%E4%B8%80%E5%AE%8C%E6%95%B4%E5%A4%87%E4%BB%BD%E6%88%90%E5%8A%9F%EF%BC%81%EF%BC%81%22%0Aelse%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%E4%BE%9D%E7%85%A7%E6%9C%80%E6%96%B0%E6%97%B6%E9%97%B4%E7%9A%84%E5%A4%87%E4%BB%BD%E6%9D%A5%E5%81%9A%E5%A2%9E%E9%87%8F%E5%A4%87%E4%BB%BD%0A%20%20%20%20%20%20%20%20%20%20%20%20%20innobackupex%20-uroot%20-p%22)mima" --incremental ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?dizhi%20--incremental-basedir%3D)dizhi`ls -t $dizhi | head -1`
echo "增量备份成功！！"
fi
}
\#判断目录里面有没有文件，进行完备于增备
if  [ ![img](https://www.yuque.com/api/services/graph/generate_redirect/latex?xinxi%20-eq%200%20%5D%0Athen%0A%20%20%20innobackupex%20-uroot%20-p%22)mima" --incremental $dizhi  #完整备份
echo "已完成完整备份"
else
bf  #开始调用周备份
fi



Expect----------------------------------------------------------------------------------



1)定义expect脚本执行的shell
\#!/usr/bin/expect
2)spawn
spawn是执行expect之后后执行的内部命令开启一个会话
3)expect ---相当于捕捉
功能:判断输出结果是否包含某项字符串(相当于捕捉命令的返回的提示)。没有捕捉到则会断开，否则等待一段时间后返回，等待通过timeout设置
4)send（\r）
相当于回车
5)interact
执行完后保持交互状态，需要等待手动退出交互状态，如果不加这一项，交互完成会自动退出
6)exp_continue
继续执行接下来的操作
7）timeout
返回设置超时时间(秒)
sed基本用法-----------------------------------------------------------------------
sed -r  '匹配内容'  文  件位置
sed -r 's/旧名称/新名称/g'  文件位置    #搜每一行，找到所有旧字符，进行全局替换
sed -r 's/旧名称/新名称/gi'  文件位置    #搜每一行，找所有旧字符，进行全局替换忽略大小写
sed -r 's/旧名称/新名称/gi'  -e  's/旧名称/新名称/gi'  文件位置  #多选换旧字符
sed -r '/^root/d' passwd      #匹配到root开头的行，删除此行
sed -r '2,$d' passwd       #删除第2行到最后一行
sed -r '/root/d' passwd      #含有root的行都删除
sed -r '/bash/,3d' passwd     #匹配到bash行，从此行到文件的第3行删除
sed -r '2i\222222' passwd       #在第2行插入
sed -r  -i.bak 's/旧名称/新名称/g' 文件位置  #用i参数在后面加上.bak就会生一个备份的文件
sed -r '2,5s/^/#/' passwd        #给文件行添加注释
sed -r 's/^/#/' passwd            #给所有行添加注释

# **NGINX 服务**

http（超文本传输协议）

nginx是一款轻量级、高性能、稳定性高、并发性好的http和反向代理服务器，nginx解析静态页面的效率非常高，处理动态请求性能比较差。单进程多线程模式，进程死掉会影响很多用户。



虚拟主机

1、基于域名的虚拟主机 （server_name来区分虚拟主机——应用：web网站）

2、基于ip的虚拟主机， （一个主机绑定多个ip地址）

3、基于端口的虚拟主机 

$host				请求信息中的"Host"，如果请求中没有Host行，则等于设置的服务器名;

$request_filename   当前请求的文件路径名（带网站的主目/usr/local/nginx/html/images/a.jpg)

$request_uri		当前请求的文件路径名（不带网站的主目录/images/a.jpg）

访问日志的展示信息

log_format  main  '$remote_addr  -  $remote_user [$time_local] "$request" '

客户端ip           访问的客户端   访问的时间   请求的协议

'status $body_bytes_sent  "$http_referer" '

发送的主体大小       记录客户端访问的来历

'"$http_user_agent"  "$http_x_forwarded_for"';

记录客户端浏览的信息   客户端的ip

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539542657-9aa48941-3a35-4af2-9346-671edfc553fe.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_19%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## **nginx并发数、隐藏版本号**

单机环境下参考服务器配置。 并发连接数在7000+ -8000左右。 集群模式20000+



nginx如何隐藏版本信息：  在配置文件http模块中添加server_tokens off;

## 为什么做流量访问限制

- **防止服务器被恶意攻击**：如暴力破解密码等，通过限制访问速度，可以减少密码被暴力破解的可能性。
- **解决流量突发问题**：如线上活动导致访问量突增、下班打卡的访问量突增等。
- **保护服务器正常运行**：限流用于保护服务器不会因为承受不住同一时刻的大量并发请求而宕机，从而保障了服务器的正常运行。
- **抵御DDOS攻击**：通过将传入请求的速率限制为真实用户的典型值，并标识目标URL地址（通过日志），还可以用来抵御DDOS攻击。
- **保护上游应用服务器**：该功能被用来保护上游应用服务器不被同时太多用户请求所压垮。

↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓

流量限制”配置两个主要的指令，limit_req_zone和limit_req

limit_req_zone指令定义了流量限制相关的参数，而limit_req指令在出现的上下文中启用流量限制(示例中，对于”/login/”的所有请求)。

limit_req_zone指令通常在HTTP块中定义，使其可在多个上下文中使用，它需要以下三个参数：

## nginx默认限制上传大小是多少 怎么设置

nginx默认限制上传大小为1MB。可以通过修改nginx配置文件中的client_max_boby_size参数来调整上传大小限制

## **nginx防盗链怎么做**

**防盗链的作用以及使用**
模块：防盗链（ngx_http_referer_module）是为了防止非法盗链影响站点的正常访问。
配置 vaild_referers 的参数，如 none | blocked | server_names | string字符串等， valid_referers 指令用于设置允许访问资源的网站白名单，允许一些网站合法盗链使用我们的资源；
none: 允许没有http_referer的请求访问资源
blocked:允许不是http://开头的，不带协议的请求访问资源
server names:只允许指定ip/域名来的请求访问资源 (白名单)
**①防盗链作用**


1**保护网站资源**：防盗链可以防止未经授权的网站获取或使用你的网站资源，如图片、视频、文档等，从而保护你的网站资源不被非法获取和使用。
2**防止攻击**：一些攻击者可能会通过获取你的网站资源来进行一些恶意操作，如DDoS攻击、注入攻击等，防盗链可以防止这种情况的发生。
3**提高网站安全性**：通过防盗链，可以防止未经授权的网站获取你的网站资源，从而提高你的网站安全性。
4**保护用户隐私**：如果用户上传的图片被其他网站盗链，那么用户的隐私信息就可能被泄露，防盗链可以保护用户隐私不被泄露。

**②防盗链的使用**

在需要防盗的页面机的子配置文件里的server模块下写入防盗链模块；



```plain
server {
    listen       80;
    server_name  localhost;
    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;

        valid_referers none blocked www.jd.com;  #允许这些访问
                if ($invalid_referer) {
                   return 403;
                }
        }
}
```



## 黑白名单的相关配置

遵循的是从大到小的规则



在Nginx中，可以使用allow和deny指令来控制流量，对特定的客户端进行允许或拒绝访问。这些指令通常用于基于IP地址或域名的访问控制。

allow指令用于指定允许访问的客户端IP地址或域名，而deny指令用于指定拒绝访问的客户端IP地址或域名。这些指令可以出现在Nginx配置文件中的不同位置，例如在http、server或location块内。

```plain
server {
        listen 80;
        server_name localhost;
        location ~ ^/admin {
                root /home/www/html;
                index index.html index.hml;
                deny 192.168.1.8;
                allow all;
                #deny 192.168.1.8;
        }
}
#需要注意:
如果先允许访问，在定义拒绝访问。那么拒绝访问不生效。
```

需要注意的是，使用allow和deny指令时，它们的顺序很重要。Nginx会按照这些指令在配置文件中出现的顺序进行匹配，一旦找到匹配项，就会执行相应的操作。因此，建议根据实际需要进行合理的排序和组合。

## **nginx的会话保持**

会话保持的作用：为了确保与某个用户的所有请求能够由一台服务器进行处理

使用第三方模块nginx-sticky-module-ng，使用ip_hash、url_hash

## **nginx怎么做反向代理**

- **提高访问速度**：反向代理服务器可以缓存目标主机返回的数据，当下一次客户再访问相同的站点数据时，会直接从代理服务器的硬盘中读取，避免了重复获取资源的时间，从而提高了访问速度。
- **保护Web服务器**：反向代理服务器可以保护Web服务器免受已知漏洞的影响，因为请求不会直接到达Web服务器。
- **负载均衡**：反向代理服务器可以充当负载均衡器，解决网站同时处理大量请求的问题，使Web服务器能够更好地处理请求，并提高系统的性能。

Nginx 需要配置文件里面定义，如果后端地址比较多，需要用upstream 模块定义后端服务器地址池，然后再server模块中，定义location模块，用Proxy_pass 转发到此地址池。这样的效果，其实还起到了七层负载均衡的作用。其实还起到了反向代理的作用。

## **nginx怎么做七层负载均衡 （=反向代理）**

Nginx 需要配置文件里面定义，如果后端地址比较多，需要用upstream 模块定义后端服务器地址池，然后再server模块中，定义location模块，用Proxy_pass 转发到此地址池。这样的效果，其实还起到了反向代理的作用。



## 4层

stream嵌套upstream   

![img](https://cdn.nlark.com/yuque/0/2024/png/40790213/1705992611178-cfe87938-ab12-40e1-87f5-53b297c76e9e.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_29%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



## **为什么选择nginx**

Nginx 是一个高性能的 Web 和反向代理服务器, 它具有有很多非常优越的特性:

单机环境下参考服务器配置。 并发连接数在7000+ -8000左右。 集群模式20000+



**作为 Web 服务器**：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx 尤其受到虚拟主机提供商的欢迎。能够支持高达 50,000 个并发连接数的响应。

**作为负载均衡服务器**：Nginx 既可以在内部直接支持 Rails 和 PHP，也可以支持作为 HTTP代理服务器 对外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比 Perl要好的多。

**作为邮件代理服务器**: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。

**Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器**: Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。

## **介绍一下nginx  \**\**\***

nginx是一款高性能，高并发，低消耗的web服务器和反向代理服务器，同时也是邮箱服务，他还是一款负载均衡软件 可以同时做七层和四层的负载均衡，Nginx对静态页面的解析非常好 但是解析动态页面就比较鸡肋，它的功能十分强大和丰富，比如像会话保持，防盗链，访问流量控制，地址重写等，        的启动特别容易,并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。还能够在不间断服务的情况下，对软件版本进行进行升级。

## **nginx负载均衡**

我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡,

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539543239-0a14aa97-2f3f-4ba9-bf2f-669583fc9709.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_28%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## **做负载均衡、权重**

负载均衡用的nginx，定义Upstream地址池，然后在server模块中，用proxy_pass转发到地址池中。



nginx权重

权重  weight=3

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702645550721-2f6b2314-e5a4-44dc-8560-e24ea7583d75.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_15%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

```plain
max_fails：表示在多少次请求失败后，将该后端服务器标记为不可用状态，默认值为1。
fail_timeout：表示在多少秒内，如果有多少个请求失败，就将该后端服务器标记为不可用状态，默认值为10秒。
backup：表示该后端服务器为备用服务器，在其他所有服务器都不可用时才会使用该服务器。
down：表示该后端服务器已经不可用，Nginx不会将请求转发到该服务器。
```

## **负载均衡算法**

upstream 支持4种负载均衡调度算法：

A、轮询(默认):每个请求按时间顺序逐一分配到不同的后端服务器；

B、ip_hash:每个请求按访问IP的hash结果分配，同一个IP客户端固定访问一个后端服务器。可以保证来自同一ip的请求被打到固定的机器上，可以解决session问题；

C、url_hash:按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器。后台服务器为缓存的时候效率；

D、fair:这是比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持 fair的，如果需要使用这种调度算法，必须下载Nginx的 upstream_fair模块；

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539543257-619b9568-de00-4477-9daf-d58f6d9ba724.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_25%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## **动静分离**

为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来美个服务器的压力。

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539543270-969367f9-edfe-4e91-b5cb-9fb2bb1690f3.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_28%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## 

## **apache和nginx的区别**

1、处理请求的方式：Apache使用多线程模型来处理请求，每个连接都会创建一个新的线程。而Nginx使用事件驱动的架构，它采用异步非阻塞的方式处理请求，可以高效地处理大量连接。

2、资源消耗：由于Nginx的事件驱动架构，它通常比Apache消耗更少的内存和CPU资源，能够处理更多的并发请求。

3、配置和扩展性：Apache的配置文件相对复杂，需要较多的配置和优化才能达到最佳性能。Nginx的配置相对简单，而且支持动态模块加载，可以通过插件扩展其功能。

4、 功能特性：Apache拥有丰富的模块和功能特性，适用于复杂的Web应用场景

Nginx则专注于高性能的静态文件服务和反向代理，适用于处理大量并发连接的场景。

5、 总的来说，Apache适用于复杂的Web应用，而Nginx适用于高并发的静态文件服务和反向代理。选择哪种Web服务器取决于具体的应用场景和性能需求。

## **Nginx是一个高性能的...，也有缺点**

1. 动态内容处理能力较弱：相对于Apache，Nginx在处理动态内容（如PHP、Python等）方面的能力较弱。虽然Nginx可以通过FastCGI等方式处理动态内容，但相比Apache并不那么灵活和全面。
2. 学习曲线较陡：相对于一些传统的Web服务器，Nginx的配置语法和特性可能对一些用户来说比较陌生，需要花费一些时间来学习和适应。
3. 缺乏内置的处理模块：Nginx的功能相对较为简单，它缺乏一些内置的处理模块，需要依赖第三方模块来实现一些高级功能，这可能增加了一些复杂性和不确定性。
4. 不适用于所有场景：尽管Nginx在处理高并发静态内容方面表现出色，但它并不适用于所有的应用场景，特别是一些需要复杂动态内容处理和模块支持的场景。

尽管存在这些缺点，但Nginx仍然是一个非常优秀的Web服务器和反向代理软件，特别适用于高并发、静态内容服务和反向代理等场景。选择是否使用Nginx还是取决于具体的应用需求和场景。

## **一个请求到来了，nginx使用epoll接收请求的过程是怎样的?**

ngnix会有很多连接进来， epoll会把他们都监视起来，然后像拨开关一样，谁有数据就拨向谁，然后调用相应的代码处理。

● **epoll**. 

epoll 可以说是I/O 多路复用最新的一个实现，epoll 修复了select/poll绝大部分问题, 比如：

• epoll 线程安全的。 

• epoll 告诉你具体哪个sock有数据，你不用自己去找   、

## **异步，非阻塞是什么**

有一个master进程，2个work进程

每进来一个request，会有一个work进程去处理。但不是全程处理，处理到可能发生阻塞的地方，比如向后端服务器转发request，并等待请求返回。那么，这个处理的work不会这么一直等着，他会在发送完请求之后，注册一个事件：“如果upstream返回了，告诉我一声，我在接着干”。于是他就休息去了。这就是异步。此时，如果再有request进来，他就可以很快再按这种方式处理。这就是非阻塞和io多路复用。儿一旦上游服务器返回了，就会触发这个事件，work才会来接手，这个request才会接着往下走。这就是异步回调

## **正向代理**

在客户端（浏览器）配置代理服务器，通过代理服务器进行互联网访问。

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539543442-b167cd5d-6640-47ac-9d0b-3d1fc0a85c72.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_22%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## **反向代理**

客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539543556-f5fc8463-e0e8-4630-84a1-5f7999c2e15e.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_28%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

区别就是

正向代理的过程隐藏了真实的客户端，服务器不知道真正的客户端是谁

反向代理的过程隐藏了真实的服务器，客户端不知道服务器是谁

四层模块的关键字：stream嵌套  →stream

## **HTTP状态码**

HTTP状态码的英文为HTTP Status Code。

下面是常见的HTTP状态码：

- 200 - 请求成功
- 301 - 资源（网页等）被永久转移到其它URL（url和内容全部重定向）
- 302-临时重定向（只把内容重定向过来）
- 304  未改变
- 401-开启密码验证
- 403 权限问题
- 404 - 请求的资源（网页等）不存在
- 500 - 内部服务器错误，一般是因为开启了防火墙
- 502 网关错误
- 503 web服务承载能力不够
- 504-网关超时

401 - Unauthorized

原因：您的web服务器开启了密码验证，客户端在请求的时候需要填入用户名和密码，只有输入正确的用户名和密码才能正常访问。

解决方法：
1、输入正确的用户名和密码；
2、关闭web服务器的密码验证功能。

403 - Forbidden

原因：禁止访问，请求是合法的，但是却因为服务器配置规则而拒绝响应客户端请求，此类问题一般为服务器或服务权限配置不当导致。

解决方法：
1、确保主页文件存在，如index.php或index.html；
2、确保web服务器运行用户和站点的目录权限一致，比如你的nginx运行用户为www，你需要确保你的站点目录的所有者为www。

404 - Not Found

原因：服务器找不到客户端请求的指定页面，可能是请求了一个服务器上不存在的资源导致的，也有可能是服务器上的该文件被删除。

解决方法：
1、确保输入的是正确的url；
2、确保你请求的文件在服务器上是真实存在的；
3、如果你的云服务器配置了数据盘，且站点目录在数据盘中，这时候你需要检查数据盘是否被正确挂载或者是否到期被释放掉了。

500 - Internal Server Error

原因：内部服务器错误，服务器遇到了意料不到的错误，不能完成客户的请求。一般为服务器的配置或内部程序的问题。

解决方法：
1、此时可能是服务器资源占用过高，你需要查看一下服务器占用率，必要时清理内存或者重启服务器；
2、文件权限问题，确保你的服务器程序文件权限为755；
3、检查基础服务是否运行，如果您用的是LNMP架构，则需要检查php-fpm和mysql是否正常运行。

502 - Bad Gateway

原因：坏的网关，一般是服务器作为代理服务器请求后端的服务器时，后端的服务不可用或没有完成响应给网关服务器，一般为反向代理服务器后端的服务器节点出现故障。
解决方法：
1、检查代理服务器后端的服务器是否正常运行，以及后端服务器上的服务是否正常运行。

503 - Service Unavailable

原因：服务当前不可用，可能是因为服务器超载或停机维护导致，或者是反向代理服务器后面没有可以提供服务的节点。

解决方法：
1、服务器供应商可能正在维护或者暂停服务，你可以联系一下服务器供应商；
2、还有可能就是服务器的cpu或内存占用过高，需要清理一下资源，必要时重启服务器。

504 - Gateway Timeout

原因：网关超时，一般是网关代理服务器请求后端服务器或者cdn请求源站服务器时，服务器没有在特定的时间内处理并响应请求，一般为服务器过载，没有在指定时间内返回数据。

解决方法：
1、对服务器性能参数进行相关调整，包括php参数调整，数据库参数调整，web服务器参数调整；
2、必要时可以选择升级服务器配置。

## **Nginx 系统优化**

1. 调整worker_processes参数：根据服务器的CPU核心数和负载情况，适当调整worker_processes参数，以充分利用服务器资源。

1.19版本之后可  以auto 自动

2. 调整worker_connections参数：根据服务器的并发连接数需求，适当调整worker_connections参数，以提高并发处理能力。

**worker_rlimit_nofile 65535; #进程限制

**ulimit -n  查看当前系统的限制后再改这个限制

3. 合理配置缓存：使用nginx内置的缓存功能，合理配置缓存大小和缓存时间，以提高网站性能和减轻后端服务器压力。
4. 启用gzip压缩：启用gzip压缩功能，可以减小传输数据大小，提高网站加载速度。

配置文件里打开  gzip on

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702553355279-b57085ee-930c-4d55-9873-c8e0b6f0d751.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_33%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

5. 使用keepalive连接：启用keepalive连接，可以减少TCP连接的建立和断开，提高性能。
6. 合理配置日志：根据实际需求，合理配置nginx的访问日志和错误日志，以便监控和排查问题。
7. 使用高效的存储设备：如果是静态资源服务器，可以考虑使用高速的存储设备，如SSD，以提高读取速度。
8. 使用反向代理缓存：对于动态内容，可以使用反向代理缓存，减轻后端服务器压力，提高性能。
9. 定期更新nginx版本：定期更新nginx版本，以获得最新的性能优化和安全补丁。
10. 使用性能分析工具：使用性能分析工具对nginx进行性能分析，找出性能瓶颈并进行优化。

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702553865441-9584e8c8-1784-4a0e-8101-e6346d47e979.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_23%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



## **Nginx 中的 master&workers**

Nginx启动后，是由两个进程组成的。master（管理者）和worker（工作者）。

一个Nginx只有一个master，但可以有多个worker

## **http介绍**

http协议是一款超文本传输协议，是用于从万维网服务器传输超文本到本地浏览器的传送协议

### http响应由什么组成

HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文

### http的工作原理是什么

http协议他是工作与客户端-服务端的架构上。浏览器作为http客户端通过URL向http服务端 就是web服务器发送所有请求Shell编程

### HTTPS的协议以及介绍

HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

HTTPS协议的端口号是443，它和http协议一样，都是互联网上应用最广泛的一种网络协议。以安全为目标的http通道，在http的基础上通过传输加密和身份认证保证了传输过程的安全性。

### 为什么使用https

提高数据加密性：HTTPS协议使用对称加密+非对称加密的模式，这种混合加密的模式，充分利用两方的优势，让网站的数据能够在传输过程中不被破解，同时提高数据的解密效率。

1. **确保数据完整**：在网站数据传输的过程中，数据会经过多个中间节点，极有可能被篡改信息。利用HTTPS协议中的数字签名，通过数字签名我们可以确认数据的发送方、确保数据的完整性，检验数据是否被篡改。
2. **解决身份认证难题**：攻击者会通伪造域名来接收目标网站的信息，这就会导致网站信息泄露。
3. **保证用户数据的私密性**：搜集用户的敏感信息，比如信用卡号、电话号码或电子邮件地址，通过使用HTTPS加密传输，你可以确保这些数据在传输过程中得到保护。
4. **提高搜索引擎排名**：搜索引擎已经开始更认真地考虑是否将HTTPS作为一个排名信号。使用HTTPS可以提高你的网站在搜索引擎中的排名。
5. **建立信任**：当用户访问由HTTPS保护的网站时，他们会看到一个绿色的锁定图标，这表明这个网站是安全的。这有助于建立用户对你网站的信任 

### Http和Https的区别

​	1.安全性不同，Http是超文本传输协议，信息是明文传输，Https则是具有安全性的SSL加密传输协议.

​	2.响应速度不同，http比https的响应速度更快

​	3.端口不同http默认访问80端口，https是443端口

​	4.消耗资源不同，http	s是构建在SSL之上的http协议，所以https会消耗更多的服务器资源

​	5.费用不同，https需要购买ssl安全证书，会产生一定的费用

## Nginx、Apache 和 Tomcat 的主要区别如下：

-  **类型：** 

- **Nginx 是Web服务器，用于静态文件服务和反向代理。**
- **Apache 是全功能Web服务器，支持动静分离。**
- **Tomcat 是应用服务器，专门运行Java Web应用。**

-  **架构：** 

- **Nginx 基于事件驱动，高性能低消耗。**
- **Apache 采用线程模型，性能次于Nginx。**
- **Tomcat 使用线程池处理请求。**

-  **性能：** 

- **Nginx 性能最高，支持几万并发。**
- **Apache 性能第二，支持几千并发。**
- **Tomcat 性能在Apache和Nginx之间。**

-  **功能：** 

- **Nginx 适合静态文件和负载均衡。**
- **Apache 功能最全，支持多种web服务器功能。**
- **Tomcat 只负责运行Java应用，不处理静态资源。**

**总体来说：**

- **Nginx 用于静态资源和负载均衡**
- **Apache 功能全面，可选择**
- **Tomcat 专注运行Java应用**



# **Tomcat服务    并发200**

## **Tomcat和Apache服务器有什么区别？**

​    Apache是一个通用的Web服务器，而Tomcat是一个专门用于运行Java Servlet和JSP的Servlet容器。Apache可以处理静态内容和动态内容，而Tomcat主要用于处理动态内容。

## war包和jar包的区别

WAR（Web Application Archive）包和JAR（Java Archive）包是两种常见的 Java 应用程序打包格式，它们之间有一些区别：



1. WAR 包：

- WAR 包是用于部署 Web 应用程序的压缩文件格式，通常包含 Web 应用程序的所有资源，如 HTML、JSP、Servlet、CSS、JavaScript 文件等。
- WAR 包可以包含 WEB-INF 目录，其中包含 web.xml 部署描述符以及其他配置文件。
- WAR 包通常用于部署 Web 应用程序到 Java EE 容器（如 Tomcat、Jetty、WebLogic 等）中。



1. JAR 包：

- JAR 包是 Java 应用程序的标准打包格式，用于打包 Java 类文件、资源文件、库文件等。
- JAR 包通常用于打包独立的 Java 应用程序或 Java 库。
- JAR 包可以包含 MANIFEST.MF 文件，用于指定应用程序的入口点等信息。

总的来说，WAR 包主要用于打包和部署 Web 应用程序，而 JAR 包主要用于打包和发布独立的 Java 应用程序或库。

## Tomcat和Nginx都是Web服务器，但它们的职责和功能有所不同：

1.Tomcat是Java Web应用服务器，支持JSP和Servlet等Java Web开发技术；而Nginx是高性能的HTTP和[反向代理](https://so.csdn.net/so/search?q=反向代理&spm=1001.2101.3001.7020)服务器。 

2.Tomcat支持Java应用程序的部署和管理，提供服务端的[动态网页](https://so.csdn.net/so/search?q=动态网页&spm=1001.2101.3001.7020)内容生成、数据库交互等Java Web应用相关功能；而Nginx则更多地是通过负载均衡和缓存技术来提高Web服务器的性能，实现高并发访问。

3.Tomcat可以独立作为Web服务器运行，也可以集成在其他Web服务器中；而Nginx通常被用作反向代理服务器，将客户端[请求转发](https://so.csdn.net/so/search?q=请求转发&spm=1001.2101.3001.7020)到内部的Web服务器或应用服务器上，并对响应进行处理后再返回给客户端。

4.总之，虽然两者都是Web服务器，但Tomcat更专注于Java Web应用程序的部署和管理，而Nginx则更专于负载均衡和反向代理等性能优化方面。

**Tomcat的部署方式有哪些？**

​    tomcat可以通过war包（Web Application Archive）部署，将war包放置在Tomcat的webapps目录下，Tomcat会自动解压并部署应用。                                                                                        也可以通过在conf/server.xml文件中配置Context来手动部署应用。（不常用）

**1.直接将项目放到webapps目录下即可**

简化部署：将项目打成一个[war包](https://so.csdn.net/so/search?q=war包&spm=1001.2101.3001.7020)，再将war包放置到webapps目录下，war包会自动解压缩。

[启动](https://so.csdn.net/so/search?q=启动&spm=1001.2101.3001.7020)Tomcat直接就可以访问了。

## Tomcat的缺省端口是多少，怎么修改

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702539571845-c952cf41-505e-47da-bae8-8b6d29dd53d8.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_19%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

## tomcat的日志类型

1. 访问日志（Access Logs）：记录所有进入 Tomcat [服务器](https://so.csdn.net/so/search?q=服务器&spm=1001.2101.3001.7020)的 HTTP 请求。这些日志包含有关请求的详细信息，如客户端 IP 地址、请求的时间戳、请求方法、请求的 URL、HTTP 状态码等。
2. 错误日志（Error Logs）：记录在处理请求过程中发生的错误和异常。这些日志包含有关错误的详细信息，如错误的时间戳、错误类型、异常堆栈跟踪等。
3. Catalina 日志（Catalina Logs）：记录 Tomcat 服务器的启动、关闭以及关键组件（如 Servlet、过滤器等）的初始化和销毁过程。这些日志提供有关服务器运行状态的信息。
4. 安全日志（Security Logs）：记录与安全相关的事件和活动，如用户认证、授权失败等。这些日志帮助管理员监视和审计服务器的安全性。
5. 应用程序日志（Application Logs）：这些日志由部署在 Tomcat 上的应用程序生成，用于记录应用程序自身的日志信息。应用程序日志可以包括调试信息、业务日志、应用程序错误等。

## **Tomcat的目录结构**

/bin：存放用于启动和暂停Tomcat的脚本

/conf：存放Tomcat的配置文件

/lib：存放Tomcat服务器需要的各种jar包

/logs：存放Tomcat的日志文件

/temp：Tomcat运行时用于存放临时文件

/webapps：web应用的发布目录   ROOT下

/work：Tomcat把有jsp生成Servlet防御此目录下

## **tomcat的主目录介绍？**

tomcat的主目录：bin目录存放二进制命令的

conf存放配置文件server.xml,

logs是日志存放，

webapps是网站的默认发布目录，

部署tomcat：jdk1.8+tomcat8.0+mysql5.7+项目jspgou商城+nginx负载均衡

————————————————

## 负载均衡：

反向代理和负载均衡  这是

nginx（定义地址池） +tomcat   多实例   

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702641355265-0dd8b22a-44a0-4eb2-ac3f-d16ecfe235b8.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_23%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



## **tomcat端口作用**

8005：这个端口负责监听关闭Tomcat的请求 

8009: 与其他服务通信接口，接受其他服务器转发过来的请求

8080: 建立http连接，外部访问用。可以修改

## **tomcat如何优化：**

改Tomcat最大线程连接数

Tomcat内存优化,启动时告诉JVM我要多大内存

并发优化:在TOMCAT_HOME/bin/catalina.sh增加如下语句，Xss，设置每个线程的大小即栈的大小

JAVA_OPTS="-Xms1024m-Xmx1024m-Xss1024K-XX:PermSize=64m-XX:MaxPermSize=128m"



（1）安全方面的优化：  *********

降权启动，防止不法分子通过tomcat获得root权限  使用普通用户  防止挖矿病毒等进入

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702946488623-ec07415b-43db-4d1e-9992-63d17415f8b0.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_14%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



修改端口号：修改tomcat配置文件server.xml中的http连接器端口号，防止黑客攻击。

配置防火墙：在服务器上配置防火墙，4限制访问Tomcat的IP地址和端口，以提高安全性。

配置日志记录：启用Tomcat的日志记录功能，记录访问日志和错误日志，以便及时发现和处理安全问题。

定期更新密码：定期更改Tomcat管理界面的密码，以防止密码泄露。

配置访问控制：使用Tomcat提供的访问控制功能，限制访问Tomcat的用户和IP地址，以防止未经授权的访问。

隐藏版本号：

![img](https://cdn.nlark.com/yuque/0/2023/png/40790213/1702642062607-cfc6236e-c925-49ab-81ed-af64dc696668.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_21%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



2）Tomcat性能优化 ******

上策：优化代码

中策：调整JVM参数：通过调整Tomcat的JVM参数，例如堆大小、垃圾回收策略、线程栈大小等，可以提升Tomcat的性能。

下策：加足够大的内存

1.增大tomcat运行内存

2.利用缓存和压缩

3.组建tomcat集群



下下策：每天0点定时重启tomcat

**********tomcat不能轻易重启********



## tomcat 假死现象

tomcat假死值得是tomcat机器在有一些情况下，没有办法处理请求，服务不可用，但是仍然在运行，导致服务不可用。

导致假死的原因有：     首先查日志！

1.内存不足，如果内存不足的话，tomcat可能无法响应或'.相应缓慢，解决的方法就是增加内存  ；

2.线程过多，因为tomcat会有一定数量 的线程来处理请求，如果线程都被占用完了，导**致**请求发生了阻塞，导致tomcat变得不可响应或者响应缓慢，解决这个办法是增加线程数； /etc/security/limit.conf

3.网络问题，网络延迟或者出现丢包情况的话可能会导致tomcat变得缓慢和无法响应，解决办法是检查网络连接是否正常，并优化网络设置；

为了诊断tomcat的那种原因，我们可以查看日志，通过日志来判断是哪个原因导致的 ，具体问题具体解决吗，或者查看服务器的资源，比如cpu，内存，磁盘，网络等

重启tomcat，因为tomcat是非常消耗资源的，有时候他的问题我们无法快速确定的时候，重启tomcat是一个很好的选择

**4.**Jvm内存溢出



有一次做活动的时候，tomcat服务器假死，导致用户打不开页面（当时我们就分析了一下吗，有可能是做活动，服务器的访问量上来了，导致数据库扛不住，但是zabbix监控显示mysql的状态正常，可能跟tomcat本身有关，查看tomcat的监听端口发现，有大量的tcp连接等待关闭，手动关闭就行了）



### 新生代、老年代、持久代

新生代：类在这里产生和应用，最后被垃圾回收，所有的类在伊甸区被新生出来，当伊甸区满了之后，GC会对该区不用的对象进行销毁，剩余有用的转到幸存区

老年代：用于存放生命周期比较长的对象

永久代：存放JDK自带的class、interface

# 集群是什么？



1 集群（cluster）技术是一种较新的技术，通过集群技术，可以在付出较低成本的情况下获得在性能、可靠性、灵活性方面的相对较高的收益，其任务调度则是集群系统中的核心技术。



 集群组成后，可以利用多个计算机和组合进行海量请求处理（**负载均衡**），从而获得很高的处理效率，也可以用多个计算机做备份（高可用），使得任何一个机器坏了整个系统还是能正常运行。

### 2、负载均衡集群技术



① 负载均衡（Load Balance）：负载均衡集群为企业需求提供了可解决容量问题的有效方案。负载均衡集群使负载可以在计算机集群中尽可能平均地分摊处理。

② 负载通常包括应用程序处理负载和网络流量负载,每个节点都可以承担一定的处理负载，并且可以实现处理负载在节点之间的动态分配，以实现负载均衡。



### 3、负载均衡集群技术的实现

负载均衡技术类型：基于 4 层负载均衡技术和基于 7 层负载均衡技术

负载均衡实现方式：硬件负载均衡设备或者软件负载均衡

硬件负载均衡产品：**F5**  、深信服 、Radware

软件负载均衡产品： **LVS**（Linux Virtual Server）、 Haproxy、Nginx 、Ats（apache traffic server）

### 4、实现效果如图

![img](https://cdn.nlark.com/yuque/0/2023/jpeg/40790213/1703591336208-e501065c-18dc-49ee-aa70-ff1b19710009.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_22%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

### 5、负载均衡分类

我们先来看一张图，相信很多同学对这张图都不陌生，这是一张网络模型图，包含了 OSI 模型及 TCP/IP 模型，两个模型虽然有一点点区别，但主要的目的是一样的，模型图描述了通信是怎么进行的。它解决了实现有效通信所需要的所有过程，并将这些过程划分为逻辑上的层。层可以简单地理解成数据通信需要的步骤。



![img](https://cdn.nlark.com/yuque/0/2023/jpeg/40790213/1703591336218-c25d7c37-d3f2-47ec-a78d-a5a9738e309d.jpeg?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_16%2Ctext_6Zey6bG8SUTvvJrku47kuJrkuo5MaW51eA%3D%3D%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)



负载均衡根据所采用的设备对象（**软/硬件负载均衡**），应用的OSI网络层次（**网络层次上的负载均衡**），及应用的地理结构（**本地/全局负载均衡**）等来分类。下面着重介绍的是根据应用的 OSI 网络层次来分类的两个负载均衡类型。



**负载均衡可以大概分为以下几类：**



-  **二层负载均衡（mac）**
  一般是用虚拟mac地址方式，外部对虚拟MAC地址请求，负载均衡接收后分配后端实际的MAC地址响应。 
-  **三层负载均衡（ip）**
  一般采用虚拟IP地址方式，外部对虚拟的ip地址请求，负载均衡接收后分配后端实际的IP地址响应。 
-  **四层负载均衡（tcp）**
  在三层负载均衡的基础上，用ip+port接收请求，再转发到对应的机器。 
-  **七层负载均衡（http）**
  根据虚拟的url或IP，主机名接收请求，再转向相应的处理服务器。 



在实际应用中，比较常见的就是四层负载及七层负载。这里也重点说下这两种负载。



### 6、四层负载均衡（基于IP+端口的负载均衡）



实现四层负载均衡的软件有：



- F5：硬件负载均衡器，功能很好，但是成本很高。
- lvs：重量级的四层负载软件
- nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活（1.9）
- haproxy：模拟四层，七层转发，较灵活



### 7、七层的负载均衡（基于虚拟的URL或主机IP的负载均衡)



1. 在四层负载均衡的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别来决定是否要进行负载均衡。
2. 实现七层负载均衡的软件有： 

- haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
- nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
- apache：功能较差
- Mysql proxy：功能尚可。



### 8、四层负载与七层负载的区别

当您访问百度网站时你的浏览器上就会显示“http://www.baidu.com”，那么这个就是百度网站的URL了。

|          | 四层负载均衡     | 七层负载均衡                                     |
| -------- | ---------------- | ------------------------------------------------ |
| 基于     | 基于IP+Port的    | 基于虚拟的URL或主机IP等。                        |
| 类似于   | 路由器           | 代理服务器                                       |
| 复杂度   | 低               | 高                                               |
| 性能     | 高；无需解析内容 | 中；需要算法识别 URL，Cookie 和 HTTP head 等信息 |
| 安全性   | 低               | 高                                               |
| 额外功能 | 无               | 会话保持，图片压缩，等                           |



**总结：从上面的对比看来四层负载与七层负载最大的区别就是效率与功能的区别。四层负载架构设计比较简单，无需解析具体的消息内容，在网络吞吐量及处理能力上会相对比较高，而七层负载均衡的优势则体现在功能多，控制灵活强大。在具体业务架构设计时，使用七层负载或者四层负载还得根据具体的情况综合考虑。**



### 9、负载均衡可以大概分为以下几类：

-  **二层负载均衡（mac）**
  一般是用虚拟mac地址方式，外部对虚拟MAC地址请求，负载均衡接收后分配后端实际的MAC地址响应。 
-  **三层负载均衡（ip）**
  一般采用虚拟IP地址方式，外部对虚拟的ip地址请求，负载均衡接收后分配后端实际的IP地址响应。 
-  **四层负载均衡（tcp）**
  在三层负载均衡的基础上，用ip+port接收请求，再转发到对应的机器。 
-  **七层负载均衡（http）**
  根据虚拟的url或IP，主机名接收请求，再转向相应的处理服务器。 



在实际应用中，比较常见的就是四层负载及七层负载。这里也重点说下这两种负载。

# **lvs**

```plain
 配置lvs-server  开启路由转发
[root@lvs-server ~]# vim /etc/sysctl.conf
net.ipv4.ip_forward = 1
[root@lvs-server ~]# sysctl -p								//使添加的参数生效
[root@lvs-server ~]# yum install ipvsadm -y
设置集群调度算法，（便于验证，此处使用轮询算法）：
[root@lvs-server ~]# ipvsadm -A -t 192.168.0.108:80 -s rr
设置后端服务器：
[root@lvs-server ~]# ipvsadm -a -t 192.168.0.108:80 -r 192.168.72.128:80 -m
[root@lvs-server ~]# ipvsadm -a -t 192.168.0.108:80 -r 192.168.72.129:80 -m
查看ipvsadm规则：
[root@lvs-server ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.0.108:80 rr
  -> 192.168.72.128:80            Masq    1      0          7         
  -> 192.168.72.129:80            Masq    1      0          7    
这些规则没有保存在配置文件，重启失效
# 做开启启动
[root@lvs-server ~]# systemctl enable ipvsadm
Created symlink from /etc/systemd/system/multi-user.target.wants/ipvsadm.service to /usr/lib/systemd/system/ipvsadm.service.
[root@lvs-server ~]# ipvsadm -Ln > /etc/sysconfig/ipvsadm
```



~~~plain
配置VIP

```shell
[root@lvs-server ~]# ip addr add dev ens33 172.16.147.200/32 #设置VIP
[root@lvs-server ~]# yum install -y ipvsadm   #RHEL确保LoadBalancer仓库可用
[root@lvs-server ~]# service ipvsadm start  #启动
注意:启动如果报错: /bin/bash: /etc/sysconfig/ipvsadm: 没有那个文件或目录
需要手动生成文件
[root@lvs-server ~]# ipvsadm --save > /etc/sysconfig/ipvsadm
```

定义LVS分发策略

```shell
-A：添加VIP
-t：用的是tcp协议
-a：添加的是lo的vip地址
-r：转发到realserverip
-s：算法
-L|-l –list #显示内核虚拟服务器表
--numeric, -n：#以数字形式输出地址和端口号
-g --gatewaying #指定LVS工作模式为直接路由器模式（也是LVS默认的模式）
-m  nat模式
-S -save #保存虚拟服务器规则到标准输出，输出为-R 选项可读的格式
rr：轮循
如果添加ip错了，删除命令如下:
# ip addr del 172.16.147.200 dev ens33
```

```shell
[root@lvs-server ~]# ipvsadm -C  #清除内核虚拟服务器表中的所有记录。
[root@lvs-server ~]# ipvsadm -A -t 172.16.147.200:80 -s rr 
[root@lvs-server ~]# ipvsadm -a -t 172.16.147.200:80 -r 172.16.147.155:80 -g 
[root@lvs-server ~]# ipvsadm -a -t 172.16.147.200:80 -r 172.16.147.156:80 -g  
[root@lvs-server ~]# service ipvsadm save #保存方式一，使用下面的保存方式，版本7已经不支持了
[root@lvs-server ~]# ipvsadm -S > /etc/sysconfig/ipvsadm  #保存方式二，保存到一个文件中
[root@lvs-server ~]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.16.147.100:80 rr
  -> 172.16.147.155:80            Route   1      0          0         
  -> 172.16.147.156:80            Route   1      0          0         
     
[root@lvs-server ~]# ipvsadm -L -n       
[root@lvs-server ~]# ipvsadm -L -n --stats    #显示统计信息
1. Conns    (connections scheduled)  已经转发过的连接数
2. InPkts   (incoming packets)       入包个数
3. OutPkts  (outgoing packets)       出包个数
4. InBytes  (incoming bytes)         入流量（字节）  
5. OutBytes (outgoing bytes)         出流量（字节）
[root@lvs-server ~]# ipvsadm -L -n --rate	#看速率
1. CPS      (current connection rate)   每秒连接数
2. InPPS    (current in packet rate)    每秒的入包个数
3. OutPPS   (current out packet rate)   每秒的出包个数
4. InBPS    (current in byte rate)      每秒入流量（字节）
5. OutBPS   (current out byte rate)      每秒出流量（字节）
```
~~~

LVS（Linux virtual server）

它是一个负载均衡、高可用性集群，主要针对大业务量的网络应用（比如新闻。电子商务、网上银行…）



LVS是建立在一个主控服务器（双机）及若干个真实服务器组成。真实服务器负责提供服务，主控服务器会根据指定的调度算法对真实的服务器进行控制。LVS集群结构对用户来说是透明的，客户端只与单个IP（虚拟IP）进行通信。客户端向lvs发出服务请求，主控服务器会通过特定的算法来指定某个真实服务器来应答，而客户端只与负载均衡的IP进行通信吧 

————————————————

## **LVS负载均衡四种工作模式**

基于内核的负载均衡器



LVS/NAT：网络地址转换模式，进站/出站的数据流量经过分发器/负载均衡器(IP负载均衡，他修改的是IP地址) --利用三层功能

LVS/DR：直接路由模式，只有进站的数据流量经过分发器/负载均衡器(数据链路层负载均衡，因为他修改的是目的mac地址)--利用二层功能mac地址

LVS/TUN： 隧道模式，只有进站的数据流量经过分发器/负载均衡器

LVS/full-nat:双向转换，通过请求报文的源地址为DIP，目标为RIP来实现转发：对于响应报文而言，修改源地址为VIP，目标地址为CIP来实现转发



## lvs的nat模式和dr模式的区别 

NAT模式通过修改数据包的地址和端口实现负载均衡，客户端和后端服务器直接通信的地址和端口都被修改，客户端看到的是负载均衡器的地址和端口。

DR模式在负载均衡器和后端服务器之间建立虚拟IP地址，客户端请求直接路由到后端服务器，后端服务器直接响应客户端，不需要经过负载均衡器。这两种模式各有优劣，可根据需求选择。



lvs常见算法：

轮询调度RR：

将外部请求按照顺序轮流分配到真实的服务器上

加权轮询WRR：

根据真实服务器的不同处理能力来调度访问请求

最少链接数LC：

调度器通过最少连接调度算法动态的将网络请求调度到以建立的连接数最少的服务器上

（两台服务器配置差不多时使用）

加权最少连接WLC：

优化负载的性能，较高权重的服务器将承受较大比例的活动连接负载

（两台服务器 有一台比较弱时 可以使用）

## LVS负载均衡原理如下：



1. 客户端请求到达负载均衡器。
2. 负载均衡器根据预设算法将请求分发到多台后端服务器上。
3. 后端服务器处理请求并返回结果给客户端。



LVS通过这种方式提高系统的性能、可靠性和可扩展性。

## **lvs的调度算法**

静态（4种）和动态（6种）

但是我们常用的

静态：



rr：轮叫调度 ：按顺序将请求分发给后端服务器，依次循环。

wrr：加权轮叫  ：根据后端服务器的权重分配请求，权重高的服务器获得更多的请求。





动态：

LC：最少链接  

WLC:加权最少链接

SED:最短期望延迟调度 

## 为什么使用LVS？优势有哪些？不足点在哪？

通过LVS提供的负载均衡技术实现一个高性能、高可用的服务器群集

**优势：**

**高并发连接**：LVS基于内核工作，有超强的承载能力和并发处理能力。单台LVS负载均衡器，可支持上万并发连接。

**稳定性强：**是工作在网络4层之上仅作分发之用，这个特点也决定了它在负载均衡软件里的性能最强，稳定性最好，对内存和cpu资源消耗极低。

**成本低廉：**硬件负载均衡器少则十几万，多则几十万上百万，LVS只需一台服务器和就能免费部署使用，性价比极高。

**配置简单：**LVS配置非常简单，仅需几行命令即可完成配置，也可写成脚本进行管理。

**支持多种算法：**支持多种论调算法，可根据业务场景灵活调配进行使用。

**支持多种工作模式：**可根据业务场景，使用不同的工作模式来解决生产环境请求处理问题。

应用范围广：因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、DNS、ftp服务等等



**不足\****：**工作在4层，不支持7层规则修改，机制过于庞大，不适合小规模应用。



##  LVS的组件有哪些？

LVS的管理工具和内核模块 ipvsadm / ipvs

ipvsadm：用户空间的命令行工具，用于管理集群服务及集群服务上的RS等；

ipvs：工作于内核上的程序，可根据用户定义的集群实现请求转发；

**专业\****术语：**

**VS**：Virtual Server #虚拟服务

**Director, Balancer** #负载均衡器、分发器

**RS**：Real Server #后端请求处理服务器

**CIP**: Client IP #客户端IP

**VIP**：Director Virtual IP #负载均衡器虚拟IP

**DIP**：Director IP #负载均衡器真实IP

**RIP**：Real Server IP #后端请求处理服务器IP

## **四层负载均衡和七层负载均衡的区别**

四层负载与七层负载最大的区别就是效率与功能的区别。

四层负载架构设计比较简单，无需解析具体的消息内容，在网络吞吐量及处理能力上会相对比较高，



而七层负载均衡的优势则体现在功能多，控制灵活强大。在具体业务架构设计时，使用七层负载或者四层负载还得根据具体的情况综合考虑



**不足\****：**工作在4层，不支持7层规则修改，机制过于庞大，不适合小规模应用

# **Keepalived  高可用**

## **keepalived是什么**

keepalived是集群管理 中 保证集群高可用的一个服务软件，用来防止单点故障。

云服务器不能做云服务器（因为云服务器有自己的协议收费）



## **keepalived工作原理  ``**云服务器不能做keepalived```

keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。

------

Keepalived通过虚拟IP、健康检查、VRRP协议、配置同步和负载均衡算法实现高可用性和负载均衡，适用于构建高可靠的服务器集群。

## keepalived主要有三个模块 (不重要)

 分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。



## keepalived脑裂的情况

keepalived中，脑裂（Split Brain）是指在一个共享资源的高可用性集群中，由于网络分区或其他原因导致多个节点同时认为自己是主节点（Master），从而导致资源的冲突和数据不一致的情况。

具体来说，脑裂可能发生在以下情况下：

1. 网络分区：当集群中的节点之间的网络发生问题，导致节点之间无法正常通信时，可能会出现网络分区的情况。在这种情况下，每个分区内的节点可能会认为自己是主节点，从而导致资源冲突。
2. 节点故障：当集群中的节点发生故障或者由于其他原因导致无法正常通信时，也可能导致脑裂的发生。
3. 配置错误：错误的Keepalived配置也可能导致脑裂的发生，例如错误的优先级配置、错误的心跳检测配置等。

脑裂的发生会导致严重的问题，例如数据不一致、资源冲突等，可能会导致服务的不可用或者数据的损坏。因此，在设计高可用性集群时，需要采取一些措施来预防脑裂的发生，例如使用心跳检测、投票机制等来确保只有一个节点被选举为主节点，并且在网络分区发生时能够正确地处理这种情况。



## Keepalived的作用是什么

Keepalived是一个开源的高可用性解决方案，它可以确保系统服务的持续可用性。它通过监控服务器的健康状态，并在主服务器出现故障时自动切换到备用服务器来确保服务的连续性。Keepalived还提供了负载均衡和故障转移功能，可以帮助管理者轻松地构建高可用性的网络架构。因此，Keepalived的作用是提供系统服务的高可用性和可靠性。

##  keepalived可以结合哪些服务进行使用？2

①nginx+keepalived②LVS+keepalived③mysql+keepalived

## **你们公司部署了什么服务的keepalived，怎么配置的**



# **Haproxy**

主要是做负载均衡的7层，也可以做4层负载均衡

7层负载均衡：用的7层http协议，

4层负载均衡：用的是tcp协议加端口号做的负载均衡

## **Haproxy与nginx，lvs的区别**

HAProxy、Nginx和LVS（Linux Virtual Server）都是常见的负载均衡软件，但它们在工作原理和用途上有一些区别：



1.  HAProxy： 

- 一款高性能的负载均衡器，专注于TCP和HTTP应用层负载均衡。
- 支持基于轮询、加权轮询、最小连接数等多种负载均衡算法。
- 适用于Web服务器、应用服务器等HTTP应用负载均衡。

1.  Nginx： 

- 一款高性能的Web服务器和反向代理服务器，也可以用作负载均衡器。
- 支持HTTP、HTTPS、TCP和UDP等多种协议的负载均衡。
- 适用于静态内容的负载均衡、反向代理以及Web服务器负载均衡。

1.  LVS（Linux Virtual Server）： 

- 基于Linux内核的负载均衡解决方案，支持四层和七层负载均衡。
- 可以实现IP负载均衡、NAT负载均衡和直接路由负载均衡等多种负载均衡方式。
- 适用于大规模的网络服务负载均衡，如网站集群、邮件服务器集群等。



总的来说，HAProxy专注于TCP和HTTP负载均衡，Nginx既可以作为Web服务器又可以作为负载均衡器，而LVS是一个基于Linux内核的负载均衡解决方案，适用于大规模的网络服务负载均衡。选择合适的负载均衡软件应根据具体的需求和场景来决定。



## 简单介绍一下haproxy？

ha-proxy是一款高性能的负载均衡软件。因为其专注于负载均衡这一件事情，因此与nginx比起来在负载均衡这件事情上做更好，更专业。

haproxy---主要是做负载均衡的7层，也可以做4层负载均衡

apache也可以做7层负载均衡，但是很麻烦。

## 55. haproxy的相关算法都有哪些？你用过哪些？

1.roundrobin

轮询,在服务器的处理时间保持均匀分布时,这是最平衡,最公平的算法.此算法是动态的,这表示其权重可以在运行时进行调整.

2.static-rr

基于权重进行轮询,与roundrobin类似,但是为静态方法,在运行时调整其服务器权重不会生效.不过,其在后端服务器连接数上没有限制

3.leastconn

新的连接请求被派发至具有最少连接数目的后端服务器。

# **ansible**

## 三种工作模式

role   yaml    点对点 

## 1. 你对Ansible有什么了解？

Ansible是一个开源的自动化工具，用于部署、配置和管理计算机系统。它基于Python开发，使用简单的YAML语言来描述自动化任务，不需要在被管理的主机上安装客户端。Ansible可以用于自动化服务器的部署、配置管理、应用部署、云基础设施管理等多个领域。它的核心概念包括Playbooks（用于描述自动化任务的YAML文件）、Roles（用于组织Playbooks的任务和变量）、Inventory（用于管理被管理主机的清单）等。Ansible的设计理念是简单易用、可读性强、可扩展性好，使得它成为了许多组织和团队在自动化领域的首选工具之一。



ansible    主机的列表名   -m  调用的模块  -a  "命令"

## 模块类型

shell   #万金油模块

command模块  #默认模块，不能用管道，shell模块可以用管道



ansible-playbook    name.yml --synctax-check   检查语法正确性



   

```plain
src=:指定源文件路径
dest=:目标地址（拷贝到哪里）
owner:指定属主
group:指定属组
```



yum 模块     #下载模块

```plain
state=     #状态是什么，干什么
state=absent       用于remove安装包
state=latest       表示最新的
state=removed      表示卸载
name=下载的服务
```



service模块   #管理服务

```plain
name=名字
state=started 启动
state=stopped 关闭
state=restarted#重启
enabled=no/yes   开机自启确认
```



file模块    #远程创建文件的模块

```plain
owner:修改属主
group:修改属组
mode:修改权限
path=:要修改文件的路径
recurse：递归的设置文件的属性，只对目录有效
yes:表示使用递归设置
state:
touch:创建一个新的空文件
directory:创建一个新的目录，当目录存在时不会进行修改user模块  #远程创建用户的模块
```



cron 模块 #远程添加定时任务模块

```plain
做定时任务要添加名字name
minute   分
hour   时
day    日
month   月
weekday   周
absent     关闭
mount   #远程添加挂载
```



get_url 模块 #下载模块

url  指定下载地址

## ansible一般是怎么查看帮助

我通常会先用ansible-doc  -l 获取一下全部模块的信息去寻找自己想要使用的模块  然后用ansible-doc 加上模块   然后/EXAM 去直接调用他的使用方法

## ansible剧本

handlers #调用

文件以 .yml 结尾

hosts: 参数指定了对哪些主机进行操作；

user: 参数指定了使用什么用户登录远程主机操作；

tasks: 指定了一个任务.

name:参数同样是对任务的描述，在执行过程中会打印出来。

检测剧本正确语法： ansible-playbook   检查的文件名--syntax-check

## 角色

ansible-galaxy init tomcat    #一键生成角色目录

目录顺序:

role_name/     ---角色名称=目录

files/：存储一些可以用copy调用的静态文件。

tasks/： 存储任务的目录,此目录中至少应该有一个名为main.yml的文件，用于定义各task；其它的文件需要由main.yml进行“包含”调用； 

handlers/:此目录中至少应该有一个名为main.yml的文件，用于定义各handler；其它的文件需要由（与notify:名字相同，方便notify通知执行下一条命令）通过main.yml进行“包含”调用； 

vars/：此目录中至少应该有一个名为main.yml的文件，用于定义各variable；其它的文件需要由main.yml进行“包含”调用； 

templates/：存储由template模块调用的模板文本； （也可以调用变量）

site.yml：定义哪个主机应用哪个角色

## 2. Ansible 异步和同步？

在过去的项目中，我使用Ansible来自动化服务器的部署和配置。我编写了Ansible Playbooks来定义所需的配置和任务，并使用Ansible来管理多个服务器。。

## 3. 你认为Ansible的优势是什么？

Ansible的优势包括易于学习和使用、基于代理的无需客户端部署、支持多种操作系统和云平台、可扩展性强、以及丰富的社区支持和模块。

## 4. 你如何使用Ansible来自动化部署和配置？

我使用Ansible Playbooks来定义所需的软件包安装、配置文件设置、服务启动等任务，并将这些Playbooks应用于需要自动化部署和配置的服务器。

## 5. 你如何处理Ansible的错误和故障？

当处理Ansible的错误和故障时，我会查看Ansible的日志和输出，以便找出问题所在。我还会使用Ansible的调试模式来详细了解任务的执行过程，并进行适当的调整和修复。

## 6. 你如何管理Ansible的变量和模板？

我管理Ansible的变量和模板通过定义变量文件和使用Jinja2模板语言来生成配置文件。这样可以使配置更加灵活和可维护。



## 8. 你有使用Ansible的最佳实践吗？

我遵循Ansible的最佳实践，包括使用角色来组织Playbooks、管理变量和模板、尽量避免在Playbooks中包含复杂的逻辑、以及使用Ansible Galaxy来获取和分享角色。



## 9. 你如何在Ansible中管理多个主机和组？

我在Ansible中管理多个主机和组通过定义主机清单文件，将主机分组并为每个组定义相应的变量。

## 10. 你对Ansible的角色和playbooks有什么了解？

Ansible的角色和playbooks是Ansible中的核心概念。角色是一组任务、处理器、变量等的集合，用于实现特定的功能。而playbooks是用来描述一系列任务的YAML文件，可以调用角色来完成特定的工作。





# iptables

```plain
查看当前的防火墙规则：         iptables -L
清除当前所有的防火墙规则：     iptables -F
保存当前的iptables规则：      iptables-save > /etc/iptables/rules.v4
使用iptables禁止制定IP访问：  iptables -A INPUT -s <IP地址> -j DROP
```



每个规则表中包含多个数据链：

1.INPUT（入站数据过滤）。

2.OUTPUT（出站数据过滤）。

3.FORWARD（转发数据过滤）。

4.PREROUTING（路由前过滤）和POSTROUTING（路由后过滤）。

## **1、四表五链说一下**

四表：

row：（追踪）

mangle：（重新封装）

filter：（过滤用的）

nat：（网络地址转换）



五链：

PREROUTING：（进路由前的包）  prerouting

INPUT：（过滤后的包） input

FARWARD：（转发） farward

OUTPUT：（转发后的包） output

POSTOUTING：（出路由后的包） postouting

9

## **2、iptables和firewalld的区别99.**

firewalld默认是拒绝的，需要设置后才能放行。而iptables默认允许，需要拒绝的采取限制

1. iptables:

- iptables是Linux系统中传统的防火墙解决方案，它基于内核模块来实现网络数据包过滤和转发。
- 管理iptables需要使用iptables命令来手动配置规则，这些规则直接操作iptables内核模块。
- 当修改iptables规则时，需要使用"iptables-save"和"iptables-restore"命令来保存和恢复规则。
- 

- iptables：当修改了iptables规则后，需要使用"iptables-restore"命令来重新加载规则。
- firewalld：当修改了firewalld规则后，可以直接使用"firewall-cmd --reload"命令来重新加载规则。
- 

firewalld需要手动刷新才生效，firewalld-cmd --reload

```plain
1. 查看Firewalld防火墙规则：
firewall-cmd --list-all

2. 查看指定zone的规则（如public、internal等）：
firewall-cmd --zone=public --list-all

3. 查看指定服务的规则（如ssh、http等）：
firewall-cmd --list-services

4. 查看指定端口的规则（如80/tcp、443/tcp等）：
firewall-cmd --list-ports

以上命令可以帮助你在CentOS 7中查看Firewalld防火墙的规则，以便了解当前系统的网络安全配置情况。
```



firewalld使用区域和服务而不是链式规则

firewalld可以动态修改单条规则，动态管理规则集，运行更新规则而不破坏现有会话和连接，而iptables在修改了规则之后需要刷新才能生效



iptables的配置文件在/etc/sysconfig/iptables中，而firewalld的配置文件在/usr/lib/firewalld和/etc/firewalld中的各种xml文件中

iptables没有守护进程，并不能算是真正意义上的服务，而firewalld有守护进程

iptables通过控制端口来控制服务，而firewalld则是通过控制协议来控制端口



## 市面上常见的安全设备类型以及价格



```plain
-L:列出一个链或所有链中的规则信息
-n：以数字形式显示地址、端口等信息
-v：以更详细的方式显示规则信息
--line-numbers：查看规则时，显示规则的序号（方便之处，通过需要删除规则-D INPUT 1
-F：清空所有的规则（-X是清理自定义的链，用的少；-Z清零规则序号）
-D：删除链内指定序号（或内容）的一条规则
-P：为指定的链设置默认规则
-A：在链的末尾追加一条规则
-I：在链的开头（或指定序号）插入一条规则
-t: 指定表名，默认filter表

默认查看规则:
# iptables  -L
以数字的形式显示ip和端口与协议
# iptables -nL 
显示规则行号
# iptables -nL --line
清空规则：
#iptables  -F 
清空单独的某一个链里面的规则
#iptables  -F  链名
保存规则：
# service iptables save
# iptables-save > /etc/sysconfig/iptables
# iptables-restore < /etc/sysconfig/iptables
```



## 防火墙？

防火墙，指由软件和硬件设备组合而成、在内部网和外部网之间、局域网与外网之间的保护屏障。

就像架起了一面墙，它能使网络之间建立起一个安全网关，从而保护内部网免受非法用户的侵入。

## 硬件防火墙和软件防火墙有什么区别？

硬件防火墙，把“软件防火墙”嵌入在硬件中，把“防火墙程序”加入到芯片里面，由硬件执行这些功能，从而减少计算机或服务器的CPU负担。一般的“软件安全厂商”所提供的“硬件防火墙”，就是在“硬件服务器厂商”定制硬件，然后再把“Linux系统”与自己的软件系统结合嵌入。

软件防火墙，一般基于某个操作系统平台开发，直接在计算机上进行软件的安装和配置。由于客户之间操作系统的多样性，软件防火墙需要支持多种操作系统，如“Unix、Linux、SCO-Unix、Windows”等。



硬件防火墙，是通过硬件和软件的组合来达到隔离内外部网络的目的；

软件防火墙，是通过纯软件的的方式，实现隔离内外部网络的目的。



# RabbitMQ

RabbitMQ是一个开源的消息队列系统，用于在应用程序之间传递消息。它可以用于解耦应用程序、异步处理任务、消息通知等。



要使用RabbitMQ，首先需要安装RabbitMQ服务器。然后可以使用RabbitMQ提供的客户端库（如RabbitMQ的官方客户端库或各种语言的第三方库）在应用程序中与RabbitMQ进行交互。通过这些客户端库，可以创建消息队列、发送消息、接收消息，以及处理消息等操作。

## 消息中间件主要作用

- 冗余(存储)
- 扩展性
- 可恢复性
- 顺序保证
- 缓冲
- 异步通信

## **1、RabbitMQ普通模式和镜像模式的区别**

普通模式：以两个节点（a、b）来说明，对于Queue（消息队列载体）来说明。对于Queue来说，消息实体只存在于其中一个节点a（或者b），a和b两个节点仅有相同的元数据，即队列的结构，当消息进入a节点的Queue后，consumer从b节点消费时，RabbitMQ会临时在a、b间进行传输，把a中的消息实体取出，并经过b发送给consumer。所以consumer应尽量连接每一个节点从中取消息，即对于同一个逻辑队列，要建立多个节点建立物理Queue。否则无论consumer连a或b，出口总在a，会产生瓶颈。

镜像模式：将需要消费的队列变成镜像队列，存在于多个节点中，这样就可以实现RabbitMQ高可用性。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在consumer消费数据时临时读取，缺点就是，集群内部的同步通讯会占用大量的网络宽带。



镜像模式 适用于对可靠性要求比较高的场合中使用。



## **2、RabbitMQ和kafka的区别**

kafka是基于pull的模式来处理消息消费，追求高吞吐量，目的是用于日志的搜集和传输，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据搜集业务

RabbitMQ是基于AMQP协议实现的，这个协议主要特征是面向消息队列、路由（包括点对点和发布订阅）、可靠性、安全。用于在企业系统内对数据一致性，稳定性和可靠性要求很高的场景，对性能和吞吐量的要求在其次。

## **3、RabbitMQ集群是做七层负载均衡还是四层**

是可以使用lvs或者haproxy做四层负载均衡



# ZABBIX

随着业务的细化，监控的业务越来越多



Zabbix是一款开源的网络监控和管理系统，用于实时监控网络设备、服务器和应用程序的性能和可用性。它能够收集、分析和报告各种指标，帮助管理员及时发现和解决问题，保障系统稳定运行。

Zabbix监控和负载均衡应用交付可以帮助确保应用的高可用性和性能。以下是如何结合Zabbix监控和负载均衡应用交付的一般步骤：



1.  **安装和配置Zabbix监控系统**：首先需要在服务器上安装和配置Zabbix监控系统，包括Zabbix Server和Zabbix Agent。配置监控项、触发器和图形以监控服务器的性能和状态。 
2.  **部署负载均衡器**：选择适合的负载均衡器，如Nginx、HAProxy等，并进行部署和配置。负载均衡器可以分发流量到多台后端服务器，提高应用的可用性和性能。 
3.  **配置Zabbix监控负载均衡器**：在Zabbix监控系统中配置监控项和触发器，以监控负载均衡器的性能和状态。监控负载均衡器的负载情况、连接数、响应时间等指标。 
4.  **监控后端服务器**：配置Zabbix监控系统监控后端服务器的性能和状态，包括CPU、内存、磁盘、网络等指标。确保后端服务器正常运行并能够应对负载均衡器的流量分发。 
5.  **设置警报和通知**：在Zabbix监控系统中设置警报规则，当监控项达到预设的阈值时触发警报。配置通知方式，如邮件、短信等，及时通知管理员。 



通过结合Zabbix监控和负载均衡应用交付，可以实现对应用的全面监控和管理，提高应用的可用性、性能和稳定性。

## 1、Zabbix监控的优缺点有哪些

优点：开源、无软件成本、server端对设备性能要求低、支持的设备多，自带多种监控模板、能实现自动化监控、开放式接口，扩展性强。



## zabbix监控和负载均衡应用交付；

缺点:需在被监控主机上安装agent， 所有数据都存在数据库里，产生的数据量很大，瓶颈主要在数据库。UI图形展示（grafana）

1. 减少不必要的监控项：审查Zabbix监控项的配置，删除或者禁用不必要的监控项，以减少对数据库的查询负担。
2. 定期备份和清理历史数据：定期备份和清理Zabbix数据库中的历史数据，确保数据库的大小和性能得到有效的管理和维护。
3. 使用Zabbix代理：使用Zabbix代理来收集数据，减少直接对数据库的查询次数。代理可以在被监控的主机上运行，定期收集数据并发送给Zabbix服务器，减轻了对数据库的直接访问。



##  zabbix怎么实现监控的？

1.创建主机群组 2.创建主机加入主机组 3.添加模板4.模板关联主机5.创建监控项6.创建触发器7.配置告警动作8.创建图形

## zabbix的监控2种模式?

**被动模式：**server端向agent端请求获取监控项配置的相关数据，agent端响应，并将数据发送给server端   ，**监控对象上报故障**

**优点：**占用网络资源少，占用存储资源少

**缺点：**及时性差

**主动模式：**agent端主动向server请求与自己相关监控配置，主动将server配置的监控项的相关数据发送给server端  ，**定时查看业务状态**

优点：及时性好。

**缺点：**占用资源



server需要mysql    proxy也需要mysql



在企业中，Zabbix通常使用被动模式。被动模式下，Zabbix服务器主动向被监控的主机发送请求，获取数据。这种模式适用于需要对被监控主机进行实时监控和数据采集的情况，例如监控服务器的性能指标、日志信息等。

## **3、zabbix监控过什么**

zabbix监控redis集群的状态，监控mysql主从的状态，mysql查询吞吐量（show global status like “questions”；）、连接情况（ show status like '%connect%';）、缓冲池情况（show variables like ‘innodb_buffer_pool%’）

nginx的状态，cpu利用率，cpu负载、磁盘使用情况

读写速率
CPU
监控cpu负载
监控使用cpu资源最多的进程
内存

业务（网页是否能访问、是否可以完成下订单、注册用户）
服务的响应时间
服务的并发量（活动用户、非活动用户）

mysql主从状态 、吞吐率、端口、   监控NGINX  TOMCAT  

搭建zabbix服务用了三台，一个server，2个agent端。

## 4、常用命令

zabbix_get -s 192.168.153.178 -k  system.cpu.load[all,avg5] -p 10050       点对点命令     分布式



rpm -qa | grep "zabbix"   查看版本



**Zabbix和Prometheus都是监控工具，但是它们的主要区别在哪里？** 
答：Zabbix是一个传统的基于代理的监控工具，它通过安装代理程序在被监控主机上收集数据，然后将数据发送给Zabbix服务器进行处理和存储。而Prometheus是一个基于HTTP的无代理监控工具，它通过HTTP协议直接从被监控主机上获取指标数据，然后存储在自己的时间序列数据库中。

## 5、什么是Zabbix？它的作用是什么？ 

答：Zabbix是一款开源的网络监控和管理系统，用于实时监测各种网络参数、服务器状态和网络服务。它可以帮助管理员及时发现并解决网络和服务器方面的问题，提高系统的稳定性和可靠性。

## 6、讲讲你对监控的理解，监控的目的是什么

保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。

## **7、zabbix自定义监控怎么做**

先创建监控脚本，测试一下能否获取到我们想获取的值，然后在zabbix_agentd.conf.d目录下创建以.conf结尾的文件，在文件中写入UserParameter=<key>,<command>，key就是自定义监控项的名字，command是要执行的命令或者你创建的脚本的执行路径

## **8、zabbix的自动发现功能**

创建发现规则，扫描一个规则范围内的ip，然后创建发现主机后的action动作，我们一般都有创建好的模板，模板关联某个主机群组（有监控项、触发器、动作），发现主机后，将它添加到主机群组，实现自动化监控



## **9、zabbix分布式监控有什么特点**

主要缓解server监控端的压力，当agent过多时，server需要跟多个agent进行交互，数据过多时，server承受不住那么大的压力。所以可以在server和agent之间增加proxy，proxy代替server搜集数据，然后将数据统一发送给server。  

轻量级：

1.占用资源少（内存、CPU）

2.大小  小

3.对基础环境几乎没有依赖性

##  zabbix遇到过什么问题

**问题****1：**主机有30多个图形，但是查看时只显示了20个图形。

**原因：**是因为zabbix的php默认值为20。

**解决：**修改zabbix前端默认配置文件 defines.inc.php中的 ZBX_MAX_GRAPHS_P ER_PAGE变量值，重启服务即可。



**问题****2:** 内存溢出导致zabbix_server服务关闭？

**解决：**修改/etc/zabbix/zabbix_server.conf配置文件里添加CacheSize=1024M ，重启服务



**问题****3：**Zabbix给新机器添加监控，按正常操作完成后，发现主机那一栏最后的灯不亮

**解决：**检查防火墙和SELinux是否关闭，查zabbix_server日志，查zabbox是否启动，来回检查了好几遍，没发现问题，删除后重新加了两遍，还是灯不亮，后来在网上找相关的解决方法，试了发现不是自己遇到的问题，等过了一段时间发现灯正常亮了。

## 8.  zabbix agent端能够执行脚本，但是zabbix server端zabbix get获取不到数据，响应超时，为什么

可能是防火墙没有开放，可以看一下日志，如果没有报错的话说明请求根本就没有发送过去，可以看一下agent端的配置文件有没有问题，如果有错误日志可以看一下是拒绝访问还是那些问题。

## 9.  Zabbix是怎么开启微信报警的？

首先，需要有一个微信企业号。（一个实名认证的[微信号]一个可以使用的[手机号]一个可以登录的[邮箱号]

下载并配置微信公众平台私有接口。

配置Zabbix告警，（增加示警媒介类型，添加用户报警媒介，添加报警动作）。

## 10. Zabbix监控了多少客户端，客户端是怎么进行批量安装的？根据实际公司台数回答。

1. 使用命令生成密钥。
2. 将公钥发送到所有安装zabbix客户端的主机。
3. 安装 ansible 软件，（修改配置文件，将zabbix 客户机添加进组）。
4. 创建一个安装zabbix客户端的脚本。
5. 执行该脚本。
6. 验证。



## zabbix微信报警如何做


(1)在企业微信群聊中创建机器人，记录生成的webhook地址
(2)在server端/usr/lib/zabbix/alertscripts目录下创建一个python脚本，更换脚本中的webhook地址
(3)创建报警媒介类型，配置消息模板
(4)将用户和创建的报警媒介绑定
(5)在设置触发器之后执行的动作时选择使用自定义的报警媒介

##  Zabbix钉钉自动监控报警


(1)首先在钉钉群中添加自定义机器人，记录webhook推送消息的地址
(2)在监控端安装python3的依赖环境以及编译python3
(3)在/usr/lib/zabbix/alertscripts文件下写发送信息的python脚本，脚本中使用前面记录的webhook地址
(4)安装脚本中用到的pip模块和requests库，创建并授权脚本产生的日志文件，方便消息发送失败进行排错
(5)在web页面中创建报警媒介类型，写好脚本的名称，并配置消息模板
(6)将用户和报警媒介绑定
(7)设置监控项以及触发器，配置触发器之后执行的动作为发送信息，采用自定义的报警媒介

## 12.你们都监控Redis的什么指标？怎么做的？



Redis响应一个请求的时间

2. 平均每秒处理请求总数
3. 已使用内存

4.客户端连接数

**怎么做：**

先创建监控脚本，测试一下能否获取到我们想获取的值，AWK和cat都可以截取 内  容

然后在zabbix_agentd.conf.d目录下创建以.conf结尾的文件，

在文件中写入UserParameter=<key>,<command>，

key就是自定义监控项的名字，

command是要执行的命令或者你创建的脚本的执行路径

在zabbix页面端设置自定义监控项

**zabbix后台用**

zabbix_get -s  ip  key 测试获取值是否正确。

# docker-ce

容器其实是一种沙盒技术。沙盒就是能够像一个集装箱一样，把你的应用"装"起来的技术。这样，应用与应用之间，就因为有了边界而不至于相互干扰（隔离性）；而被装进集装箱的应用，也可以被方便地搬来搬去。

## 基础命令

```plain
docker info  查看docker运行状态
docker images   查看镜像
docker ps  查看容器（正在运行的容器）
docker ps -a  查看所有容器      -qa 查看ID
docker inspect  查看容器的详细信息（包括镜像、、、）     查看镜像详情：inspect
docker images -q  只查看所有镜像的id:
docker pull   拉镜像！！！！  跟镜像名字或者ID
docker rmi   删除镜像   rm删容器      rm -f强制
docker search centos 搜索基于 centos 操作系统的镜像
# docker stop  name
# docker kill  name      --强制终止容器
重启容器： docker restart name
让容器运行在后台：
# docker run -dit 镜像ID /bin/bash    -d 后台运行必须要加-it
docker stats   查容器占用的资源   cpu  mem
# docker kill $(docker ps  -q)   杀死所有running状态的容器
# docker stop `docker ps  -q` 杀死所有running状态的容器
docker inspect 查看容器的详细信息（包括镜像、、、）
docker stats  查看容器的cpu和内存情况
docker history ID/name  查看镜像的制作过程

docker exec -it ce02568 /bin/bash     挂起
ctrl+p+q  #退出

 docker rename mytest testmy   修改容器名称
 docker logs -f nginx1    查日志
 docker export -o centos7-1.tar 96e2b726   打包容器 docker export 容器名称 > 镜像.tar

 docker import centos7-1.tar centos7-1:v1  导入容器

 docker run -it --name c6.1 centos7-1:v1 /bin/bash       运行   d 后台运行
 docker history   ID/name   查看镜像制作过程
 
 docker build -t jenkins:v1 .  --tag, -t，镜像的名字及tag，通常name:tag或者name格式；可以在一次构建中为一个镜像设置多个tag
 # docker run -itd --name nginx1 -p 8082:80 nginx:1.23.4    映射
 
 docker create   创建不启动
 docker run -it --restart=always  daocloud.io/library/centos:7 /bin/bash   #最常用        退出时重启 交互式模式运行一个CentOS 7容器
 docker run -it --name 名字  daocloud.io/centos:6 /bin/bash   #名字自定义   起一个容器
-i：标准输入输出
-t：分配一个终端或控制台
--restart=always：容器随docker engine自启动，因为在重启docker的时候默认容器都会被关闭  
也适用于create选项
-d	后台运行容器，并返回容器ID

docker怎么将本机文件复制到docker容器中？
docker cp  本地文件路径  容器:路径  
docker cp  容器:文件路径   本地路径    复制目录需要加-a

docker export -o 包名.tar  容器名字；         打包成tar包；
docker import centos7-1.tar centos7-1:v1 ，  进行导入；

docker save -o 打包后的名字.tar     镜像名or ID       打包镜像         docker load < nginx.tar   导入镜像
echo  1 zb/proc/sys/net/ipv4/ip_forward           加1   临时生效    sysctl -p永久生效

不进入容器执行 docker exec  -it  容器id touch /testfile
docker logs -f  XX   查制定容器ID 的日志
创建容器但不启动 docker create
```



## **docker的优点**

提高服务器资源利用率、快速搭建新技术环境，不用学习复杂的部署环境、完美构建微服务部署环境、一次构建多次部署、快速部署、迁移、回滚、不依赖底层环境

相对于传统虚拟机，占用资源更少、启动更快、可移植性强，一次交付多次使用



[docker](https://www.zhihu.com/search?q=docker&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"3171236123"})其他便利性就不说了，有一个非常实用的，就是中毒了，比如挖矿、勒索病毒，只要没给[docker容器](https://www.zhihu.com/search?q=docker容器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A"3171236123"})足够的权限，这些病毒就只能跑在容器里面，不会感染宿主机，清理病毒就很方便了，删掉重开即可。



## docker为什么占用的资源少？

首先docker 容器是轻量级的，它利用操作系统层的虚拟化技术，不需要运行完整的操作系统，从而大大减少了内存和磁盘空间的占用；其次，docker使用的是宿主机的内核，从而节省了内存和磁盘空间；最重要的是docker本质上就是一个进程；

## 6.docker中kill和stop的区别：

docker的停止命令有两个:docker stop 容器名字/容器ID  和docker kill 容器名字/容器ID；

使用kill的话是直接把主进程杀死掉（容器本身就是一个进程），也算是强制杀死；强制杀死主进程的话可能会造成子进程无法自然停止，可能会造成内存无法释放，或者释放不完全；

stop的过程是先将子进程停止掉，然后再停止主进程，这样会让子进程自然停止并且可以正常释放内存；

通常情况下我们都使用stop；

## 7.docker容器怎么迁移？镜像怎么迁移？

我们可以将正在运行的容器打成tar包，打成tar包的命令有两个：docker export -o 包名.tar  容器名字；

第二个是docker export 容器名字/ID  > 包名.tar   然后将这个tar包传送到另一台机器，然后使用docker import tar包   镜像名字:版本；



镜像迁移的话是可以迁移到镜像仓库中也可以打成tar包迁移，

1.迁移到镜像仓库：例如阿里云，我们可以先登录到阿里云仓库，使用的是docker login的命令，然后将本地需要迁移的镜像打标签：docker tag 的命令，然后往镜像仓库推送：docker push 这些具体的步骤阿里云有具体的步骤；

2.打成tar包的方式迁移的话是，使用docker save -o tar包名字 镜像名:版本 进行打包，使用docker load < tar包名字，进行导入；



## docker怎么将镜像推送到远程仓库中？ 

首先需要登录到仓库，比如阿里云的，首先登录:docker   login ;然后是将这个要上传的镜像打标签：docker tag；

然后是开始推送：docker push ，详细步骤以及参数阿里云上都有；如果是将本地容器做成镜像上传到镜像仓库的话，我们可是先提交一下，docker commit；   

## **docker的缺点**

单纯用docker的话，网络是个问题，容器之间不能通信，排查问题比较麻烦

## **docker的网络模式**

host：主机网络。docker容器和主机共用一个ip地址。

none：无指定网络。启动容器时，可以通过--network=none,docker容器不会分配局域网ip

container：指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。

bridge：网络桥接  默认模式。默认情况下启动、创建容器都是用该模式，所以每次docker容器重启时会按照顺序获取对应ip地址。



## docker资源隔离

在使用 docker 运行容器时，一台主机上可能会运行几百个容器，这些容器虽然互相隔离，但是底层却使用着相同的 CPU、内存和磁盘资源。如果不对容器使用的资源进行限制，那么容器之间会互相影响，小的来说会导致容器资源使用不公平；大的来说，可能会导致主机和集群资源耗尽，服务完全不可用。



docker run --rm -it   progrium/stress --cpu 4



docker挂载点

## **dockerfile**

FROM 指定基础镜像

LABEL 为镜像指定标签

RUN 运行命令

ENV 设定环境变量

ADD 添加文件到容器： 压缩包 自动帮你解压

COPY 文件拷贝

WORKDIR 指定工作目录

EXPOSE 暴露端口

CMD 指定要运行的命令

通过dockerfile构建镜像的时候尽量把命令写到一行，因为dockerfile创建镜像是一层一层创建的，如果命令行太多，会导致镜像比较大，写在一行的话，能够减小镜像的大小

运行Dockerfile构建镜像，可以使用以下命令：

docker build -t  <image_name> <path_to_dockerfile>

## cmd和entrypoint区别

1. CMD指令为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。
2. CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。
3. 类似于 RUN 指令，用于运行程序，但二者运行的时间点不同:CMD 在docker run 时运行，RUN 是在 docker build时运行。

注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。

## ENTRYPOINT

1. 类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。
2. 如果运行 docker run 时使用了 --entrypoint 选项，将覆盖 ENTRYPOINT 指令指定的程序。
3. 在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。

注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。



CMD设置的指令在镜像运行时自动运行，无法追加指令，只能把指令全部覆盖

ENTRYPOINT设置的指令在镜像运行时与CMD一样，可以在新建镜像时设置的指令后追加新的指令，也可以使用 --entrypoint 覆盖指令。



## Docker和KVM虚拟机的区别是什么？

1.占用体积：docker容器的占用体积小，虚拟机的占用体积大；

2.隔离性：容器提供了基于进程的隔离，相同虚拟机上的不同的容器可能共用共同资源（CPU，内存，磁盘空间等），而虚拟机提供了资源完全的隔离；

3.启动速度：容器启动的速度是秒级的，而虚拟机的启动所需的时间比容器长；

4.使用内核情况：docker使用宿主机的内核，而虚拟机使用独立的内核；但是docker只能用在64位操作系统上；

本质的区别是，容器是基于进程的隔离；



一次构建，多次部署：我们第一次拉取镜像的时候镜像里边是没有环境内容等等，然后我们对他进行构建环境等等操作，然后构建完成后我们可以将他推送到镜像仓库里，然后后边需要用的时候直接拉取然后创建容器就可以直接使用，不需要再构建环境了；或者打成镜像包，后边使用的时候导入即可；

## Docker仓库，公开和私有的区别

公开的仓库拉取的时候不需要验证用户名和密码，但是推送的时候需要用户名和密码；

私有的仓库拉取和推送的时候都需要验证用户名和密码

## **docker三大核心组件**

docker registeries  docker 仓库

docker images       docker 镜像

docker containers  docker 容器

关系：

- 仓库中存储着各种不同的镜像，用户可以从仓库中拉取镜像到本地使用。
- 镜像是容器的模板，通过镜像可以创建多个相同的容器实例。
- 容器是镜像的运行实例，每个容器都是基于一个镜像创建的，可以运行在 Docker 容器引擎中。

## **docker三大组成要素：**

命名空间：命名空间保证了容器之间彼此互不影响。容器隔离，pid用于隔离进程ID、net、mnt、user、hostname

资源限制：cgroups 资源（内存、cpu）

文件系统：overlay2



# Docker容器的主要作用包括：


1**提供一致性环境**：Docker通过将应用程序及其依赖项打包成容器，确保应用程序在不同的环境中运行时保持一致性。
2**简化应用部署**：通过打包容器映像，可以轻松地在不同的机器上部署应用程序，从而简化了部署过程。
3**提高资源利用率**：Docker允许在同一台物理机器上运行多个容器，从而提高了资源利用率。
4**提供隔离和安全性**：每个Docker容器都运行在独立的命名空间中，增强了应用程序之间的隔离和安全性。
5**管理和扩展应用程序**：Docker容器可以用于管理和扩展应用程序，使开发人员能够更有效地管理应用程序的生命周期。

# **Docker-compose单节点编排工具**

## **1、了解docker-compose吗**

docker-compose也是一种编排工具，说一下比较常用的服务配置

services：定义一个容器

build：构建定义的容器，可以指定包含构建上下文的路径，或者作为一个对象，带对象具有上下文路径和指定的Dockerfile文件

image：指定启动容器的镜像，可以是镜像仓库/标签或者镜像id。如果镜像不存在compose将尝试从官方镜像仓库将其pull下来，如果同时指定了build，这种情况下，他将使用指定的build选项构建他，并使用image指定的名字来对其进行标记

container_name：定义容器的名字

volumes：卷挂载路径，可以在宿主机上挂载相对路径或者绝对路径，相对路径应始终以.或者..开始。通过顶级volumes定义一个挂载卷，并在每一个服务的卷列表引用他，会替换早期的compose中的volumes_from

command：定义了容器运行之后执行的命令

links：连接到另一个服务中的容器，需要指定服务名称和链接别名。或只指定服务名称。external_links：链接到docker-compose.yaml外部的容器

expose：暴露端口，但不映射到宿主机，只被连接的服务访问

ports：暴露端口信息，映射到宿主机

restart：容器的重启策略，默认为no（容器是否随着docker服务的启动而自启，aways总是，on-failure，出现错误重启容器）

environment：添加环境变量。注意：只给定名称的变量会自动获取他在compose主机上的值



# K8S

**容器编排是什么？**
●"编排"就是对 Docker 容器的一系列定义、配置和创建动作的管理
●Kubernetes是谷歌严格保密十几年的秘密武器—Borg的一个开源版本，是Docker分布式系统解决方案。由谷歌在2014年首次对外宣布
●Borg是谷歌内部使用的大规模集群管理系统，基于容器技术，目的是实现资源管理的自动化，以及跨多个数据中心的资源利用率的最大化
**编排工具有哪些？**
(1)kubernetes：可以跨主机，可以做集
(2)群管理；
(3)docker-compose：单机，不可以跨主机
(4)swarm：可以跨主机，这个是和docker-compose结合使用的
●kubernetes是google omega 的开源版本，Google 与 RedHat 公司共同主导的项目
(1)paas：平台即服务；相当于阿里云等购买现成的服务；减少开发量和维护成本
(2)iaas：基础设置即服务；相当于一个租赁平台器、存储，类似于公有云；
(3)saas：软件即服务；现成的系统，例如：人脸识别等
(4)caas：通讯即服务；相当于是以上三种的一个延申
**kubernetes的核心概念**
(1)master：负责资源调度，控制副本，提供统一访问集群入口，是核心节点也是管理节点
(2)node：宿主机，负责起pod
(3)nodeip：宿主机ip
(4)pod：负责起容器，放容器，可以包含多个容器；k8s管理的最小运行单位pod
(5)pause容器：负责pod中，容器间的通讯的；这个是个会自动拉起的容器。会自动创建，不需要手动创建
(6)pod IP：虚拟二层网络，不能用于外部通讯，只用于pod之间的通讯
(7)pod volume：存储卷；数据卷；作用：容器之间数据共享的
(8)Event：相当于日志，一个时间的记录；用来排错的
(9)Endpoint：（pod ip + 容器port）；作用：用来访问的
(10)ReplicaSet：作用：用来设置副本数量的
(11)Deployment：作用：用来管理ReplicaSet的；使用最频繁的
(12)RC=Replication Controller：作用：用来管理pod副本的；一个执行者
(13)Service：作用：暴漏端口的，它有暴漏内部服务的端口到外网的能力
(14)Cluster IP：集群IP--不能对外通讯，只能内部通讯；无法被ping通
(15)Lable标签与selectors--选择器
注意：Node、Pod、Replication Controller和Service等都可以看作是一种“资源对象”，几乎所有的资源对象都可以通过Kubernetes提供的kubectl工具执行增删改查等操作，并将其保存在etcd中持久化存储
**kubernetes架构和组件**
(1)master节点包含以下组件：
●api server：处理所有请求的
●scheduler：用来资源调度的；例如：控制具体在哪一台node上创建pod
●Kubernetes Controller----例如：Replication Controller：管理控制pod数量的
(2)Node节点包含以下组件：
●kubelet：具体的执行者，在node上创建pod的
●kube-proxy：负责流量或请求转发的；负责网络通信的
●Docker Engine：负责本机的容器创建和管理工作
(3)其余组件：
●kubectl：通过命令行方式，创建请求
●web ui：
●etcd：数据库；请求存储到数据库；存储请求的数据；etcd数据库，可以部署到master上，也可以独立部署，分布式键值存储系统
**集群部署**
部署方式有以下几种：
(1)minikube：单点的部署方式，基本不用
(2)kubeadm（最常用的：一个工具，提供kubeadm init和kubeadm join ，用于快速部署kubernetes'集群
(3)直接使用epel-release yum源，缺点就是版本较低1.5
(4)二进制包：很麻烦，基本不用
**kubeadm方式部署集群：有官方文档**
●三台机器--主：2核4G；从：2核2G以上；磁盘不少于20G
●在docker基础上
●域名解析
●ntpdate：时间同步
●关闭swap 分区：临时修改：swap -a；永久修改：/etc/fstab---注释掉swap分区即可
●安装kubeadm包，加载ipvs相关内核模块 ，sysctl --sysytem使配置生效，查看是否加载成功：lsmod | grep ip_vs
●配置启动kublete集群
●配置kubelet使用pause镜像，配置环境变量，配置kubelet的groups
●启动kubelet
●配置master，初始化，生成证书
●配置使用网络插件：calico.yaml
●node节点加入集群：kubeadm join ip:端口 --token
●查看一下
集群部署Dashboard页面：用页面访问的
●上传镜像
●查看集群端口
●创建访问账号：用yaml文件创建ServicAccount账号
●获取访问令牌（令牌的方式登录）
●浏览器访问：很长很长的命令
**集群常用命令**
(1)kubectl get pod -n 命名空间 # 查看对应资源：状态
(2)kubectl get pod -A	#查看所有名称空间内的pod
(3)kubectl get nodes	#查看node节点信息状态
(4)kubectl get svc		#查看service对象
(5)kubectl describe pod -n	# 查看对应资源：时间信息
(6)kubectl logs -f 			#查看pod资源日志
(7)kubectl apply -f 		#创建资源清单
(8)kubectl delete -f		#删除资源
(9)kubectl edit service 资源名	# 修改资源：根据反射出来的etcd的配置内容，生产中不允许此操作。且命令禁止
(10)kubectl cluster-info		#查看集群节点的信息
(11)kubectl -s http：//api-server:6443 get componentstatuses		#查看各组件的信息
(12)kubectl explain pod 		#查看各资源对象对应的api版本
**YAML语法：**
(1)大小写敏感
(2)使用缩进表示层级关系
(3)缩进不允许使用tab键，只允许空格
(4)缩进的空格数量不重要，只要相同层级的元素左对齐即可
(5)‘#’ 表示注释
(6)书写yaml切记: 后面要加一个空格
(7)如果需要将多段yaml配置放在一个文件中，中间要使用---分隔
**YAML文件支持以下几种数据类型：**
纯量：单个的，不可再分的值
对象：键值对的集合，又称为映射/哈希/字典
数组：一组按次序排列的值，又称为序列/列表
**创建资源清单：**
kubectl create -f yaml文件名称
kubectl apply -f yaml文件名称 
注意：apply和create的区别：
create创建的应用，如果需要修改yaml文件，必须先指定yaml文件删除，再创建新的pod
apply创建的应用，可以直接修改yaml文件，继续apply创建，不用先删掉，重新加载一边后内容会自动更新
**yaml文件里创建pod的相关命令：**
(1)创建pod：kubectl apply -f pod.yml
(2)查看pod：kubectl get pods
(3)查看pod运行在哪台机器上：kubectl get pods -o wide
(4)查看pod定义的详情信息：kubectl get pod pod的名字 -o yaml
(5)查看pod 的状态：kubectl describe pod pod的名字
(6)进入pod容器内部：kubectl exec -it website /bin/bash
(7)删除pod的两种方式：
(8)kubectl delete pod pod名1 pod名2 #单个或是多个删除
(9)kubectl delete pod --all		#批量删除
(10)kubectl delete -f xxx.yaml 		#指定创建pod的yml文件名
**Pod的生命周期：**
(1)Pending ：表示pod的yaml文件已经提交给了kubernetes，API对象被创建并保存在Etcd当中。但也有可能是容器因调度不成功等原因，创建失败
(2)Runing ：此状态表示Pod已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中
(3)Failed ：此状态表示Pod里至少有一个容器以不正常的状态退出
(4)Unknown：这是一个异常状态（未知状态）
使用YAML配置文件用于定义k8s的定义的好处：
(1)便捷性：不必添加大量的参数到命令行中执行命令
(2)可维护性：YAML 文件可以通过源头控制，跟踪每次操作
(3)灵活性：YAML可以创建比命令行更急复杂的结构
在k8s中，只需要知道两种结构类型：
(1)Lists ：列表，就是数组
(2)Maps：字典；即一个Key:Value的键值对信息
**创建Pod的三种方式**
(1)绑定Node的名称：nodeName: kub-k8s-node2		
a.#指定node节点的名称创建，要和containers保持同样的缩进
(2)绑定lable标签：nodeSelector: #指定标签，标签是唯一的
(3)绑定主机别名：HostAliases
**容器属性：**
(1)Containers：这个字段属于 Pod 对容器的定义。
(2)ImagePullPolicy 字段：定义镜像的拉取策略。默认值： Always:表示每次创建 Pod 都重新拉取一次镜像。Never:表示Pod永远不会主动拉取这个镜像IfNotPresent:表示只在宿主机上不存在这个镜像时才拉取。
(3)Lifecycle 字段：定义 Container Lifecycle Hooks。作用是在容器状态发生变化时触发一系列"钩子"。
**投射数据卷Projected Volume：pv**
**12-1、k8s支持的pv的四种方式：**
(1)Secret				# 常用：定义一次可以多次使用；用来保存敏感私密数据：如密码
(2)ConfigMap			# 放配置文件的
(3)Downward API		
(4)ServiceAccountToken
**12-2、Pod使用Secrets的方式：**
(1)内建Secrets：
由ServiceAccount创建的API证书附加的秘钥k8s自动生成的用来访问apiserver的Secret，所有Pod会默认使用这个Secret与apiserver通信
(2)创建自己的Secret：
方式1：使用kubectl create secret命令；
方式2：yaml文件创建Secret
**Secrets的相关命令：**
(1)创建secret：
kubectl create secret generic db-user-pass --from-file=./username.txt 
(2)查看创建结果：
kubectl get secrets
(3)查看详情信息：
kubectl describe secret 。。。#describe 指令不会展示secret的实际内容，这是出于对数据的保护考虑
(4)如果想查看实际内容使用命令：
kubectl get secret db-user-pass -o yaml
(5)再用 base64解码：echo Q2xvdWRAMjMwMQ==|base64 --decode
**yaml方式创建Secret**
(1)内容先用base64编码（不用明文形式）：
echo -n 'admin' | base64
echo -n '1f2d1e2e67df' | base64
(2)编写：secret.yml 
(3)创建secret.yaml文件：kubectl apply -f secret.yml 
(4)解码：echo 'MWYyZDFlMmU2N2Rm' | base64 --decode
使用Secret
(1)映射secret key到指定的路径
(2)被挂载的secret内容自动更新
(3)以环境变量的形式使用Secret（secret更新，pod中不会自动更新）
secret可以作为数据卷挂载或者作为环境变量暴露给Pod中的容器使用，也可以被系统中的其他资源使用。
创建一个Secret，多个Pod可以引用同一个Secret
**创建ConfigMap（cm）的方式：**
(1)直接在命令行的方式：--from-literal
(2)通过指定文件创建
(3)通过指定目录创建
(4)事先写好标准的configmap的yaml文件，然后kubectl create -f 创建
●通过命令行的方式创建：
kubectl create configmap test-configmap --from-literal=user=admin
●通过指定为文件的方式创建：
先vim server.conf---再kubectl create configmap test-config2 --from-file=server.conf
●通过指定目录的方式创建：
mkdir config---目录里touch文件---kubectl create configmap test-config3 --from-file=./config
●通过事先写好configmap的标准yaml文件创建：
先vim configmap.yaml---再kubectl apply -f 创建
使用ConfigMap的方式：
(1)通过环境变量使用：spec---env：
(2)作为volume挂载使用：spec---containers----volumeMounts：。。；spec--volumes:。。
**RBAC（基于角色的访问控制）**
对于一个文件：给不同职位的人不同的权限
(1)RBAC常用命令：
●生成账号：
kubectl config set-credentials soso --client-certificate=soso.crt --client-key=soso.key --embed-certs=true
●设置上下文环境：
kubectl config set-context soso@kubernetes --cluster=kubernetes --user=soso
●切换用户：
kubectl config use-context soso@kubernetes
●删除上下文：
kubectl config delete-context soso@kubernetes
●创建角色
（命令行方式）：kubectl create role role-reader --verb=get,list,watch --resource=pod,svc
（yaml文件的额方式）：vim role.yaml
●查看角色：
kubectl get roles
●查看角色的详情信息：
kubectl describe role role-reader
●用户和角色绑定：
kubectl create rolebinding myrole-binding --role=role-reader --user=soso；
也可以使用yaml文件的形式：vim role-binding.yaml



### k8s是什么？请说出你的了解？

答：Kubenetes是一针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。

K8S是Google公司推出的，它来源于由Google公司内部使用了15年的Borg系统，集结了Borg的精华。

### k8s的组件了解吗


组件：
master节点上的组件
apiserver：k8s系统的入口，封装了核心对象的增删改查功能。
scheduler：负责pod的节点选择，负责集群的资源调度，组件抽离
controller：执行各种控制器，目前提供了很多种调度器保证k8s集群的正常运行
node节点上的组件
kubelet：负责管控容器，kubelet会从k8sapiserver接受pod的创建请求，启动和停止容器，监控容器的状态并汇报给k8sapiserver
k8s-proxy：负责为pod创建代理服务。k8s-proxy会从apiserver获取所有的service信息，并根据service的信息创建代理服务，实现service到pod的请求路由和转发，从而实现k8s层级的虚拟转发网络
docker engine：docker引擎，负责本机的容器创建和管理工作以及镜像的拉取
flannel网络插件
etcd可以部署在master也可以单独部署，分布式键值存储系统，用于保存集群状态数据，比如pod、service、等对象信息



### 什么是Kubernetes？它的主要特点是什么？

Kubernetes是一个开源的容器编排平台，用于自动化部署、扩展和管理容器化应用程序。其主要特点包括：

- 自动化部署、扩展和管理容器化应用程序。
- 提供高可用性、弹性和自愈能力。
- 提供灵活的容器编排和调度功能。
- 支持多种云平台和物理基础设施。
- 提供丰富的监控、日志和调试功能。

### Kubernetes中的Pod是什么？它的作用是什么？

Pod是Kubernetes中最小的部署单元，它可以包含一个或多个紧密相关的容器。Pod提供了一种抽象层，用于封装容器应用、存储、网络等资源。Pod的作用是为容器提供一个运行环境，容器共享Pod内的网络和存储资源。

### 什么是Kubelet？它的作用是什么？

Kubelet是运行在每个Kubernetes节点上的代理程序，负责管理节点上的Pod和容器。Kubelet负责与Kubernetes Master节点通信，接收Pod的配置信息并确保Pod按照配置运行在节点上。

### Kubernetes中的Service是什么？它的作用是什么？

Service是Kubernetes中的一种抽象，用于定义一组Pod的访问方式。Service提供了一个稳定的网络端点，允许其他应用或用户访问Pod。Service可以通过标签选择器匹配一组Pod，并为这些Pod提供一个统一的入口。

### 什么是Kubernetes的控制器？它们的作用是什么？

Kubernetes的控制器是用于管理Pod和其他资源的控制器。常见的控制器包括ReplicaSet、Deployment、StatefulSet等。它们的作用是确保系统中的资源处于期望的状态，并根据需要进行自动扩展、缩容或滚动更新。

### Kubernetes中的Namespace是什么？它的作用是什么？

Namespace是Kubernetes中用于将集群划分为多个虚拟集群的一种方式。每个Namespace可以包含一组资源，如Pod、Service、Deployment等。Namespace的作用是帮助用户在集群中组织和隔离资源，使其更易管理。

### 什么是Kubernetes的Deployment？它的作用是什么？

Deployment是Kubernetes中用于定义Pod和ReplicaSet的控制器。Deployment提供了一种声明式的方式来管理Pod的部署和更新，可以实现滚动更新、回滚等功能，确保应用的稳定运行。

### Kubernetes中的ConfigMap和Secret分别是什么？它们的作用是什么？

ConfigMap用于存储应用程序的配置信息，如环境变量、配置文件等，以便应用程序能够动态获取配置信息。Secret用于存储敏感数据，如密码、密钥等，确保数据在存储和传输过程中的安全性。

### 如何进行Kubernetes集群的扩展和缩容？

Kubernetes集群的扩展和缩容可以通过调整ReplicaSet的副本数量来实现。通过增加或减少ReplicaSet的副本数量，Kubernetes会自动创建或销毁Pod来适应集群的负载变化。

### Kubernetes中的Pod如何进行日志查看和调试？

可以通过kubectl命令行工具来查看Pod的日志，例如：

```plain
kubectl logs <pod_name>
```

另外，可以通过kubectl exec命令进入Pod内部进行调试：

```plain
kubectl exec -it <pod_name> -- /bin/bash
```



##  2、k8s的控制器用过哪几种


deployment：负责管理pod副本，保证pod的实际运行数量与指定的数量一致，比RC更完
replication controller：负责管理副本的数量，是实现弹性伸缩、动态扩容和滚动升级的核心
daemonset：DaemonSet 确保全部（或者某些）节点上运行一个 Pod 的副本。当有节点加入集群时，会为他们新增一个 Pod。
statefulset：StatefulSet 中的 Pod 拥有一个具有黏性的、独一无二的身份标识。这个标识基于StatefulSet 控制器分配给每个 Pod 的唯一顺序索引。唯一标识格式：podname.servicename.namespace名称.svc.cluster.local，有序的创建删除pod

##  3、k8s的资源对象


资源对象：
Projected Volume：为了给容器提供预先定义好的数据
secret：主要用来保存小片敏感数据，例如密码、用户名、token等，创建secret后，pod引用这个secret才能使用
configmap：保存的是不需要加密的一些配置信息。
downwardapi：用于在容器中获取pod的基本信息
serviceaccount：用以给pod提权，需要定义角色、定义绑定规则，将定义的角色通过绑定规则与clusterrole绑定，然后serviceaccount关联clusterrole，pod引用这个serviceaccount实现提权
service：service是pod的一个逻辑分组，是pod服务的对外入口抽象。service同样也通过pod的标签来选择pod，与控制器一致。
ClusterIP：默认类型，自动分配一个仅可在内部访问的虚拟IP。应用方式：内部服务访问
NodePort：在ClusterIP的基础之上，为集群内的每台物理机绑定一个端口，外网通过任意节点的物理机IP:端口来访问服务。应用方式：外服访问服务
LoadBalance：在NodePort基础之上，提供外部负载均衡器与外网统一IP，此IP可以将请求转发到对应服务上。这个是各个云厂商提供的服务。应用方式：外服访问服务
ExternalName：引入集群外部的服务，可以在集群内部通过别名方式访问（通过 serviceName.namespaceName.svc.cluster.local访问）
支持持久化存储
storageclass：定义了如何创建pv
PV：描述的是持久化存储卷，主要定义的是一个持久化存储在宿主机上的目录，比如一个nfs的挂载目录
PVC：描述的是pod所希望使用的持久化存储的属性，比如。volume存储的大小、可读写权限等等
静态存储：集群管理员手工创建pv，在定义pv时需要将后端存储的特性进行设置
动态存储供给：管理员无需创建pv，而是通过storageclass的设置对后端存储进行描述，标记为某种类型。此时要求pvc对存储的类型进行声明，系统将自动完成pv的创建以及与pvc的绑定

##  4、k8s遇到过什么问题*

# Prometheus

Prometheus是一套使用[go语言](https://so.csdn.net/so/search?q=go语言&spm=1001.2101.3001.7020)进行编写的监控工具，专注于基础监控，默认仅保留15天的监控数据，15天的监控数据，已经足够运维人员去排查和分析运维故障。



## Prometheus 监控的对象有哪些？

 Prometheus 可以监控各种对象，包括物理服务器、虚拟机、容器和应用程序等。它支持多种监控方式，例如通过主动拉取指标数据、通过推送方式获取指标数据以及通过服务发现来自动发现监控目标。



## Zabbix和Prometheus都是监控工具，但是它们的主要区别在哪里？ 

答：Zabbix是一个传统的基于代理的监控工具，它通过安装代理程序在被监控主机上收集数据，然后将数据发送给Zabbix服务器进行处理和存储。而Prometheus是一个基于HTTP的无代理监控工具，它通过HTTP协议直接从被监控主机上获取指标数据，然后存储在自己的时间序列数据库中。

## Prometheus如何进行数据可视化和监控仪表盘的展示？

Prometheus可以通过Grafana等数据可视化工具展示监控数据和仪表盘。

用户可以使用PromQL查询语言编写查询，然后在Grafana中创建图表和仪表盘展示数据。

# KVM

## 命令

```plain
启动/停止虚拟机：
virsh start myvm
 virsh shutdown vm1   //正常关闭
 virsh destroy vm1	//强制关闭
 
查看虚拟机列表：  virsh list --all
删除虚拟机：  virsh undefine myvm
查看kvm模块加载:  lsmod | grep kvm

virt-manager(可用于查看安装后的虚拟机)
查看kvm虚拟机配置文件： virsh dumpxml name

修改node6的配置文件： virsh edit node6  

暂停（挂起）虚拟机： virsh suspend vm_name  
恢复虚拟机： virsh resume vm_name    

重启 virsh reboot vm1
重置（和重启没区别）: virsh reset vm1

虚拟机开机自动启动:virsh autostart vm1 
取消开机自启  virsh autostart --disable vm1
```

**KVM**
**虚拟化软件你了解吗：（企业级虚拟化和桌面虚拟化的区别？）**
●kvm和VMware esxi 企业级虚拟化软件，VMware-esxi（企业级别）本身就是一个操作系统，是可以直接安装在物理机上的强大的裸机管理系统，是一款虚拟软件
●VMware Workstation 桌面虚拟化（windows和linux）
(1)桌面虚拟化：基层硬件安装操作系统，操作系统上安装虚拟化软件，虚拟化软件和操作系统分开的
(2)企业级虚拟化：基础硬件安装VMware esxi虚拟化操作系统，虚拟化软件本身就是一个操作系统
(3)平台虚拟化（platform Virtualization），针对计算机和操作系统的虚拟化
(4)资源虚拟化（resource Virtualization），针对特定的系统资源的虚拟化，比如内存、存储、网络资源等
(5)应用程序虚拟化（Application Virtualization）：包括仿真、模拟、解释技术等。把硬件的东西变成了一个应用
**你都接触过什么虚拟化软件？都用来干什么？**
(1)VMware workstation 一般我是用来个人学习使用
(2)VMware esxi 和 KVM都属于是企业级虚拟化软件，企业的物理服务器一般都是用这两个，任选其一
(3)kvm是开源的，VMware esxi 是收费的
**半虚拟化和全虚拟化**
(1)全虚拟化是指虚拟机模拟了完整的底层硬件，包括处理器、物理内存、时钟、外设等，使得为原始硬件设计的操作系统或其他系统软件完全不做任何修改就可以在虚拟机中运行。
(2)现在的kvm与vmware都支持全虚拟化
(3)全虚拟化的运行速度要快于硬件模拟，但是性能方面不如裸机，因为Hypervisor（虚拟监控程序）需要占用一些资源
(4)半虚拟化（也叫超虚拟化）是另一种类似于全虚拟化的技术，它使用Hypervisor分享存取底层的硬件，但是它的guest操作系统集成了虚拟化方面的代码。因为操作系统自身能够与虚拟进程进行很好的协作
(5)半虚拟化需要guest（虚拟机）操作系统做一些修改，使guest操作系统意识到自己是处于虚拟环境的，但是半虚拟化提供了与原操作系统相近的性能
**kvm基础命令**
查看安装后的虚拟机：virt-manager
查看kvm虚拟机的配置文件： virsh dumpxml nam
virsh list 【只显示开机的虚拟机】（--all 显示所有虚拟机）
将node4虚拟机的配置文件保存至node6.xml
virsh dumpxml node4 > /etc/libvirt/qemu/node6.xml
查看虚拟机配置文件：virsh dumpxml 名字
修改虚拟机配置文件：virsh edit 虚拟机名字 （不需要重启）
启动: virsh start 名字
暂停(挂起)虚拟机: virsh suspend 名字 
恢复虚拟机: virsh resume 名字
正常关闭: virsh shutdown 名字
强制关闭: virsh destroy 名字
重启: virsh reboot 名字
重置（和重启没区别）: virsh reset 名字
删除虚拟机: virsh undefine 名字
虚拟机开机自动启动: virsh autostart 名字
域名vm1取消自动标记自动创建: virsh autostart --disable vm1
查看虚拟机ip
1、查看已启动的虚拟机ip: virsh dumpxml 名字 | grep mac 
2、查看已启动的虚拟机ip: virsh domifaddr 名字
虚拟机命令克隆
第一种: virt-clone -o vm1 --auto-clone
第二种: virt-clone -o vm1 -n vm2 --auto-clone
\#-n 指定克隆虚拟机的名字
第三种:virt-clone -o vm1 -n vm2 -f /var/lib/libvirt/images/vm2.img
-f 指定克隆虚拟机的镜像文件位置
**KVM磁盘镜像格式：**
raw 资源全用 不支持快照
qcow 动态资源 
qcow2 支持快照
**网络配置**
brctl show 【查看网卡】
brctl delif virbr0 vent0 【删除虚拟网卡】
brctl addif virbr0 vnet0 【添加vent网

**kvm的镜像**
KVM的镜像是指虚拟机的虚拟硬盘文件，它包含了虚拟机的操作系统、应用程序以及所有数据。在KVM中，镜像文件通常存储在宿主机的文件系统中，并被虚拟机作为其硬盘使用。
KVM支持多种镜像文件格式，其中最常见的包括RAW、QCOW和QCOW2。RAW格式是一种简单的镜像文件格式，它直接映射了宿主机的物理硬盘空间，因此性能较好，但不支持一些高级特性，如快照和压缩。QCOW和QCOW2格式则是基于RAW格式的改进，它们支持快照、压缩和增量备份等高级特性，但性能略逊于RAW格式。
**kvm的快照**
KVM（Kernel-based Virtual Machine）的快照是一种将虚拟机在某一时间点的状态（包括磁盘内容、内存、设备状态等）进行保存的功能，以便将来可以恢复到该状态。这种功能对于备份、恢复、测试等场景非常有用。
KVM快照的实现方式主要有两种：
1基于磁盘镜像的快照：这种方式是通过创建一个新的磁盘镜像文件来保存虚拟机在某一时间点的状态。这种方式对于qcow2格式的磁盘镜像文件支持得比较好，而对于raw格式的磁盘镜像文件则不太适用（除非使用LVM等工具进行额外的处理）。创建快照时，可以使用qemu-img命令或者libvirt等工具进行操作。
2基于内存状态的快照：这种方式主要是保存虚拟机的内存状态和其他资源状态，以便在需要时可以恢复到该状态。但是，如果虚拟机的磁盘内容在创建快照后被修改，那么恢复到快照状态时可能会导致数据不一致或者损坏。因此，在使用这种方式时需要特别注意。
需要注意的是，KVM快照并不是一种实时的备份解决方案，而是一种在某个时间点对虚拟机状态进行快照的方式。因此，在需要实时备份或者高可用性解决方案时，可能需要考虑其他的技术或者工具。
另外，KVM快照的名称可以由KVM随机指定分配，也可以通过配置文件等方式进行自定义设置。在实际使用中，可以根据具体的需求和场景选择合适的快照方式和管理策略。
**kvm快照和镜像的区别**
KVM的快照和镜像在虚拟机的备份和恢复方面有一些关键的区别。
1含义和用途：快照备份主要是将虚拟机的虚拟硬盘的完整副本复制一份并保存，用于恢复虚拟机的状态。这主要用于数据的恢复和操作系统的升级和维护。而镜像备份是将整个服务器的硬盘镜像复制一份并保存，包含有完整的操作系统和应用程序，用于恢复整个系统。镜像备份主要用于服务器备份和虚拟机备份，以及在操作系统需要重装或升级时。
2存储空间占用：由于镜像备份包含整个操作系统和所有的应用程序，所以它相对于快照备份而言需要占用更多的存储空间。
3恢复速度：由于快照备份只保存了虚拟机的状态，所以它的恢复速度相对于镜像备份而言会更快。
4操作系统安装与否：快照备份不包含完整的操作系统和应用程序，因此在恢复时必须重新安装操作系统和应用程序。而镜像备份包含完整的操作系统和应用程序，只需要将备份的镜像文件还原到硬盘上即可。
5其他特性：镜像还可以直接用来创建新的虚拟机实例，而快照则不能。快照通常用于当前虚拟机实例磁盘的数据恢复，而镜像可以用于当前实例及其他实例更换系统盘或创建新的虚拟机实例。此外，快照不能跨地域使用，而镜像可以。
综上所述，KVM的快照和镜像在含义、用途、存储空间占用、恢复速度、操作系统安装需求以及其他特性方面都存在明显的区别。选择使用快照还是镜像，需要根据具体的备份和恢复需求，以及可用的存储空间和恢复时间来决定。

# 其他问题

## ssh有什么作用

SSH (Secure Shell) 协议主要用于提供一个安全的通道，使得用户能在一个不安全的网络（例如互联网）上安全地访问和管理远程服务器。其主要功能包括：

1. 安全远程登录：SSH 允许用户安全地登录到远程服务器，并在该服务器上执行命令。
2. 安全文件传输：通过SSH, 用户可以安全地上传或下载文件。SSH协议家族中的SCP和SFTP协议具体负责这项功能。
3. 命令执行：用户可以通过SSH在远程服务器上执行单个命令或脚本。
4. 端口转发和隧道：SSH可以创建加密的网络隧道，以安全地转发网络流量。这对于绕过网络限制或增强网络通信的安全性非常有用。
5. 身份验证和授权：SSH提供多种身份验证机制，例如密码认证和公钥认证，以验证用户身份并控制用户对远程服务器的访问权限。
6. 加密和完整性保护：SSH协议提供强有力的加密和完整性保护功能，确保数据在传输过程中不被窃取或篡改。
7. 压缩：SSH可以在传输数据前对其进行压缩，以减少网络带宽的使用和提高传输速度。

通过以上功能，SSH协议为用户提供了一个安全、可靠和易于使用的远程访问和管理工具

## scp用的什么协议

ssh协议

### ansible什么协议

ssh协议

### ssh协议在哪一层

建立在应用层的安全协议

### ssh默认端口号

22，一般会改为其他的比如30022，可以在/etc/sshd/ssh_config中修改

### ssh一般修改什么配置

修改默认端口

## **服务器/****虚拟机****比较卡**

某天突然收到报警信息，cpu使用率和cpu负载一直很高，我就用top命令看了一下，发现是mysql占用cpu的使用率很高，就对数据库的状态进行排查，先看了一下mysql的连接数，发现并不高，然后就show processlist查看了一下mysql哪些线程在运行，发现有几条sql语句一直在执行，陷入了循环，我就把这几条sql语句截图发到开发工作群，问一下这个sql语句是干啥的，能不能停掉，不然cpu负载一直这么高要是宕机了就麻烦了，开发说可以先停掉，我就kill id号，将这几个线程杀死。解决问题，数据库内存2核8g



某天收到报警信息内存和cpu占用都很高，服务器变得很卡，就用top查看了一下，发现是一个lthpc用户起来的程序，发现占用cpu500%，对这个用户一点印象都没有，所以就kill杀死了，但是过了一会这个程序就起来了，就想着应该是有木马，就crontab –l查看了一下任务计划，因为使用root用户查看的，所以没有看到，就去了/var/spool/cron中看了一下，发现了lthpc这个用户创建的定时任务，打开看了一下，发现他每个一段时间就会执行一个脚本，我就根据里面的路径找到了这个脚本，还是隐藏文件，因为当时也比较急，没有看脚本内容就直接删除了，总结，删除无关用户，修改用户密码，增强密码强度，开启防火墙。

## 常见服务器厂家，以及服务器价格，配置等

常见服务器厂家：目前市面上常见的服务器厂家有HP、DELL、IBM、华为、浪潮等。这些厂家都有自己的特点和优势，用户可以根据自己的需求和预算选择适合自己的服务器。

服务器价格：服务器的价格因品牌、配置、性能等因素而异。一般来说，中小型企业可以选择价格相对较低的入门级服务器，价格在几千元到一万多元不等。而部门级和企业级服务器的价格则会更高，一般在数万元到数十万元不等。

服务器配置：服务器的配置包括CPU、内存、硬盘、网卡等。对于不同的应用场景，需要选择不同的配置。例如，对于需要处理大量数据的应用，需要选择配置较高的CPU和内存；对于需要存储大量数据的应用，需要选择容量较大的硬盘。

## CDN主要用来干嘛的，以及购买方式及价格

CDN（Content Delivery Network）是一种通过在各个网络节点上缓存内容来加速互联网内容传输的技术。主要用于加速网站、图片、视频等静态资源的访问速度，提高用户体验。CDN的购买方式和价格因不同的服务商而异，一般按照流量计费或按照带宽计费。用户可以根据自己的需求选择不同的套餐，价格也会因此而有所不同。以下是一些常见的CDN服务商及其购买方式和价格：

阿里云CDN：按照流量计费，价格为0.28元/GB起，具体价格根据地域、流量大小等因素而定。

腾讯云CDN：按照流量计费，价格为0.28元/GB起，具体价格根据地域、流量大小等因素而定。

百度云CDN：按照带宽计费，价格为0.6元/Mbps/天起，具体价格根据地域、带宽大小等因素而定。

## 关于国内服务器托管商的信息以及价格的介绍：

选择主打服务器托管的服务商，成立时间越久积累的运营经验越丰富，技术团队和售后服务更完善，例如地面通。

了解对方服务器托管的不同类型和方式，托管内容可以进行灵活调整甚至是量身定制，例如面通提供不同级别的套餐和满足特殊需求的服务。

价格适中最好，影响价格的因素包括带宽费用、机位费用和IP数量，具体价格根据实际需求来选择，例如带宽分为单线、双线或多线，机位分为1U、2U、4U等，IP数量可以额外购买。

托管商的信息以及价格



## 阿里云价格、基本部署

## 华为云价格、基本部署

## 腾讯云价格、基本部署

## 国内主要的DNS ISP如万网、新网、DNSPOD、阿里DNS

## 国内主要的3家CDN （加速的）ISP，对比其价格、性能、市场的占有率等

## 业务部署在物理服务器还是云服务器

物理机  4*4 128G



## 公有云，私有云，混合云的区别

###### 公有云

众多企业公用一个服务器 就是一个网络上的云服务器。可以理解为共享资源服务（用完之后清空租给别人）

优点：价格比较便宜，使用起来也很方便， 节省了维护的成本，所以用户多以创业公司和个人居多

缺点：相对来说不够安全，容易发生文件泄露的风险，而却需要移动大量数据的时候，企业面临的将是很大的一笔费用

###### 私有云

服务器可以是自己建立的也可以是租用的第三方服务器，企业独享服务器只为该企业提供数据服务。

优点：是提供了更安全的环境，用户可以根据需求选择定制其资源

缺点：安装成本高，高度安全可能会使部分功能操作有局限性

###### 混合云

混合了公有云和私有云的一种解决方式，企业可以将重要文件放置私有云，普通文件放置公有云，两者之间可以进行数据和应用的移植

优点：可以满足企业多样化的需求，节省必要的开支

缺点：是开发过程中因兼容问题可能会变得复杂，后期维护也需邀花费时间和人力，对于企业的实力要求比较高



总的来说，公有云提供商提供的公有云服务是由第三方管理和维护的，而私有云是由企业自己管理和维护的云计算基础设施，而混合云则是将公有云和私有云结合起来，以满足企业不同的需求。



# 技术面试

## 反问技术面试官



### 1、自己所应聘的部门有多少人？进去后是由谁负责带？

基本上根据这个部门员工的人数，你就可以大致了解他们的实力和规模，甚至是预测出他们这个部门目前处于一个什么样的水平和状态。



## 你们的服务上线是什么流程

**要点：**具体情况具体描述

1.需求分析和设计：我们首先会与客户沟通需求，然后根据需求进行系统设计和技术选型。

2.开发和测试：在确定好系统的功能和技术架构之后，我们会进行开发和测试。开发人员会根据设计文档编写代码，测试人员会对代码进行测试，确保系统的稳定性和可靠性。

3.部署和上线：在测试通过之后，我们会将代码部署到服务器上，并进行上线。在上线之前，我们会进行充分的准备工作，确保上线过程中不会出现问题。

4.监控和优化：一旦系统上线，我们会进行监控和优化，及时处理问题和进行性能优化。

以上是我们一般的上线流程，但具体流程可能会因项目的不同而有所差异。

## 公司网站的并发是多少

## 

### 2、贵公司就运维而言所用到的技术栈？

看自己掌握的技术是否与公司所用的技术是否匹配，并且可以看出自己与工作中所需要技能的差距。

### 3、贵公司的培训项目是什么样的呢 ？

### 4、这次面试多久可以出结果？是否还有下一轮？

### 5、学习建议类

（如果面试的时候对自己的技术面很没底的话，这个时候你可以问一问别人关于学习前端的一些经验，一般面试官都很乐于告诉你的）

### 6、您希望我们员工身上具有什么样的特质呢？

（这个是看令人心动的offer上get到的问题，个人觉得很好）

### 7、您面试到现在，看了这么多候选人，您觉得我相对于这个岗位，还有哪些差距需要改善？



## ———————————————————————

# HR面试

##  反问

几轮面试？周期？人员架构？公司主流？个人工作定位？还能做些什么？

1、公司的公司氛围、团队建设是怎样子的？

2、这个岗位出差、加班多吗？

3、新人有培训吗？

4、公司的晋升机制是什么样子的呢？

5、公司有餐补、房补、交通补助之类的吗？

6、*********当面试官问你的薪资要求时，你可以先问一下公司的薪酬体系**********

福利是否有五险一金，缴纳基数是否和工资一样？

每月除了基本工资，是否有绩效，比例各占多少？很多公司会把固定岗位工资拆分为基本工资和岗位绩效！

公司每年有几次调薪考核的机会？

每年年终奖，KPI奖金的基本算法是怎样的？

加班制度是怎样的，加班费如何计算？以及是否有员工体检，车补、话补、餐补等员工福利？

7、您认为考核这个岗位员工的最重要指标有哪些？

8、您觉得这个团队的氛围怎么样？

————————————————







## 你现在在哪里

我现在在老家因为刚过完年，陪陪老人。



你举得你的个性上最大的有点是什么？

##  五年内你的职业规划

未来5年准备往运维架构师方面去努力，其次就是用业余时间多深入学习英语，也有考RHCA和CKA的打算，主要还是想在技术方面多做深化

##  公司人员架构

我隶属于研发部 我们部门16个人左右 一共有两个运维   另外一名是实习生之前给我打下手

## 为什么离职

当初签的合同3年到期了，我在上一家公司处事都是还可以，工作不是全部，生活也要兼顾。其次就是打算与父母和家人的距离近一些

(客观理由+主观理由)



## 近期是否参加了培训考试

参加了RHCE考试

## 你能为公司带来什么

技术

## 你的业余爱好

跑步、爬山、旅行、看书、学英语、美食

## 给面试官打分

考察的比较有深度，我都没想到您能问到这些问题，为人态度谦和，如果满分是十分的话，我愿意给您一分多一分满意多一份爱。



## 你怎么理解你应聘的岗位

重要



## 你希望和什么样的上级共事

就喜欢您这样的领导，聊的来所以走到现在，觉得真挺好。

我希望我上级有什么是坦诚不公的说出来，我是一个接受建议的人，其次就是有担当一些的领导。



## 与上级的意见出现问题

干事之前充分探讨，前面讨论，后面以领导为中心，集中干，不要有任何怀疑，team

## 喜欢这个工作中的哪一点

喜欢这个场景，新事物，新场景，都是年轻人。dream

## 

## 期望薪资

   我过去的三年内一直在 XXXXX公司 工作，我是一毕业就在这个公司，这三年中，我积累了很多实战项目经验和为人处事方面的知识。

## 加班的看法

首先我认为加班是非常正常的一件事，既然吃的是公司给的这碗饭，就有义务为公司着想。公司的效益关乎着咱们一个大团体，而且我也会主动去加班，一方面也可以避开下班高峰期，另一方面可以做做工作总结 写写日报 这些。总之公司需要我加班的时候，我可以接受！

## 为什么选择运维

高中时期受信息老师的影响，接触了LINXU操作系统以及明白网站的架构方式，后来大学也如愿以偿学的这个方向，而且工作都从事3年了，加上现在国家和企业都在往这方面发展和推进，我认为前景会很不错。

## 你对我们公司了解多少

我从网上看到咱们公司是大公司，大公司各方面规章制度相对都会比较完善，一半大公司员工综合素质也比较高，其次就是技术点跟我匹配。

我从网上看到咱们公司规模不是很大，但是我愿意



## 你对我们公司有什么想了解的

贵公司是否鼓励在职进修？对于在职进修的补助办法如何？

贵公司的多角化经营，而且在海内外都设有分公司，将来是否有外派、轮调的机会？

贵公司强调的团队合作中，其它的成员素质和特性如何？

## 为什么要录取你

首先我是一个比较外向和有趣的人，我加入到公司之后可以主动的跟同事破冰，其次就是我的技术栈和咱们公司是高度吻合的，我比较年轻，学习能力没的说，我不会排除英文，因为程序员经常接触英文，我会主动的去接受英文，这对工作都是非常有帮助的。最后就是比较有争议的加班，我接受加班，不会顶撞领导，可以很好的处理好关系。

## 什么时候到岗

听您安排  一周之内都可以
# 架构学习笔记

## :one:备份Rsync

#### 理解概念：

> 全量：推送全部数据（scp）；
>
> 增量：仅推送修改新疆的数据（rsync）；
>
> 两者的区别：
>
> **“换掉整个鱼缸的水”** 和 **“只补充鱼缸蒸发掉的水”**。

##### 全量 / 增量：

> 示例：全量推送，将本机etc目录文件推送到10.0.0.31主机的/tmp/目录下
>
> scp  -r /etc/  root@10.0.0.31:/tmp/  
>
> 示例：增量推送，将本机/etc/ssh/目录文件推送到10.0.0.31主机的/mnt/目录下
>
> rsync  -avz  /etc/ssh/  root@10.0.0.31:/mnt/

##### 主流文件传输协议对比

| 特性         | FTP                    | SCP / SFTP                 | Rsync                                 |
| :----------- | :--------------------- | :------------------------- | :------------------------------------ |
| **核心优势** | 功能丰富，交互性好     | **操作简单，安全性高**     | **增量同步，效率极高**                |
| **安全性**   | **差**（明文传输）     | **高**（基于SSH加密）      | 中（SSH模式安全，守护进程模式需配置） |
| **传输效率** | 一般                   | 一般                       | **高**（只传变化部分，可压缩）        |
| **核心机制** | 双通道（控制+数据）    | SSH加密通道                | 差异比较与增量传输                    |
| **典型场景** | 匿名下载、老旧系统集成 | **临时、安全的单文件传输** | **定期备份、大规模数据同步**          |
| **使用难度** | 简单（需记命令）       | **非常简单**               | 较复杂（选项多）                      |

> #### FTP - 文件传输协议
>
> **因其安全性问题，在现代互联网环境中应尽量避免使用，除非是为兼容老旧系统或搭建公共匿名下载站。**
>
> #### SCP / SFTP - 安全复制/安全文件传输协议
>
> **系统管理员进行临时、安全文件传输的“瑞士军刀”，简单直接又可靠。**
>
> #### Rsync - 远程同步
>
> **是处理大规模、周期性数据同步和备份的“专业工程师”，功能强大，为自动化而生。**

### 传输模式

#### 本地模式：

> 单个主机本地之间的数据传输(此时类似于 cp 命令)
>
> ```powershell
> #本地拷贝数据命令
> Local: rsync [OPTION...] SRC... [DEST]
> rsync #备份命令(cp)
> [options] #选项
> SRC... #本地源文件
> [DEST] #本地目标文件
> 
> #本地拷贝数据示例
> [root@backup ~]# rsync ‐avz /etc/passwd /tmp/
> ```

#### 远程模式（SSH协议）：

> 通过 ssh 通道传输数据,类似 scp 命令

> 推送（上传）与拉取（下载）

```powershell
推送(上传)：
rsync    源    目标
示例：rsync    /etc/hosts    10.0.0.31:/tmp

拉取（下载）：
rsync    目标    源
示例：rsync    10.0.0.31:/etc/hosts    /tmp 
```

> 指令解析

```powershell
rsync  -av  /etc  10.0.0.31:/tmp
选项：
-a ： 即rlptgoD合集。r-递归复制；l复制软连接；p-保持权限不变；m保持修改时间不变；o-所有者不变；g-用户组不变；D-设备与特殊文件。
-v ： 显示过程。
-z ： 传输数据的时候进行压缩。
‐‐bwlimit=500 ： 限速500kb（默认kb单位），不要-z一起使用！
```

> Rsync 借助 SSH 协议同步数据存在的缺陷

```powershell
1.使用系统用户（不安全）
2.使用普通用户（会导致权限不足情况）
```

#### 守护进程模式（rsync协议，端口 873）：:star:

> rsync 自身非常重要的功能(不使用系统用户，更加安全)

```powershell
安装服务
dnf  install -y rsync

检查软件包内容
/etc/rsyncd.conf						配置文件（服务端配置文件，守护进程模式）
/usr/bin/rsync							rsync命令
/usr/lib/systemd/system/rsyncd.service	systemctl控制rsyncd服务的配置文件

配置服务
[root@backup ~]#cat /etc/rsyncd.conf
uid = rsync
gid = rsync
port = 873
fake super = yes
use chroot = no
max connections = 200
timeout = 600
ignore errors
read only = false
list = false
hosts allow = 10.0.0.0/24
# 允许通过的网络IP地址
hosts deny = 10.0.1.0/24
# 禁止通过的网络IP地址 
auth users = rsync_backup
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log
#####################################
[backup]
comment = welcome to oldboyedu backup!
path = /backup

根据配置文件创建必要的数据
1)创建rsync虚拟用户
[root@backup ~]#useradd -M -s /sbin/nologin rsync
[root@backup ~]#id rsync
uid=1001(rsync) gid=1001(rsync) groups=1001(rsync)
2)创建密码文件
[root@backup ~]#cat /etc/rsync.passwd
rsync_backup:123123
3)修改密码权限为600
[root@backup ~]#chmod 600 /etc/rsync.passwd
[root@backup ~]#ll /etc/rsync.passwd
-rw------- 1 root root 20 Apr 8 11:54 /etc/rsync.passwd

创建backup目录
[root@backup ~]#mkdir /backup
[root@backup ~]#ll -d /backup
drwxr-xr-x 2 root root 6 Apr 8 11:55 /backup
修改目录的权限为rsync用户
[root@backup ~]#ll -d /backup
drwxr-xr-x 2 root root 6 Apr 8 11:55 /backup
[root@backup ~]#chown rsync.rsync /backup
[root@backup ~]#ll -d /backup
drwxr-xr-x 2 rsync rsync 6 Apr 8 11:55 /backup

创建 systemd 服务文件
vi  /etc/systemd/system/rsyncd.service
[Unit]
Description=fast remote file copy program daemon
Documentation=man:rsyncd(8)
After=network.target

[Service]
Type=forking
ExecStart=/usr/bin/rsync --daemon --config=/etc/rsyncd.conf
ExecReload=/bin/kill -HUP $MAINPID
Restart=on-failure

[Install]
WantedBy=multi-user.target

# 重新加载 systemd 配置
systemctl daemon-reload
systemctl start rsyncd
systemctl enable rsyncd
ss  -tunlp  | grep 873
```

 ![image-20251023163601755](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20251023163601755.png)

> 指令解析

```powershell
rsync -avz rsync_backup@10.0.0.41::backup/oldboy/7.txt .

# 双冒号 :: 表示你正在连接到一个 rsync 守护进程。
# backup 是守护进程配置中定义的一个模块名，它指向服务器上的一个特定目录。
# /oldboy/7.txt 是该模块路径下的具体文件。
# rsync_backup这个系统不存在的用户；但必须要
这个命令的含义是： 
使用 rsync_backup 用户身份，
通过 rsync 守护进程协议，
从 10.0.0.41 服务器的 backup 模块下，
将 oldboy/7.txt 文件拉取到本机的当前目录。
```

### 客户端配置:star:

> Rsync 客户端仅需配置虚拟用户的密码,并授权为600安全权限

```powershell
# 方式一：适合终端执行指定用户密码文件
## 选项是 --password-file=/你的/密码文件/路径
## 密码文件内容只有密码（123123），没有用户名。
[root@nfs01 ~]# dnf install rsync ‐y
[root@nfs01 ~]# echo "123123" > /etc/rsync.pass
[root@nfs01 ~]# chmod 600 /etc/rsync.pass
#示例：
rsync -avz  /data/backup/ rsync_backup@10.0.0.41::backup/  --password-file=/etc/rsync.pass

# 方式二：脚本中使用，强烈推荐方式
##　命令中没有 --password-file 或其他密码相关选项。
##　环境变量只在当前终端（或Shell脚本进程）中有效。新开一个终端窗口需要重新设置。
## 设置环境变量（一次设置，在当前终端会话中有效）
[root@nfs01 ~]# export RSYNC_PASSWORD=123123
#　示例：
rsync -avz  /data/backup/ rsync_backup@10.0.0.41::backup/
```

定时备份：rsync服务 + 定时任务

实时同步：rsync服务 + sersync/lsyncd 时间实时同步

## Rsync 全网备份项目流程

- 项目步骤

|                                 |                                           |
| ------------------------------- | ----------------------------------------- |
| rsync服务端部署                 | 服务端配置  /backup/目录                  |
| rsync客户端节点配置脚本（备份） | 备份；推送；清理                          |
| 其他节点匹配定时任务            | 定时运行脚本                              |
| 在备份服务器检查并发送邮件      | 清理备份；在rsync服务端检查备份、发送邮件 |

客户端脚本

- 变量
- 打包压缩 + 定时任务
- 创建md5
- 推送到服务端
- 删除旧的备份

脚本

- 清理旧的备份
- 统计备份结果

- 发送邮件

定时脚本

 

## :two:定时任务

>部署		安装软件或服务

- 定时任务软件包名字：cronie
- 服务名称（进程） crond    比如：systemctl  status  crond

```powershell
rpm  -qa  cronie
rpm  -ql  cronie
```

> 目录结构

```powershell
- /var/spool/cron/root		用户的定时任务的配置文件的目录(一般都是root用户)
- crontab 					定时任务管理的命令
- /var/log/cron				定时任务日志
```

> 配置命令

```powershell
crontab   -l     # list查看当前用户的定时任务		
no crontab for root  # 用户未设置定时任务
crontab   -e     # edit编辑当前用户的定时任务		保存位置 /var/spool/cron/root
no crontab for root - using an empty one		# 表示该用户没有定时任务，创建一个空更新任务

```

> 定好任务格式说明

- 什么时间做什么？
  - 什么时间（分时日月周）   什么事情（命令或脚本）
  - *****************                                   command  to  be  executed
  - 分钟（0-59）；小时（0-23）；日期（1-31）；月份（1-12）：周（0-6；0或者7表示周日）

- 比喻
  - 3008* * *      go  to  school     	---->   每天早上8:30去上学
  - 0000* * *      go  to  bed              ---->   晚上12点上床睡觉  

- 注解
  - *08 * * *      go  to  大保健		# 这就变成了每天8点钟这一小时每分钟都去大保健！
  - 0000* * *      go  to  bed           # 时分已经做了设定，那就是每天这个时分去做什么事情



| 特殊符号 | 说明                                        | 案例与解释                                                   |
| :------- | :------------------------------------------ | :----------------------------------------------------------- |
| **`/`**  | **间隔频率** 表示“每隔”一段时间执行一次。   | **`*/2 * * * *`** 每2分钟执行一次。  <br />**`0 */2 * * *`** 每2小时执行一次（在每小时的0分执行）。 |
| **`-`**  | **连续范围** 表示一个连续的时间范围。       | **`0 8-22 * * *`** 在早上8点到晚上10点期间，每小时的0分执行。<br />**`0 8-22/3 * * *`** 在早上8点到晚上10点期间，每3小时执行一次（8点，11点，14点...）。 |
| **`,`**  | **多个取值** 指定多个不连续、独立的时间点。 | **`00 08,11,14,17,20 * * *`** 在每天的8点、11点、14点、17点、20点执行。 |
| **`*`**  | **每/所有** 代表该字段的所有可能取值。      | **`* * * * *`** 每分钟执行。 <br />• 在**分钟**字段：表示 0-59 • 在**小时**字段：表示 0-23 |

测试

```powershell
# 查看定时任务的日志
tail -f /var/log/cron

# 增加1小时
sudo date -s "+1 hour"

# 减少30分钟
sudo date -s "-30 minutes"

# 增加1天
sudo date -s "tomorrow"

# 回到1天前
sudo date -s "yesterday"
```

#### 案例一：

```powershell
crontab   -e 
#1. 同步时间 by duanxueli  at 20221111
* */2 * * * * /sbin/ntpdate ntp1.aliyun.com >/dev/null 2>&1
在 Rocky Linux 9 中，ntp 软件包已经被移除了。需要使用 chrony 作为替代，它是现代 Linux 发行版的默认时间同步工具。
# 安装 chrony
sudo dnf install chrony

# 启动并启用服务
sudo systemctl enable --now chronyd

# 检查服务状态
sudo systemctl status chronyd

# 查看时间同步状态
chronyc tracking
chronyc sources

# 立即进行时间同步
chronyc makestep

# 查看时间源状态
chronyc sources -v

# 查看当前时间设置
timedatectl

重新编写定时任务
crontab   -e 
#1. 同步时间 by duanxueli  at 20221111
* */2 * * * * /usr/bin/chronyc chronyc makestep >/dev/null 2>&1
```

#### 案例二：

```powershell
mkdir -p /backup/
tar zcf /backup/etc-`date +%F_%w`.tar.gz /etc/

专用脚本目录:
mkdir -p /server/scripts/
#书写脚本
cat backup-etc.sh
tar zcf /backup/etc-`date +%F_%w`.tar.gz /etc/
#执行脚本
sh backup-etc.sh

2. 定时备份 /etc/ 目录 by duanxueli at xxxx
* * * * * /bin/sh /server/scripts/backup-etc.sh >/dev/null 2>&1
```

#### 定时任务注意事项：

> 命令使用绝对路径

**原因：**

- 定时任务执行时的环境变量与用户登录时的环境不同
- `$PATH` 变量可能不包含常用目录（如 `/usr/bin`, `/bin` 等）
- 使用相对路径可能导致命令找不到

```powershell
# 使用绝对路径
0 2 * * * /bin/tar -zcf /backup/data.tar.gz /data

# 或者先设置 PATH
PATH=/usr/bin:/bin
0 2 * * * tar -zcf /backup/data.tar.gz /data
```

> 书写的命令或脚本定向到空或追加到文件

方法一：输出重定向到空（丢弃输出）

```powershell
# 丢弃所有输出（标准输出和错误输出）
0 2 * * * /bin/tar -zcf /backup/data.tar.gz /data >/dev/null 2>&1

# 或者分开重定向
0 2 * * * /bin/tar -zcf /backup/data.tar.gz /data >/dev/null 2>/dev/null
```

方法二：输出追加到日志文件

```powershell
# 输出追加到日志文件（保留执行记录）
0 2 * * * /bin/tar -zcf /backup/data.tar.gz /data >>/var/log/backup.log 2>&1

# 或者分开记录
0 2 * * * /bin/tar -zcf /backup/data.tar.gz /data >>/var/log/backup.log 2>>/var/log/backup_error.log
```

> 日期格式转义：在 crontab 中使用 % 需要转义为 \%
>
> 设置 MAILTO：可以设置 MAILTO="" 来禁用邮件通知
>
> 环境变量：可以在 crontab 开头设置必要的环境变量
>
> 脚本执行权限：如果执行脚本，确保脚本有执行权限

#### 完整的定时任务示例

```powershell
# 编辑定时任务
crontab -e

# 示例内容：
PATH=/usr/bin:/bin:/usr/sbin:/sbin
MAILTO=""  # 空字符串表示不发送邮件

# 备份任务 - 输出重定向到日志
0 2 * * * /bin/tar -zcf /backup/full_$(date +\%Y\%m\%d).tar.gz /data >>/var/log/backup.log 2>&1

# 清理任务 - 丢弃输出
0 3 * * 0 /bin/find /backup -name "*.tar.gz" -mtime +30 -delete >/dev/null 2>&1
```





## :three:存储服务NFS

服务端

> rw，读写权限；ro，仅允许只读；sync，同步；async，异步；
>
> 同步：执行操作后待彻底完成并返回结果，才能执行下一步；比喻类似为打电话或者乘出租车；性能较低、资源利用率低但安全性高；
>
> 异步：执行操作后，进程立即继续执行后续任务，不等待操作完成通知；比喻类似为发邮件或者乘公交车；性能高、资源利用率高但安全性低；

```powershell
部署
dnf install -y rpcbind nfs-utils
dnf install  -y nfs-server
# utiles 工具集合

准备目录和权限
mkdir  -p /data/
ps  -ef | grep nfs
id nfsnobody
# 该账户自动生成！
chown -R nfsnobody:nfsnobody   /data/
配置服务
vi  /etc/exports
/data/ 10.0.0.0/24（rw,sync,no_root_squash）
# 配置表示：10.0.0.0/24网段对NFS服务端的/data/目录，拥有rw读写权限和保留root用户权限
systemctl reload nfs
# reload表示优雅重启，不会中断已有连接；restart在nfs中，会导致客户端一段时间的夯住。

启动
systemctl enable  rpcbind
systemctl start  rpcbind
systemctl enable nfs
systemctl start nfs

排错指令：
rpcinfo -p ip
# 检查nfs服务端的rpc信息；ip可加可不加
showmount  -e
# 查看nfs服务端共享的目录 ； ip可写可不写 ； ip为nfs服务端的ip
df -h
# 快速查看磁盘分区的使用情况；在这里用作查看挂载目录；
```

挂载

```powershell
mount  -t  nfs  10.0.0.14:/data/  /mnt/
# 将10.0.0.14服务器上的/data/目录挂载到本地/mnt/目录；效果是访问/mnt/就是访问对端服务器的/data/目录；临时的！！！
umount  /mnt
# 卸载mnt目录
```

NFS相关文件

> 服务端配置文件路径：
>
> ```
> /etc/exports → /var/lib/nfs/etab
> ```
>
> 客户端挂载配置路径
>
> text
>
> ```
> /etc/rc.local 或 /etc/fstab → /proc/mounts
> ```

- 服务端配置

  - 解释
    - **`/etc/exports`**：管理员手动编辑的NFS共享配置文件
    - **`/var/lib/nfs/etab`**：系统实际使用的NFS导出表（运行时配置）

  - 工作流程：
    - 编辑 `/etc/exports` 文件
    - 执行 `exportfs -r` 重新加载配置
    - 系统自动生成 `/var/lib/nfs/etab`（实际生效的配置）

- 客户端配置

  - 解释
    - **`/etc/fstab`**：系统启动时自动挂载的配置文件
    - **`/etc/rc.local`**：启动脚本（也可用于挂载）
    - **`/proc/mounts`**：当前系统所有挂载点的实时信息

  - 工作流程
    - 在 `/etc/fstab` 或启动脚本中配置NFS挂载
    - 系统启动或手动挂载后
    - 在 `/proc/mounts` 中查看实际挂载状态

NFS客户端永久挂载

```powershell
方法一：挂载指令写入  /etc/rc.local  配置文件中
chmod +x  /etc/rc.d/rc.local

方法二：按照 /etc/fstab 格式要求书写
设备					挂载点		文件系统类型	 挂载参数		是否检查	是否备份
10.0.0.14:/data/	 /upload/	nfs			defaults	 0			0
```

> 如果配置了nfs客户端永久挂载，未来要优先启动nfs服务端

实时同步

- 工具
  - inotify  ：书写脚本，通过shell指令监控指定目录是否发生变化；
  - sersync：国产开源，内置inotify + rsync 指令；





## :four:CV工程师试验笔记



###### 主dns配置 (10.0.0.51)

```powershell
apt install bind9 -y
systemctl is-active bind9
cat /etc/bind/named.conf.options
options {
directory "/var/cache/bind";
recursion yes;
allow-recursion { 10.0.0.0/24; };
allow-transfer { 10.0.0.52; };
forwarders { 8.8.8.8; 114.114.114.114; };
dnssec-validation auto;
listen-on { 10.0.0.51; };
};
systemctl restart named
ss -tnulp | grep named
定制正向解析配置
cat /etc/bind/named.conf.local
zone "shiyan.com" {
type master;
file "/etc/bind/zones/db.shiyan.com";
notify yes;
also-notify { 10.0.0.52; };
};
创建区域文件目录
mkdir -p /etc/bind/zones
复制模板文件并修改
cp /etc/bind/db.local /etc/bind/zones/db.shiyan.com
cat  /etc/bind/zones/db.shiyan.com 
; ==========================================
; shiyan.com DNS Zone File
; Created: 2025-10-26
; Administrator: admin@shiyan.com
; ==========================================

$TTL 1800
@ IN SOA dns1.shiyan.com. admin.shiyan.com. (
    2024102001 ; Serial (YYYYMMDDNN)
    3600       ; Refresh
    1800       ; Retry
    604800     ; Expire
    86400      ; Negative Cache TTL
)

; ========== Nameservers ==========
    IN NS dns1.shiyan.com.
    IN NS dns2.shiyan.com.

; ========== DNS Servers ==========
dns1    IN A 10.0.0.51
dns2    IN A 10.0.0.52

; ========== Storage Layer (TTL=1800) ==========
; 存储层解析（TTL=1800，默认已匹配）
mysql-master    IN A 10.0.0.70
0mysql-slave1    IN A 10.0.0.71
mysql-slave2    IN A 10.0.0.72
nfs-storage     IN A 10.0.0.200
nfs1            IN A 10.0.0.61
nfs2            IN A 10.0.0.62
backup          IN A 10.0.0.60

; ========== Cache Layer (TTL=1800) ==========
; 缓存层解析（TTL=1800，默认已匹配）
redis-master    IN A 10.0.0.30
redis-slave     IN A 10.0.0.31

; ========== Application Layer (TTL=300) ==========
; 应用层（单独设置TTL=300，格式：TTL值 + 记录类型）
$TTL 300
mycat           IN A 10.0.0.201
mycat1          IN A 10.0.0.80
mycat2          IN A 10.0.0.81
jpress-1        IN A 10.0.0.90
jpress-2        IN A 10.0.0.91
wordpress       IN A 10.0.0.95
discuz          IN A 10.0.0.96

; ========== Reverse Proxy Layer (TTL=300) ==========
; 反向代理层（TTL=300，沿用上面的$TTL 300）
nginx-1         IN A 10.0.0.105
nginx-2         IN A 10.0.0.106

; ========== Load Balancer Layer ==========
; 接入层（vip需要TTL=300，其他用默认1800）
$TTL 1800
lvs-master      IN A 10.0.0.125
lvs-backup      IN A 10.0.0.126
$TTL 300
vip             IN A 10.0.0.130

; ========== Operations Layer ==========
; 运维层（zabbix需要TTL=3600
$TTL 3600
zabbix-master   IN A 10.0.0.145
zabbix-slave    IN A 10.0.0.146
$TTL 1800
ansible         IN A 10.0.0.149

; ========== Business Entry Layer (TTL=300) ==========
; 业务入口层（TTL=300）
$TTL 300
www             IN CNAME vip.shiyan.com.

检查配置文件
named-checkconf
named-checkzone shiyan.com /etc/bind/zones/db.shiyan.com

systemctl enable named
systemctl restart named
systemctl restart bind9
systemctl enable bind9
```

###### 从dns配置 (10.0.0.52)

```powershell
apt install bind9 -y
systemctl is-active bind9
开放入口
cat /etc/bind/named.conf.options
options {
directory "/var/cache/bind";
recursion yes;
allow-recursion { 10.0.0.0/24; };
dnssec-validation auto;
listen-on { 10.0.0.52; };
};
systemctl restart named
ss -tnulp | grep named
添加 “从区域” 配置
cat /etc/bind/named.conf.local
zone "shiyan.com" {
        type slave;
        file "/var/cache/bind/db.shiyan.com";
        masters { 10.0.0.51; };
};
检查配置语法
named-checkconf
systemctl restart named
systemctl enable named
验证同步效果
ls /var/cache/bind/
file /var/cache/bind/db.shiyan.com
```

###### 整体测试

- CNAME域名解析测试

```powershell
dig www.shiyan.com +short @10.0.0.51
dig www.shiyan.com +short @10.0.0.52
```

- 普通域名解析测试

```powershell
dig mysql-master.shiyan.com +short @10.0.0.52
dig mysql-master.shiyan.com +short @10.0.0.51
```

##### 存储部署

- 基础环境配置--增加dns地址

  

###### mysql主 （10.0.0.70）

```powershell
安装软件
apt install mysql-server -y
创建专属的二进制文件目录并修改属主属组
mkdir -pv /data/mysql/logbin
chown -R mysql:mysql /data/mysql/
定制配置文件
grep -Ev '#|^$' /etc/mysql/mysql.conf.d/mysqld.cnf
[mysqld]
user = mysql
bind-address = 0.0.0.0 # 开放访问入口
mysqlx-bind-address = 0.0.0.0 # 开放访问入口
key_buffer_size = 16M
myisam-recover-options = BACKUP
log_error = /var/log/mysql/error.log
server-id = 10 # 指定server-id
log_bin = /data/mysql/logbin/mysql-bin # 指定二进制文件路径
default_authentication_plugin=mysql_native_password # 避免出现认证问题
max_binlog_size = 100M
# binlog_ignore_db = mysql # 忽略系统库

ubuntu主机开放apparmor的访问权限
tail -n4 /etc/apparmor.d/usr.sbin.mysqld
# 增加如下的两行允许mysql使用自定义日志目录
/data/mysql/logbin/ r,
/data/mysql/logbin/** rw,

systemctl restart apparmor
systemctl restart mysql

认证环境配置--创建同步用的账号认证信息
mysql
CREATE USER 'repl'@'10.0.0.%' IDENTIFIED BY '123123';
GRANT REPLICATION SLAVE ON *.* TO 'repl'@'10.0.0.%';
FLUSH PRIVILEGES;
确认主节点效果
SHOW MASTER STATUS\G;
```

###### msyql从 （10.0.0.71）

```powershell
apt install mysql-server -y
grep -Ev '#|^$' /etc/mysql/mysql.conf.d/mysqld.cnf
[mysqld]
user = mysql
bind-address = 10.0.0.71 # 开放访问入口
mysqlx-bind-address = 10.0.0.71 # 开放访问入口
key_buffer_size = 16M
myisam-recover-options = BACKUP
log_error = /var/log/mysql/error.log
server-id = 11 # 指定server-id
relay-log = mysql-relay-bin # 启用中继日志
read-only = 1 # 设为只读（避免从节点写操作）
default_authentication_plugin	= mysql_native_password # 避免出现认证问题

systemctl restart mysql
mysql
CHANGE MASTER TO
MASTER_HOST='10.0.0.70',
MASTER_USER='repl',
MASTER_PASSWORD='123123',
MASTER_LOG_FILE='mysql-bin.000001', # 主节点的 File 值
MASTER_LOG_POS=157; # 主节点的 Position 值
FLUSH PRIVILEGES;

start slave;				# 启动集群
show slave status\G;		# 确认集群效果
```

###### msyql从 （10.0.0.72）

```powershell
apt install mysql-server -y
root@mysql-s-72:~# grep -Ev '#|^$' /etc/mysql/mysql.conf.d/mysqld.cnf
[mysqld]
user            = mysql
bind-address            = 10.0.0.72
mysqlx-bind-address     = 10.0.0.72
server-id               = 12
relay-log               = mysql-relay-bin
read-only               = 1
default_authentication_plugin   = mysql_native_password
key_buffer_size         = 16M
myisam-recover-options  = BACKUP
log_error = /var/log/mysql/error.log
max_binlog_size   = 100M
重启服务
systemctl restart mysql
创建集群
mysql
CHANGE MASTER TO
MASTER_HOST='10.0.0.70',
MASTER_USER='repl',
MASTER_PASSWORD='ReplPass123!',
MASTER_LOG_FILE='mysql-bin.000002', # 主节点的 File 值
MASTER_LOG_POS=157; # 主节点的 Position 值
FLUSH PRIVILEGES;
启动集群
start slave;
确认集群效果
show slave status\G
```

###### 集群环境测试

```powershell
show slave hosts;
主节点上创建测试数据
CREATE DATABASE IF NOT EXISTS test_db;	# 创建数据库
USE test_db;
CREATE TABLE IF NOT EXISTS student (
id INT PRIMARY KEY AUTO_INCREMENT, -- 学号：主键（唯一标识），自动递增
name VARCHAR(20) NOT NULL, -- 姓名：字符串类型，非空（必须填写）
age INT DEFAULT 0 -- 年龄：整数类型，默认值为 0（未填写时自动填
充）
);
# 创建 student 表
INSERT INTO student (name, age)			
VALUES
('张三', 15),
('李四', 16),
('王五', 15);
SELECT * FROM student;					# 查询表中所有数据，验证插入结果

slave1 上测试效果
mysql -e "select * from test_db.student"
slave2 上测试效果
mysql -e "select * from test_db.student"
```

###### 改造slave2节点

```powershell
创建专属的二进制文件目录并修改属主属组
mkdir -pv /data/mysql/logbin
chown -R mysql:mysql /data/mysql/
定制配置文件
grep -Ev '#|^$' /etc/mysql/mysql.conf.d/mysqld.cnf
[mysqld]
user = mysql
bind-address = 10.0.0.12 # 开放访问入口
mysqlx-bind-address = 10.0.0.12 # 开放访问入口
key_buffer_size = 16M
myisam-recover-options = BACKUP
log_error = /var/log/mysql/error.log
server-id = 10 # 指定server-id
log_bin = /data/mysql/logbin/mysql-bin # 指定二进制文件路径
log_bin_index = /data/mysql/logbin/mysql-bin.index
default_authentication_plugin=mysql_native_password # 避免出现认证问题
log_slave_updates = 1 # 关键：记录从主节点同步的操作到binlog
expire_logs_days = 7 # 自动清理7天前的binlog
max_binlog_size = 1G # 单个binlog文件最大1G（避免过大）
开放apparmor的访问权限
tail -n4 /etc/apparmor.d/usr.sbin.mysqld
# 增加如下的两行允许mysql使用自定义日志目录
/data/mysql/logbin/ r,
/data/mysql/logbin/** rw,
重新启动服务
systemctl restart apparmor
systemctl restart mysql
mysql
# 创建备份账户
CREATE USER 'backup_user'@'localhost' IDENTIFIED BY '123123';
授予备份所需的核心权限
GRANT SELECT, SHOW VIEW, RELOAD, LOCK TABLES, REPLICATION CLIENT, PROCESS ON *.* TO 'backup_user'@'localhost';
FLUSH PRIVILEGES;
确认效果
mysql -ubackup_user -p'BackupPass123!' -hlocalhost -e "select version();"
定制客户端连接认证
tail -n4 /etc/mysql/mysql.cnf
[mysqldump]
user=backup_user
password=BackupPass123!
socket=/var/run/mysqld/mysqld.sock
测试效果
root@mysql-s-72:~# mysqldump \
--databases test_db \
--single-transaction \
--source-data=2 \
--lock-tables=false \
> test_backup_$(date +%Y%m%d).sql
确认效果
grep -Ev '\-|/|^$' test_backup_2025*
清理文件
 rm -f test_backup_2025*
```

###### slave2的全量备份

```powershell
mkdir /data/scrips -pv
定制备份用脚本
vim /data/scrips/mysql_full_backup.sh
#!/bin/bash
# *************************************
# * 功能: mysql全量备份(分库分表)
# * 作者: deepseek
# * 联系: https://chat.deepseek.com/a/chat/s/d429fcf1-6db9-45c7-b00a-6e59bcd97557
# * 版本: 2025-10-26 修正版
# *************************************

# 基础配置
BASE_DIR="/data/backup/mysql_backups"
FULL_DIR="${BASE_DIR}/full"
LOG_DIR="${BASE_DIR}/logs"
MD5_DIR="${BASE_DIR}/md5_checksums"
DATE=$(date +%Y%m%d)
TIMESTAMP=$(date +%Y%m%d%H%M)

# 数据库连接配置
MYSQL_USER="backup_user"
MYSQL_PASS="123123"
MYSQL_SOCKET="/var/run/mysqld/mysqld.sock"
EXCLUDE_DBS=("information_schema" "performance_schema" "sys" "mysql")

# 创建必要目录
mkdir -p "${FULL_DIR}/${DATE}" "${LOG_DIR}" "${MD5_DIR}"
LOG_FILE="${LOG_DIR}/full_backup_${TIMESTAMP}.log"

echo "===== 全量备份启动 | 时间：$(date '+%Y-%m-%d %H:%M:%S') =====" >> "${LOG_FILE}"

# 获取所有业务数据库列表
ALL_DBS=$(mysql -u"${MYSQL_USER}" -p"${MYSQL_PASS}" -S "${MYSQL_SOCKET}" \
-N -e "SHOW DATABASES;" 2>> "${LOG_FILE}")

# 过滤掉系统库
BUSINESS_DBS=()
for DB in ${ALL_DBS}; do
    if ! [[ " ${EXCLUDE_DBS[@]} " =~ " ${DB} " ]]; then
        BUSINESS_DBS+=("${DB}")
    fi
done

# 分库分表备份函数
backup_db_tables() {
    local db=$1
    echo "开始备份数据库: ${db}" >> "${LOG_FILE}"
    
    # 获取当前数据库的所有表
    TABLES=$(mysql -u"${MYSQL_USER}" -p"${MYSQL_PASS}" -S "${MYSQL_SOCKET}" \
    -D "${db}" -N -e "SHOW TABLES;" 2>> "${LOG_FILE}")
    
    # 分表备份
    for table in ${TABLES}; do
        local backup_file="${FULL_DIR}/${DATE}/${db}_${table}_full_${TIMESTAMP}.sql"
        
        # 执行备份（单表）
        mysqldump -u"${MYSQL_USER}" -p"${MYSQL_PASS}" -S "${MYSQL_SOCKET}" \
        --single-transaction \
        --source-data=2 \
        --lock-tables=false \
        "${db}" "${table}" > "${backup_file}" 2>> "${LOG_FILE}"
        
        # 检查备份是否成功
        if [ $? -ne 0 ] || [ ! -s "${backup_file}" ]; then
            echo "错误：数据库 ${db} 表 ${table} 备份失败" >> "${LOG_FILE}"
            rm -f "${backup_file}"
            continue
        fi
        
        # 生成MD5校验值
        md5sum "${backup_file}" > "${MD5_DIR}/$(basename ${backup_file}).md5"
        echo "成功备份：${backup_file}" >> "${LOG_FILE}"
    done
}

# 执行所有业务库备份
for db in "${BUSINESS_DBS[@]}"; do
    backup_db_tables "${db}"
done

# 记录binlog位置信息（修正版）
BINLOG_POS_FILE="${FULL_DIR}/${DATE}/binlog_pos.txt"
echo "===== 当前实例binlog信息 =====" > "${BINLOG_POS_FILE}"
mysql -u"${MYSQL_USER}" -p"${MYSQL_PASS}" -S "${MYSQL_SOCKET}" \
-N -e "SHOW MASTER STATUS" 2>> "${LOG_FILE}" \
| awk '{print "Binlog_File: " $1 "\nBinlog_Pos: " $2}' >> "${BINLOG_POS_FILE}"

# 清理31天前的备份（修正版）
echo "清理31天前的全量备份..." >> "${LOG_FILE}"
find "${FULL_DIR}" -type d -mtime +31 -exec rm -rf {} \; 2>/dev/null
find "${MD5_DIR}" -name "*.md5" -mtime +31 -delete
find "${LOG_DIR}" -name "full_backup_*.log" -mtime +31 -delete

echo -e "===== 全量备份完成 | 时间：$(date '+%Y-%m-%d %H:%M:%S') =====" >> "${LOG_FILE}"
```

> 脚本测试

```powershell
tree /data/backup/
/bin/bash /data/scrips/mysql_full_backup.sh
tree /data/backup/

创建目标目录（如“20250816”，对应1个月前的日期）
mkdir -p /data/backup/mysql_backups/full/20250816
在目录内创建文件（如备份文件和binlog记录文件）
touch /data/backup/mysql_backups/full/20250816/order_full_20250816.sql
touch /data/backup/mysql_backups/full/20250816/binlog_pos.txt
调整目录和文件的时间为“1个月前”
find /data/backup/mysql_backups/full/20250816 -exec touch -d "2 month ago" {} +
tree /data/backup/mysql_backups/
执行脚本
/bin/bash /data/scrips/mysql_full_backup.sh

tree /data/backup/mysql_backups/
```

###### slave2的增量备份

```powershell
编写mysql增量同步脚本文件
vim /data/scrips/mysql_incr_backup.sh
#!/bin/bash
# *************************************
# * 功能: mysql增量备份数据(分库分表)
# * 作者: deepseek
# * 联系: https://chat.deepseek.com/a/chat/s/d429fcf1-6db9-45c7-b00a-6e59bcd97557
# * 版本: 2025-10-26
# *************************************
# 基础配置
BASE_DIR="/data/backup/mysql_backups"
INCR_DIR="${BASE_DIR}/incremental" # 增量备份存储路径

FULL_DIR="${BASE_DIR}/full" # 全量备份路径（用于获取binlog基线）
LOG_DIR="${BASE_DIR}/logs" # 日志路径
MD5_DIR="${BASE_DIR}/md5_checksums" # 校验值存储路径
DATE=$(date +%Y%m%d) # 日期（用于目录命名）
TIMESTAMP=$(date +%Y%m%d%H%M) # 时间戳（用于文件名")
# 数据库连接配置
MYSQL_USER="backup_user"
MYSQL_PASS="123123"
MYSQL_SOCKET="/var/run/mysqld/mysqld.sock"
MYSQL_BINLOG_DIR="/data/mysql/logbin" # slave2本地binlog目录（需启用log_bin）
EXCLUDE_DBS=("information_schema" "performance_schema" "sys" "mysql") # 排除系统库

# 创建必要目录
mkdir -p "${INCR_DIR}/${DATE}"
LOG_FILE="${LOG_DIR}/incr_backup_${TIMESTAMP}.log"
echo "===== 增量备份启动 | 时间：$(date '+%Y-%m-%d %H:%M:%S') =====" >> "${LOG_FILE}"

# 获取最新全量备份的binlog位置
get_latest_binlog_info() {
# 查找最新的全量备份目录
LATEST_FULL=$(ls -rt "${FULL_DIR}" | tail -n1)
# 读取全量备份记录的“从库自身binlog信息”
BINLOG_POS_FILE="${FULL_DIR}/${LATEST_FULL}/binlog_pos.txt"

# 解析从库自身的binlog文件名和pos值（关键！）
SLAVE_BINLOG_FILE=$(grep "Slave_Binlog_File" "${BINLOG_POS_FILE}" | awk '{print $2}')
SLAVE_BINLOG_POS=$(grep "Slave_Binlog_Pos" "${BINLOG_POS_FILE}" | awk '{print $2}')
echo "使用全量备份 ${LATEST_FULL} 的binlog基线：${SLAVE_BINLOG_FILE}:${SLAVE_BINLOG_POS}" >> "${LOG_FILE}"
}

# 获取所有业务数据库列表（与全量备份保持一致）
get_business_dbs() {
ALL_DBS=$(mysql -u"${MYSQL_USER}" -p"${MYSQL_PASS}" -S "${MYSQL_SOCKET}" \
-N -e "SHOW DATABASES;" 2>> "${LOG_FILE}")
# 过滤系统库
BUSINESS_DBS=()
for DB in ${ALL_DBS}; do
if ! [[ " ${EXCLUDE_DBS[@]} " =~ " ${DB} " ]]; then
BUSINESS_DBS+=("${DB}")
fi
done
}

# 分库增量备份函数（基于binlog）
backup_incr_db() {
local db=$1
local backup_file="${INCR_DIR}/${DATE}/${db}_incr_${TIMESTAMP}.sql"

echo "开始备份数据库 ${db} 的增量数据" >> "${LOG_FILE}"
# 解析binlog，提取指定库的增量数据
mysqlbinlog --start-position="${SLAVE_BINLOG_POS}" \
--database="${db}" \
-u"${MYSQL_USER}" -p"${MYSQL_PASS}" -S "${MYSQL_SOCKET}" \
"${MYSQL_BINLOG_DIR}/${SLAVE_BINLOG_FILE}" > "${backup_file}" 2>> "${LOG_FILE}"

# 检查备份是否成功
if [ $? -ne 0 ] || [ ! -s "${backup_file}" ]; then
echo "错误：数据库 ${db} 增量备份失败" >> "${LOG_FILE}"
rm -f "${backup_file}"
return 1
fi
# 生成MD5校验值
md5sum "${backup_file}" > "${MD5_DIR}/$(basename ${backup_file})-incr.md5"
echo "成功备份：${backup_file}" >> "${LOG_FILE}"
return 0
}

# 主执行流程
get_latest_binlog_info
get_business_dbs
# 对所有业务库执行增量备份
for db in "${BUSINESS_DBS[@]}"; do
backup_incr_db "${db}"
done
# 清理8天前的增量备份
echo "清理8天前的增量备份..." >> "${LOG_FILE}"
find "${INCR_DIR}" -type d -mtime +8 -exec rm -rf {} \;
find "${MD5_DIR}" -name "*-incr.md5" -mtime +8 -delete
# ================================== 备份完成日志 ==================================
echo -e "\n===== 增量备份完成 | 时间：$(date '+%Y-%m-%d %H:%M:%S') =====" >> "${LOG_FILE}"
```

> 脚本测试

```powershell
清理环境
rm -rf /data/backup/mysql_backups/*
全量备份
/bin/bash /data/scrips/mysql_full_backup.sh
tree /data/backup/mysql_backups/
cat /data/backup/mysql_backups/full/2025*/binlog_pos.txt
主节点添加数据
mysql -e "INSERT INTO test_db.student (name, age)  VALUES('张三1', 15);"
slave2节点做增量同步
/bin/bash /data/scrips/mysql_incr_backup.sh
确认增量同步后的效果
tree /data/backup/mysql_backups/
```

###### 定时任务

> 在 slave2 节点上添加以下定时任务

```powershell
crontab -e
# 每周一凌晨4:00执行全量备份
0 4 * * 1 /bin/bash /data/scrips/mysql_full_backup.sh
# 每2小时执行一次增量备份（0:00、2:00、...、22:00）
0 */2 * * * /bin/bash /data/scrips/mysql_incr_backup.sh
```

##### NFS 服务部署

- 共享目录规划
  - 共享目录路径
    - /nfs/jpress
    - /nfs/wordpress
    - /nfs/discuz

- 权限规划      10.0.0.0/24(rw,sync,no_root_squash)
  - rw（Read-Write，读写权限）
  - sync（同步写入）
  - no_root_squash（不压缩 root 权限）

- 实施方案:  rsync + sersync 实时双向数据同步

###### 环境部署

主节点NFS（10.0.0.20）

```powershell
apt install nfs-server -y
创建专属的工作目录
mkdir -pv /data/{jpress,wordpress,discuz}
定制配置文件
cat /etc/exports
/data/discuz 10.0.0.0/24(rw,sync,no_root_squash)
/data/wordpress 10.0.0.0/24(rw,sync,no_root_squash)
/data/jpress 10.0.0.0/24(rw,sync,no_root_squash)
重启nfs服务
systemctl restart nfs-server
确认效果
exportfs -v
showmount -e 10.0.0.20
```

从节点NFS（10.0.0.21）

```powershell
apt install nfs-server -y
mkdir -pv /data/{jpress,wordpress,discuz}
cat /etc/exports
/data/discuz 10.0.0.0/24(rw,sync,no_root_squash)
/data/wordpress 10.0.0.0/24(rw,sync,no_root_squash)
/data/jpress 10.0.0.0/24(rw,sync,no_root_squash)
systemctl restart nfs-server
exportfs -v
showmount -e 10.0.0.21
```

###### 数据同步方案

> 环境前提：
>
> 1 两台主机已安装 NFS 服务，且/data目录已通过 NFS 共享。
> 确保权限一致，建议使用root或相同 UID/GID 的用户操作，避免权限冲突。
> 2 网络互通，建议配置 SSH 免密登录。
> rsync通过 SSH 传输时无需密码。

###### 双机免密认证

> NFS1——10.0.0.20

```powershell
生成密钥对
ssh-keygen -t rsa
# 执行指令后回一次询问 密钥保存路径、设置密钥密码 ； 直接无脑回车键保存在当前用户家目录中，密码留空 ；
跨主机免密码认证
root@ubuntu-nfs1-20:~# ssh-copy-id root@10.0.0.21
测试效果
ssh root@10.0.0.21 "hostname -I"
```

> NFS2——10.0.0.21

```powershell
ssh-keygen -t rsa
ssh-copy-id root@10.0.0.20
ssh root@10.0.0.20 "hostname -I"
```

###### nfs1部署rsync

```powershell
apt install -y rsync inotify-tools
nfs2节点准备数据传输环境
touch /data/{discuz,jpress,wordpress}/nfs2.txt
tree /data/
nfs1节点准备数据传输环境
touch /data/{discuz,jpress,wordpress}/nfs1.txt
tree /data/{discuz,jpress,wordpress}
先通过 rsync 手动同步一次，确认目录权限、文件传输正常
rsync -avz --delete \
/data/jpress \
/data/wordpress \
/data/discuz \
root@10.0.0.21:/data/
nfs2确认数据同步效果
tree /data/

定制rsync服务
cat  /etc/rsyncd.conf 
# 全局配置
uid = root
gid = root
use chroot = no
max connections = 10
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsync.lock
log file = /var/log/rsyncd.log
ignore errors
read only = no
list = no
# 同步模块：jpress（对应/data/jpress目录）
[jpress]
path = /data/jpress
comment = jpress data sync
hosts allow = 10.0.0.20/32 10.0.0.21/32
auth users = rsync_user
secrets file = /etc/rsyncd.secrets
# 同步模块：wordpress
[wordpress]
path = /data/wordpress
comment = wordpress data sync
hosts allow = 10.0.0.20/32 10.0.0.21/32
auth users = rsync_user
secrets file = /etc/rsyncd.secrets
# 同步模块：discuz
[discuz]
path = /data/discuz
comment = discuz data sync
hosts allow = 10.0.0.20/32 10.0.0.21/32
auth users = rsync_user
secrets file = /etc/rsyncd.secrets
定制认证文件
echo "rsync_user:123123" > /etc/rsyncd.secrets		# 创建密码文件（格式：用户名:密码）
chmod 600 /etc/rsyncd.secrets			# 限制权限（必须600，否则rsync服务启动失败）
systemctl enable rsync.service
systemctl restart rsync.service
```

```powershell
在nfs2上部署软件、定制新文件
apt install -y rsync inotify-tools
touch /data/wordpress/test_nfs2.txt
同步wordpress模块至nfs1（在nfs2执行）
rsync -av /data/wordpress/ rsync_user@10.0.0.20::wordpress
验证nfs1是否收到（在nfs1执行）
ls /data/wordpress/test_nfs2.txt
```

```powershell
rsync测试2 (在nfs2执行)
创建专属密码文件【注意：密码文件，里面只需要存放密码值就可以了】
echo "123123" > /etc/rsyncd.pwd
chmod 600 /etc/rsyncd.pwd
测试效果
rsync -avz /data/wordpress/ rsync_user@10.0.0.20::wordpress --password-file=/etc/rsyncd.pwd
```

###### nfs2部署rsync

```powershell
确认软件包，没有就apt
apt show rsync
nfs1节点确认数据传输环境
tree /data/{wordpress,discuz,jpress}
nfs2节点准备数据传输环境
rm -f /data/{discuz,jpress,wordpress}/*
tree /data/{discuz,jpress,wordpress}
touch /data/{wordpress,discuz,jpress}/test_nfs2.txt
先通过 rsync 手动同步一次，确认目录权限、文件传输正常
rsync -avz --delete \
/data/jpress \
/data/wordpress \
/data/discuz \
root@10.0.0.20:/data/
nfs1确认数据同步效果 -- nfs1上的数据应该丢弃
tree /data/{wordpress,discuz,jpress}
```

```powershell
rsync服务定制
vi  /etc/rsyncd.conf
# 全局配置
uid = root
gid = root
use chroot = no
max connections = 10
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsync.lock
log file = /var/log/rsyncd.log
ignore errors
read only = no
list = no
# 同步模块：jpress（对应/data/jpress目录）
[jpress]
path = /data/jpress
comment = jpress data sync
hosts allow = 10.0.0.20/32 10.0.0.21/32
auth users = rsync_user
secrets file = /etc/rsyncd.secrets
# 同步模块：wordpress
[wordpress]
path = /data/wordpress
comment = wordpress data sync
hosts allow = 10.0.0.20/32 10.0.0.21/32
auth users = rsync_user
secrets file = /etc/rsyncd.secrets
# 同步模块：discuz
[discuz]
path = /data/discuz
comment = discuz data sync
hosts allow = 10.0.0.20/32 10.0.0.21/32
auth users = rsync_user
secrets file = /etc/rsyncd.secrets
定制认证文件
echo "rsync_user:123123" > /etc/rsyncd.secrets
chmod 600 /etc/rsyncd.secrets
systemctl enable rsync.service
systemctl restart rsync.service
```

> rsync测试1

```powershell
在nfs1执行
echo "123123" > /etc/rsyncd.pwd
chmod 600 /etc/rsyncd.pwd
在nfs1上定制新文件
rm -f /data/{wordpress,discuz,jpress}/*
touch /data/{wordpress,discuz,jpress}/test_nfs1.txt
tree /data/{wordpress,discuz,jpress}
同步所有目录信息至nfs2
for i in wordpress discuz jpress
do
    rsync -avz /data/$i/ rsync_user@10.0.0.21::$i --password-file=/etc/rsyncd.pwd
done
验证nfs2是否收到
tree /data/{wordpress,discuz,jpress}
```

###### nfs1部署sersync

```powershell
mkdir /data/softs -p ; cd /data/softs
wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz
mkdir /data/server
tar xf sersync2.5.4_64bit_binary_stable_final.tar.gz -C /data/server/
mv /data/server/GNU-Linux-x86 /data/server/sersync
ls /data/server/sersync/
mkdir /data/server/sersync/{bin,conf}
mv /data/server/sersync/confxml.xml /data/server/sersync/conf/
mv /data/server/sersync/sersync2 /data/server/sersync/bin/
tree /data/server/sersync/
```

```powershell
安装xml检测工具
apt install -y libxml2-utils
定制专属的配置文件
cat /data/server/sersync/conf/confxml.xml
<?xml version="1.0" encoding="ISO-8859-1"?>
<head version="2.5">
<host hostip="localhost" port="8008"></host>
<debug start="false"/> <!-- 关闭调试模式 -->
<fileSystem xfs="false"/> <!-- 非xfs文件系统 -->
<filter start="false"> <!-- 不启用过滤 -->
<exclude expression="(.*)\.svn"></exclude>
<exclude expression="(.*)\.gz"></exclude>
</filter>
<inotify> <!-- 监控所有文件事件 -->
<delete start="true"/>
<createFolder start="true"/>
<createFile start="true"/>
<closeWrite start="true"/>
<moveFrom start="true"/>
<moveTo start="true"/>
<attrib start="true"/>
<modify start="true"/>
</inotify>
<sersync>
<!-- 同步模块1：jpress -->
<localpath watch="/data/jpress">
<remote ip="10.0.0.21" name="jpress"/> <!-- 目标nfs2的IP和模块名 -->
</localpath>
<!-- rsync参数配置（与系统中的rsync认证匹配） -->
<rsync>
<commonParams params="-artuz"/> <!-- 基础同步参数 -->
<auth start="true" users="rsync_user"
passwordfile="/etc/rsyncd.pwd"/> <!-- 密码文件路径 -->
<userDefinedPort start="false" port="873"/> <!-- 默认rsync端口 -->
<timeout start="true" time="100"/>
<ssh start="false"/> <!-- 禁用ssh模式，使用rsync daemon -->
</rsync>
<!-- 失败日志与重试 -->
<failLog path="/var/log/sersync_fail.log" timeToExecute="60"/> <!-- 60秒
重试失败任务 -->
<crontab start="false" schedule="600"><!--600mins-->
<crontabfilter start="false">
<exclude expression="*.php"></exclude>
<exclude expression="info/*"></exclude>
</crontabfilter>
</crontab>
<plugin start="false" name="command"/>
</sersync>
</head>
确认配置文件语法问题
xmllint --noout /data/server/sersync/conf/confxml.xml
```

> 测试sersync

```powershell
nfs1主机准备文件
echo nihao > /data/jpress/sersync.txt
nfs2主机清理环境
root@nfs2:~# rm -rf /data/{wordpress,discuz,jpress}/*
使用当前目录结构启动sersync
/data/server/sersync/bin/sersync2 -r -o /data/server/sersync/conf/confxml.xml
nfs2主机确认效果
tree /data/{wordpress,discuz,jpress}
nfs1主机再次输入文件效果
mkdir /data/jpress/dir{1,2,3}
touch /data/jpress/dir{1,2,3}/nihao.txt
/data/server/sersync/bin/sersync2 -r -o /data/server/sersync/conf/confxml.xml
nfs2主机验证自动数据同步的效果
tree /data/{wordpress,discuz,jpress}
清理环境
ps aux | grep rsync | grep -v grep
pkill sersync2
ps aux | grep rsync | grep -v grep
```

###### 改造sersync (nfs执行)

```powershell
cd /data/server/sersync/conf/ && mv confxml.xml jpress_conf.xml
准备服务文件
vi /etc/systemd/system/sersync_jpress.service
[Unit]
Description=Sersync service for /data/jpress directory sync
After=network.target rsync.service
[Service]
Type=forking
ExecStart=/data/server/sersync/bin/sersync2 -d -r -o /data/server/sersync/conf/jpress_conf.xml
ExecStop=pkill -f sersync2
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal
[Install]
WantedBy=multi-user.target
启动服务
systemctl daemon-reload
systemctl start sersync_jpress.service
systemctl is-active sersync_jpress.service
确认数据同步效果
echo xxx > /data/jpress/fengyun.txt			# nfs1主机准备文件
ls /data/jpress/							# nfs2确认效果
关闭服务(nfs1执行)
systemctl stop sersync_jpress.service
systemctl is-active sersync_jpress.service
```

###### 定制其他sersync

```powershell
准备配置文件 (nfs1执行)
cd /data/server/sersync/conf/  && cp jpress_conf.xml wordpress_conf.xml  && cp jpress_conf.xml discuz_conf.xml
sed -i 's/jpress/wordpress/g' wordpress_conf.xml  && sed -i 's/jpress/discuz/g' discuz_conf.xml  && ls
准备服务文件
cd /etc/systemd/system/ && cp sersync_jpress.service sersync_wordpress.service && cp sersync_jpress.service sersync_discuz.service
sed -i 's/jpress/wordpress/g' sersync_wordpress.service && sed -i 's/jpress/discuz/g' sersync_discuz.service
grep ExecStart sersync_*
启动服务
systemctl daemon-reload
systemctl enable rsync sersync_wordpress.service sersync_discuz.service sersync_jpress.service
systemctl restart rsync sersync_wordpress.service  sersync_discuz.service sersync_jpress.service
```

###### 综合测试

```powershell
确认nfs2主机效果
tree /data/{wordpress,discuz,jpress}
nfs1主机操作数据
rm -rf /data/{wordpress,discuz,jpress}/* && touch /data/{wordpress,discuz,jpress}/nfs1.txt
nfs2主机确认数据同步效果
tree /data/{wordpress,discuz,jpress}
```

**到此为止，sersync服务在nfs1主机上部署完毕**

###### nfs2部署sersync

```powershell
nfs2节点安装secsync
scp -r root@10.0.0.20:/data/server /data/
nfs2节点配置secsync
sed -i 's/10.0.0.21/10.0.0.20/g' /data/server/sersync/conf/*.xml && grep remote /data/server/sersync/conf/*.xml
准备服务启动文件
scp root@10.0.0.20:/etc/systemd/system/sersync_*  /etc/systemd/system/
启动数据同步服务
systemctl daemon-reload
systemctl enable rsync sersync_wordpress.service sersync_discuz.service sersync_jpress.service
systemctl restart rsync sersync_wordpress.service sersync_discuz.service sersync_jpress.service
配置sersync (nfs2主机操作数据)
rm -rf /data/{wordpress,jpress,discuz}/*  &&  touch /data/{wordpress,jpress,discuz}/nfs2-txt
nfs1主机确认数据同步效果
tree /data/{wordpress,discuz,jpress}
```

**到此为止，sersync服务在nfs2 和 nfs1主机上部署完毕**



##### **Backup Server服务部署**

> 基础环境部署

```powershell

```







# 补充笔记

### 初始化部署

- 允许远程登陆

```powershell
编辑 SSH 配置文件：
vim /etc/ssh/sshd_config

修改或添加以下参数：
# 允许 root 登录
PermitRootLogin yes
# 如果需要密码认证（可选）
PasswordAuthentication yes

重启 SSH 服务：
systemctl restart ssh

检验
# 检查配置语法
sudo sshd -t
# 查看服务状态
sudo systemctl status ssh
ss  -tunlp | grep 22
```

- 修改主机名称
- 修改IP地址
- 定义终端命令提示符的显示格式和颜色 ( 注意不要放置在shell语句中 )

```powershell
永久生效（添加到 ~/.bashrc）
root@rocky9-10:~# vi .bashrc
PS1='\[\e[1;31m\]\u@\h\[\e[0m\]:\[\e[1;35m\]\w\[\e[0m\]\$ '

重新加载配置文件
. ~/.bashrc

颜色代码：
\[\e[1;31m\] - 亮红色
\[\e[1;35m\] - 亮紫色
\[\e[0m\] - 重置颜色
内容变量：
\u - 当前用户名
\h - 主机名
\w - 当前工作目录的完整路径
\$ - 普通用户显示$，root用户显示#
```

- 下载常用软件包

  - ```powershell
    # 查询软件包信息（包括未安装的）
    dpkg -l | grep 软件包名称
    
    # 搜索包含关键字的软件包
    apt search 软件包名称
    
    # 查看软件包是否存在及详细信息
    apt show 软件包名称
    
    # 检查软件包是否在仓库中
    apt list 软件包名称
    
    # 模拟安装，查看依赖和是否可用
    apt install -s 软件包名称
    ```

```powershell
下载
apt install -y \
  wget curl tree bash-completion \
  network-manager net-tools iputils-ping \
  vim unzip

apt install -y dnsutils

网络工具
wget - 命令行下载工具
curl - 网络数据传输工具
nmcli - NetworkManager 命令行工具
net-tools - 传统网络工具（ifconfig、netstat等）
iputils-ping - ping 命令

系统工具
tree - 树状显示目录结构
bash-completion - Bash 自动补全
vim - 文本编辑器
unzip - ZIP 压缩包解压
```



### 克隆虚拟机部署

> 链接克隆的优点不提，其缺点如下：
>
> 需要频繁在母体与本体之间查找数据，读取操作性差；

- 在开机进入虚拟机前重新生成MAC地址

- 重置系统唯一标识符

```powershell
rm -f /etc/machine-id 
systemd-machine-id-setup 
```

- 重置SSH主机密钥

```powershell
rm -f /etc/ssh/ssh_host_*
ssh-keygen -A
systemctl  restart sshd
```

> rm -f /etc/machine-id 
> systemd-machine-id-setup 
>
> rm -f /etc/ssh/ssh_host_*
> ssh-keygen -A
> systemctl  restart sshd

### 修改网卡名称 ( 以rocky9为例 )

> 重命名连接

```powershell
nmcli connection modify "ens160" connection.id "eth0"
```

> 修改配置文件网卡名称

```powershell
cd /etc/NetworkManager/system-connections/
mv  ens160.nmconnection eth0.nmconnection 
sed -i "s@ens160@eth0@g" /etc/NetworkManager/system-connections/eth0.nmconnection
```

> 重新生成并更新系统的启动菜单配置文件
>
> 1. **检查现状** -> 2. **修改内核参数** -> 3. **验证修改** -> 4. **生成最终菜单** -> 5. **重启生效**

```powershell
# 检查当前运行的内核参数
cat /proc/cmdline
# 确认是否包含 net.ifnames=0 biosdevname=0

grubby --update-kernel=ALL --args="net.ifnames=0 biosdevname=0"
# 添加内核参数
# 目标：此命令会直接修改 /boot/loader/entries/ 下的引导条目，为 ALL 内核添加网卡命名规则参数。
# 注意：这一步是“修改配置”，而不是“生成最终菜单”。

# 验证参数是否添加成功
grubby --info=$(grubby --default-kernel)

# 查看系统启动项
ls /boot/efi
# 如果返回值是EFI   那么执行指令
grub2-mkconfig -o /boot/efi/EFI/rocky/grub.cfg
# 否则
grub2-mkconfig -o  /boot/grub2/grub.cfg

# 重启系统
reboot
```

> 网卡名称生成异常情况处理

```powershell
# 查看网卡状态
nmcli connection show

# 根据网卡名称删除网卡 eth130 
nmcli connection delete "eth130"
# 根据网卡设备的UUID删除
sudo nmcli connection delete f547318d-ac79-3c72-9908-fd53cdee2e79

# 重新为 eth130 网卡设备创建连接
nmcli connection add type ethernet ifname eth130 con-name eth0


nmcli device disconnect eth0
# 危险的指令，没有的指令！立即断开 eth0 网卡的连接，释放其IP地址，并将其状态设置为"已断开"。
```



### 修改网卡名称 ( 以ubuntu2404为例 )

部署环境

```powershell
# 更新软件包列表
apt update

# 安装 NetworkManager……（bash-completion重启才能生效）
apt install network-manager bash-completion -y


# 启动并启用 NetworkManager 服务
systemctl start NetworkManager
systemctl enable NetworkManager

# 检查服务状态
systemctl status NetworkManager
```

永久修改启动参数

```powershell
# 查看系统启动项
ls /boot/efi

# 查看 GRUB 版本
grub-install --version

如果是efi启动模式		grub2-mkconfig -o /boot/efi/EFI/rocky/grub.cfg
如果是BIOS启动模式		grub-mkconfig -o  /boot/grub2/grub.cfg   或者    grub-mkconfig -o /boot/grub/grub.cfg

# 修改 GRUB 配置以使用传统网卡命名
sed -i 's/GRUB_CMDLINE_LINUX="/GRUB_CMDLINE_LINUX="net.ifnames=0 biosdevname=0 /' /etc/default/grub
# 更新 GRUB 配置
update-grub
# 应用 netplan 配置（测试语法）
sudo netplan generate
reboot
```



## Docker 网络模式详解

#### 1. Bridge 模式 (桥接模式) ⭐ 最主流、默认

**描述：

**Bridge 模式是 Docker 的**默认网络模式**。在此模式下，Docker 会创建一个名为 `docker0` 的虚拟网桥，并为每个容器分配一个独立的网络命名空间。容器通过 `veth pair` 设备对连接到这个网桥上，由网桥负责进行数据转发。

特点：默认网络模式；通过docker0虚拟网桥连接；需要端口映射才能从外部访问；容器获得独立IP

**工作机制：**

- **容器访问外部**：通过 **SNAT (Source NAT)**。外部看到的是宿主机的 IP，实现了容器内访问互联网。
- **外部访问容器**：通过 **DNAT (Destination NAT)**。必须通过 `-p` 参数进行**端口映射**，将容器的端口绑定到宿主机的端口上。

**优点：**

- ✅ **网络隔离性好**：容器拥有独立的 IP 和端口空间，与宿主机及其他容器隔离。
- ✅ **端口映射灵活**：通过 `-p` 参数可以灵活控制哪些容器服务暴露给外部。
- ✅ **单机多容器应用理想选择**：是大多数独立应用和微服务架构的首选。

**缺点：**

- ❌ **性能略有损耗**：数据包需要经过 `docker0` 网桥和 NAT，会带来微小的性能开销。
- ❌ **配置相对复杂**：需要手动管理端口映射。

**前置条件：**
此模式需要宿主机开启 IP 转发功能。

```powershell
sysctl -a | grep ip_forward
# 输出应为：net.ipv4.ip_forward = 1
```

**配置与管理：**

```powershell
默认命令即为 Bridge 模式：
docker run --network bridge nginx
# 等价于
docker run nginx

修改默认桥接网络 (docker0) 的网段：
修改 Docker 守护进程配置 /etc/docker/daemon.json (推荐) ：
{
  "bip": "10.100.0.1/24"
}

或 service 文件(二选一，这个方式了解即可！)
vim /usr/lib/systemd/system/docker.service
# 修改ExecStart模块
ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --bip=10.100.0.1/24

重启 Docker 服务：sudo systemctl restart docker
```



#### 2. Host 模式 (主机模式)

 **描述（特点）：**
容器不会创建独立的网络命名空间，而是直接**共享使用宿主机的网络栈**。容器不会获得独立的 IP，而是直接使用宿主机的 IP 和端口。正因为共享宿主机网络所以各容器网络无隔离、网络性能几乎无损耗，与之带来的弊端也很显著：容易产生端口冲突、网络资源无法分别统计、不支持端口映射。

打开容器前确认宿主机的80/tcp端口没有打开;

创建host模式的容器: docker run -d --network host --name web1 nginx-centos7-base:1.6.1

创建容器后，宿主机的80/tcp端口打开

进入容器：docker exec -it web1 sh

进入容器后仍显示宿主机的主机名提示符信息



#### 3. None 模式 (无网络模式)

**描述：**
容器拥有自己的网络命名空间，但内部**不进行任何网络配置**。容器只有 `lo` 回环接口，无法与外界进行任何网络通信。

**配置：**

bash

docker run --network none alpine

**特点：**

- **绝对隔离**：完全封闭的网络环境。
- **无法通信**：无法与宿主机、其他容器或外部网络通信。
- **无法端口映射**。



#### 4. Container 模式 (容器模式)

**描述：**
新创建的容器不会创建自己的网络栈，而是与一个**已存在的指定容器共享**同一个网络命名空间。两个容器的网络（IP、端口、路由等）完全一致。

**配置：**

bash

```powershell
# 先启动一个基础容器
docker run -d --name web-base nginx
# 新容器共享 web-base 的网络
docker run -it --network container:web-base alpine
```

**特点与注意事项：**

- **网络空间共享**：两个容器可以使用 `localhost` 直接访问对方的服务，因为它们共享同一个网络栈。
- **依赖性强**：如果被共享的基础容器停止，依赖它的容器网络将失效。
- **默认不支持端口映射**。
- **网络隔离于宿主机**：它们共享的网络空间与宿主机是隔离的。



#### 5. 自定义网络模式 ⭐ 推荐的最佳实践

**描述：**
用户可以根据需要创建自己的虚拟网络（底层驱动可以是 `bridge`, `overlay` 等），实现更灵活、更安全的容器间通信。

**优势：**

- **自动服务发现**：同一自定义网络内的容器可以通过**容器名**直接通信，无需 `--link`。
- **更好的隔离**：可以为不同项目创建独立的网络。
- **自定义子网**：可以手动指定 IPAM（IP 地址管理）配置，如子网、网关。

**操作命令：**

**创建自定义网络** (默认驱动为 `bridge`)：

- bash

```powershell
# 简单创建
docker network create mynet

# 高级创建（指定子网、网关）
docker network create -d bridge --subnet 172.20.0.0/16 --gateway 172.20.0.1 myapp-net
```

**将运行中的容器连接到自定义网络**：

```powershell
docker network connect myapp-net existing-container
```

**从网络中断开容器**：

```powershell
docker network disconnect myapp-net existing-container
```

**查看网络详情**：

```powershell
docker network inspect myapp-net
```

**删除网络**：

```powershell
docker network rm myapp-net
```

**总结：** 对于多容器应用，**自定义 Bridge 网络**是官方推荐的方式，它结合了默认 Bridge 模式的隔离性和便捷的内置 DNS 服务发现功能。



### 通过自定义网络实现 wordpress 

基础环境：下载镜像；创建目录；做镜像加速或正向代理；

第一部分：创建自定义网络

```powershell
docker network create -d bridge \
--subnet 172.37.0.0/16 --gateway 172.37.0.1 wordpress-net
```

- `docker network create`：创建自定义网络的命令。
- `-d bridge`：`-d` 指定网络驱动（driver）。`bridge` 表示创建一个本地的桥接网络。这是默认值，可以省略。
- `--subnet 172.37.0.0/16`：`--subnet` 指定该自定义网络使用的 IP 地址范围 。
- `--gateway 172.37.0.1`：`--gateway` 指定容器访问外部网络的网关地址。通常这是宿主机在该网络中的虚拟接口地址。
- `wordpress-net`：自定义网络的名称。

第二部分：运行 WordPress 容器

```powershell
docker run -d -p 80:80 \
--network wordpress-net --name wordpress \
-v /data/wordpress:/var/www/html \
registry.cn-beijing.aliyuncs.com/wangxiaochun/wordpress:php8.2-apache
```

- `docker run`：创建并启动一个新容器。
- `-d`：在后台运行容器 。
- `-p 80:80`：设置端口映射。

- - 格式：`-p <宿主机端口>:<容器内端口>`
  - 这里是将**宿主机的 80 端口**映射到**容器的 80 端口**。这样，外部用户通过访问 `http://宿主机IP` 就能访问到容器内的 WordPress 服务。

- `--network wordpress-net`：指定容器加入之前创建的 `wordpress-net` 网络。
- `--name wordpress`：为容器指定名称为 `wordpress`
- `-v /data/wordpress:/var/www/html`：创建数据卷。

- - 格式：`-v <宿主机目录>:<容器内目录>`
  - 这里将宿主机的 `/data/wordpress` 目录挂载到容器内的 `/var/www/html`（WordPress 代码和上传文件所在目录）。**作用是将数据持久化，即使容器被删除，网站数据也不会丢失。**

- `--restart=always`：配置容器的重启策略。

- - `always` 当docker重启时，容器也会自动启动。

- `--network-alias` 别名 ：为容器做别名设置；仅限于自定义网络类型；连接双向

第三部分：运行 MySQL 容器

```powershell
docker run --network wordpress-net \
-e MYSQL_ROOT_PASSWORD=123123 \
-e MYSQL_DATABASE=wordpress \
-e MYSQL_USER=wordpress \
-e MYSQL_PASSWORD=123123 --name mysql -d \
-v /data/mysql:/var/lib/mysql \
-network-alias mysql mysql:8.0-debian
```

- `-e MYSQL_ROOT_PASSWORD=123123`：`-e` 是 `--env` 的缩写，用于设置容器内的环境变量。

- - `MYSQL_ROOT_PASSWORD`：设置 MySQL `root` 用户的密码。**这是 MySQL 官方镜像的必需变量。**

- `-e MYSQL_DATABASE=wordpress`：环境变量，指示镜像在启动时自动创建一个名为 `wordpress` 的数据库。
- `-e MYSQL_USER=wordpress`：环境变量，创建一个名为 `wordpress` 的新用户。
- `-e MYSQL_PASSWORD=123123`：环境变量，为上面创建的 `wordpress` 用户设置密码。



### 通过自定义网络实现 Redis Cluster

```powershell
 # 创建自定义网络
 docker network create net-redis --subnet 172.28.0.0/24 
 # 创建6个redis容器配置 (通过脚本创建六个redis容器配置)
 for port in {1..6};do 
 mkdir -p /data/redis/node-${port}/conf 
 mkdir -p /data/redis/node-${port}/data
 cat >> /data/redis/node-${port}/conf/redis.conf << EOF
port 6379
bind 0.0.0.0
masterauth 123123
requirepass 123123
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
cluster-announce-ip 172.28.0.1${port}
cluster-announce-port 6379
cluster-announce-bus-port 16379
appendonly yes
EOF
done

# 检查是否创建成功
tree /data/redis/
more /data/redis/node-1/conf/redis.conf

# 创建6个 redis 容器
for port in {1..6};do
docker run -p 637${port}:6379 -p 1667${port}:16379 --name redis-${port} \
-v /data/redis/node-${port}/data:/data \
-v /data/redis/node-${port}/conf/redis.conf:/etc/redis/redis.conf \
-d --net net-redis --ip 172.28.0.1${port} redis:5.0.9-alpine3.11 \
redis-server /etc/redis/redis.conf 
done


创建 redis cluster
docker exec -it redis-1 /bin/sh			
redis-cli -a 123123 --cluster create 172.28.0.11:6379 172.28.0.12:6379 172.28.0.13:6379  172.28.0.14:6379 172.28.0.15:6379 172.28.0.16:6379 --cluster-replicas 1

redis-cli -a 123123 -c
# 启动redis集群 -c 表示启动集群模式，或者说是以集群模式启动
cluster info
# 查看集群启动状态
cluster nodes
# 可以看到集群中的主备对应关系
set name duan
set name shirley
# 添加数据观察分配存储路径

docker stop redis-2
# 测试故障实现 redis cluster 高可用性
docker exec -it redis-1 /bin/sh
redis-cli -a 123123 --cluster check 127.0.0.1:6379
# 再次查看cluster状态,可以看到redis-2对应的slave提升为新的master
```

## Docker重要参数

### EXPOSE 指令

\1. 只是声明，不是发布

- ✅ **只是声明**容器内部会监听 80 端口

\2. -p 明确映射 - 控制哪些端口真正暴露

```powershell
# 必须用 -p 才能从外部访问
docker run -p 80:80 nginx:latest

# 只有 EXPOSE 没有 -p，外部无法访问
docker run nginx:latest  # 只能容器内访问
```

1. 方便 `-P` 随机映射，容器间通信

```powershell
# 自动映射所有 EXPOSE 的端口到随机宿主机端口
docker run -P nginx:latest
docker ps  # 看到类似 0.0.0.0:32768->80/tcp
```

**不要依赖 EXPOSE 做安全**

```powershell
# 错误理解：以为 EXPOSE 80 会阻止其他端口访问
# 实际情况：容器内任何端口都可以被访问，EXPOSE 只是声明
```

**生产环境**

```powershell
# Dockerfile 中声明：
FROM nginx:alpine
EXPOSE 80
EXPOSE 443

# 生产环境（指定IP，避免冲突）
docker run -d \
  -p 127.0.0.1:80:80 \
  -p 127.0.0.1:443:443 \
  myapp:latest
```

**总结**

**一句话记住：EXPOSE 只是"说明文档"，**`**-p**` **才是真正的"开门营业"**

- `-p`：**可以映射任何端口**，不受 EXPOSE 限制
- `-P`：**只随机映射** EXPOSE 声明的端口



### VOLUME 指令详解

#### 基本作用

`VOLUME "/mydata"` 在 Dockerfile 中声明一个**挂载点**，用于数据持久化。

- 容器中的 `/mydata` 目录会成为挂载点
- **数据不会随着容器删除而丢失**
- 如果不指定主机目录，Docker 会自动在主机创建匿名卷挂载到 `/mydata`

```powershell
# 查看所有卷
docker volume ls

# 查看容器使用的卷
docker inspect container_name
```

### 数据持久化的三种方式

存储引擎：overlay2

联合文件系统；允许挂载多个文件系统；

tmpfs 临时文件系统；无法做到永久挂载，容器删除，卷也随之删除；

### 方式1：使用匿名卷（自动管理）

```powershell
docker run -d -v /data nginx:1.1
# Docker 自动管理卷位置；-v 容器内路径；
# 执行效果相当于：docker run -d -v /var/lib/docker/volumes/随即字符串目录/_data:/data --name nginx01
# 不推荐，由于是随机字符串，不方便管理；
docker volume prune	# 清理不再使用的匿名卷
```

### 方式2：使用命名卷（推荐）

```powershell
# 创建命名卷
docker volume create mydata_volume

# 使用命名卷
docker run -d -v mydata_volume:/mydata nginx:1.1
# -v 卷名称:容器路径   （仅写卷名，不需要添加宿主机路径，默认路径是/var/lib/docker/volumes/）
ls /var/lib/docker/volumes/mydata_volume
# 在docker history 容器名  指令显示中有一个volume路径，根据这个写容器路径；

docker volume ls
# 查看docker中所有的数据卷；
ls /var/lib/docker/volumes/
ls /var/lib/docker/volumes/随机字符串/_data/
# 查看数据卷的默认存储路径
docker history  mysql:8.0-debian  | grep -i volume
# 宿主机挂载到容器路径根据这个提示进行挂载
```

### 方式3：绑定主机目录

```powershell
# 挂载主机目录
docker run -d -v /host/path:/mydata nginx:1.1
# -v 宿主机的目录:容器目录   （宿主机的目录必须要写路径，无论绝对路径还是相当于路径）
# 意义为将宿主机的该目录挂载到容器中的该目录，容器删除，文件不会随之删除。
同时，如果一个宿主机中的文件在容器启动时将之加载使用，也可以通过这个参数完成！
docker run -d -p 80:80 --name nginx01 -v /mnt/web/:/data/web -v ./www.duan.org:/apps/nginx/conf.d/www/duan.org nginx:0.1
```

#### 注意事项

\1. 初始化问题

如果挂载空卷到有数据的目录：

```powershell
VOLUME /mydata
RUN echo "initial data" > /mydata/file.txt
```

**数据会被覆盖！** 主机卷内容会覆盖容器内数据。

\2. 最佳实践

```powershell
# 先准备数据，再声明卷
COPY initial-data/ /mydata/
VOLUME /mydata
```

### 容器服务端（多容器数据共享）

 **该容器有没有启动不影响数据共享，即便容器删除也不影响容器间的数据共享**

```powershell
数据卷容器：
docker run -d --name share-server  -v /mnt/data1:/data1  -v  /mnt/data2:/data2    nginx:1.1 
客户端容器对其进行复用；
docker  run --name nginx01 --volumes-from share -d
```



##### Bip 指令的核心作用

`--bip` 是 Docker 守护进程的一个启动参数，用于**自定义 docker0 网桥的 IP 地址和子网掩码**。

- 需要在 Docker 守护进程启动时配置，通常是通过修改 Docker 的配置文件来实现。
- 设置的是 **docker0 网桥**本身的 IP 地址，Docker 容器从它定义的子网中获取 IP 地址。

编辑 Docker 的 service 配置文件：

```powershell
在 daemon.json 文件中添加 bip 配置项：
vi /etc/docker/daemon.json
{
  "bip": "192.168.100.1/24"
}
重启 Docker 服务使配置生效：
sudo systemctl restart docker
```

### 实例Dockerfile的执行流程

```powershell
# 1. 基础镜像（此时默认还是 /bin/sh）
from nginx:mainline-alpine3.22 

# 2. 添加标签
label author=m65 version=1.0

# 3. 使用 /bin/sh 执行（因为 SHELL 指令还没执行到）
run sed -i 's#dl-cdn.alpinelinux.org#mirrors.aliyun.com#' /etc/apk/repositories &&\
        echo "更换为阿里云软件源" 

# 4. 使用 /bin/sh 执行
run apk update &&\
         apk add bash curl net-tools tzdata &&\
         ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\
         echo "Asia/Shanghai" > /etc/timezone

# 5. 从这里开始，后续的 RUN 使用 /bin/bash
shell ["/bin/bash", "-c"]

# 6. 使用 /bin/bash 执行，大括号扩展生效
run echo {1..10}
```

Dockerfile 有一个问题：**SHELL 指令放得太靠后**，前面的 `RUN` 无法受益。

- `SHELL` 指令改变的是**执行环境**，不是命令本身
- `RUN` 总是通过 shell 执行命令
- 把 `SHELL` 指令放在 Dockerfile 前面，让所有后续命令受益
- 使用 `/bin/bash` 可以支持更多高级功能（如大括号扩展、数组等）



### 疑难杂症之entrypoint

#### 实例一：

```powershell
exec格式 （推荐）
ENTRYPOINT ["/test.sh"]
CMD ["/apps/nginx/sbin/nginx", "-g", "daemon off;"]

Shell格式
ENTRYPOINT /test.sh
CMD /apps/nginx/sbin/nginx -g "daemon off;"
```

##### 执行流程：

1. 首先ENTRYPOINT执行 test.sh 脚本，在 `test.sh` 脚本中，通过 `$@` 获取所有 CMD 传递的参数 ;
2. 表面看是：
   ENTRYPOINT ["/test.sh"]

CMD ["/apps/nginx/sbin/nginx", "-g", "daemon off;"]

1. 最终执行的命令是：`/test.sh /apps/nginx/sbin/nginx -g "daemon off;`
2. 比如启动运行容器：docker run -d --name nginx00 -p 80:80 nginx:1.1
   实际执行的命令是：/test.sh /apps/nginx/sbin/nginx -g "daemon off;"

##### `exec "$@" []` 的作用

- `exec`：用后续命令（CMD）**替换当前 shell 进程 ，**

- - 若不添加exec，执行的cmd命令会作为当前shell的子进程 ；
  - 确保PID1是应用进程，可以正常接受信号，支持优雅停止；
  - 生产环境非常推荐exec "$@"的组合 ；

- `"$@"`：引用所有位置参数，保持参数原样传递
- [ ] ：中括号是必须的，表示exec格式，与之相对的是shell格式 ；
- 实例中shell的运行时表现为：
  /bin/sh -c "/test.sh"

/bin/sh -c "/apps/nginx/sbin/nginx -g \"daemon off;\""

##### entrypoint 与 cmd 的区别

- 两者同时存在时，cmd作为entrypoint的参数启动执行；
- entrypoint 定义一个脚本，实现环境初始化 ；
- cmd 实现定义默认容器启动命令 ；
- 其实entrypoint 不用也可以，只是为了分工明确，条理清晰；
- 其他的：略





### 更换软件源

##### Ubuntu

> - **noble** - Ubuntu 24.04 LTS (Noble Numbat) - **最新 LTS 版本**
> - **jammy** - Ubuntu 22.04 LTS (Jammy Jellyfish) - 当前稳定 LTS 版本
> - **focal** - Ubuntu 20.04 LTS (Focal Fossa) - 较旧 LTS 版本

查看当前系统版本

```powershell
lsb_release -a
# 或
cat /etc/os-release
```

编辑软件源的配置文件

```powershell
# 将原来的软件源文件改名为ubuntu.sources.bak，新建一个ubuntu.sources文件
vi /etc/apt/sources.list.d/ubuntu.sources
Types: deb
URIs: https://mirrors.aliyun.com/ubuntu/
Suites: noble noble-updates noble-backports
Components: main restricted universe multiverse
Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg

Types: deb
URIs: https://mirrors.aliyun.com/ubuntu/
Suites: noble-security
Components: main restricted universe multiverse
Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg

或者修改关键点：
ls /etc/os-release    # 查看系统版本信息
sed -i  "s@URIs:.*@URIs: http://mirrors.aliyun.com/ubuntu/@" "/etc/apt/sources.list.d/ubuntu.sources"
sed -i  "s@$VERSION_CODENAME@noble@g" "/etc/apt/sources.list.d/ubuntu.sources"

# 更新软件包列表
apt update
# 检查下载速度
sudo apt install -y wget curl
# 查看可更新软件包
apt list --upgradable
```









# 课堂笔记

- 面试宝典
  - 理论的口语化
- 工作重点
  - 动手试验

- 表达能力
- 加强复习，每天最后留半小时复习

nginx和LVS区别，调度算法有什么？

LVS四种工作模式

keepalived核心功能：

vrrp，虚拟路由冗余协议，vip漂移，实现高可用

ipvs，

脚本功能

通知

存储层：DAS、NAS 和 SAN 是三种主要的存储架构



##### 问答

###### 不同的数据库有什么特点？

| 类型       | 数据模型      | 优点           | 缺点       |
| :--------- | :------------ | :------------- | :--------- |
| **关系型** | 表格          | ACID事务，成熟 | 扩展性有限 |
| **Redis**  | 键值+多种结构 | 极快，功能丰富 | 内存限制   |
| **文档型** | JSON文档      | 灵活，易扩展   | 事务支持弱 |
| **列式**   | 列族          | 大规模扩展     | 复杂查询慢 |

nosql和redis特性

数据可主要分两大类：关系型数据库和nosql数据库

sql 意义为结构化查询语言

关系型数据库适合存结构化数据；

nosql 数据库分类。列存储、文档存储、图储存、对象、xml



###### 数据库事务的四个关键特性

- ACID：原子性、一致性、隔离性、持久性
  - Atomicity：事务中的所有操作要么**全部成功**，要么**全部失败**
  - Consistency：事务执行后，数据库必须从一个**一致状态**转换到另一个**一致状态**
  - Isolation：多个事务**并发执行**时，互相不干扰
  - Durability：事务一旦提交，对数据的修改就是**永久性**的

- 支持ACID的数据库
  - 关系型数据库：MySQL、PostgreSQL、Oracle、SQL Server
  - 部分NoSQL：MongoDB（4.0+）、Redis（通过事务）

- NoSQL数据库通常牺牲ACID来获得：高性能和更好的扩展，以及更灵活的数据模型；





cap  -- **分布式存储系统**

一致性；可用性；分区容错性；

强调的是分布式储存。三者不能同时具备。最多有两个同时具备。

das ，因为不是分布式，所以不适用cap；

nas/san，设计中优先考虑一致性，涉及到高可用时考虑可用性；软件常常动态的在c和a之间进行权衡；

比如mysql就是ap



##### redis  

降低软件服务器访问mysql服务器的频率，由redis代理数据访问请求；

以电商网站为例，读的频率多，那么redis服务器就应该代理多的访问请求；

###### 缓存穿透。

redis没有记录，mysql也没有记录，而用户不断发起请求。那么大概率是用户（攻击者）创建了不存在的数据，针对redis和mysql资源的占用和消耗。

解决方法：

接口层增加校验，用户校验、id校验等

###### 缓存击穿。

redis么有记录，mysql有记录。在热点数据过期后，造成大量用户数据访问mysql服务器。

解决方法：

设置热点数据永不过期

###### 缓存雪崩

redis中数据大批量到过期时间，而查询数据量巨大，压力到了数据库甚至可能down机。

解决方法：

缓存数据的过期时间设置为随机，防止同一时间大量数据同时删除。

###### 缓存宕机

redis服务器down机，导致mysql彻底承担redis和本身的任务，然后一起down机！

###### 早上待留问题

为什么redis那么快？
他是纯粹的基于内存，而mysql还是基于硬盘读取；c语言相交于python语言执行效率较高；

mysql是什么工作模式？是多线程工作，一个用户分配一个线程；而redis是单线程，数据以键值对存在；

为什么两者设计不同？基于内存快，但是数据不持久；基于硬盘慢，但是数据持久；

单线程为何如此快？ 纯粹基于内存运行；pipeline 多条执行

session共享，实现web集群中多服务器间的session共享；

###### 下午课程

- 包安装
- 二进制安装
- 源编译
  - configure --prefix/usr/local/myapp; make;makeintall
    - configure  生成一个makefile文件，为后续的make执行提供环境



- 容器化安装



半连接队列，在第二次握手之后，服务器方

全链接队列，在第三次握手之后，也是服务器方

连接队列不要设置太小，否则会影响并发量；也不要设置太大，否则会使tcp连接时间延长；

redis优化

消除warning告警；

优化内核内存分配参数；

linux指令

文件管理；用户权限管理；文本处理；进程管理；网络管理；磁盘管理；服务管理

脚本分类

安装；监控；优化；测试



###### 指令

```powershell
ulinit  -a
sysctl -p
deff 第一个文件 第二个文件	# 比较文件内容

redis-cli -a 密码 -h 主机ip地址 -p 端口 get class
redis-cli -a 密码 -h 主机ip地址 -p 端口 keys '*'
redis-cli -a 密码 -h 主机ip地址 -p 端口 set class M66
redis-cli  
redis-cli -a 密码 -h 主机ip地址 -p 端口		# 默认6379端口
info Memory		# info 模块名称
select 1		# 切换到编号为1的数据库
set class M65
get class
keys *
keys *682*		# 模糊匹配，生产环境中严禁使用！它会大量占用资源
flushdb			# 清除当前数据库的数据
flushall		# 清除所有数据库的数据
shutdown		# 关闭当前登陆端口的redis服务
dbsize
rename-command 需要禁止的指令	""		 # redis中禁用危险的指令
rename-command 指令	改名后的指令		# redis中改换指令名称

vi /apps/redis/etc/redis.conf		# redis服务存放密码文件，也是配置文件
bind 0.0.0.0 
protected-mode yes		# 默认保护模式，禁止空密码登陆
port 6379				# 可以在这里修改端口号，然后重启服务
tcp-backlog 511			# 全连接队列设定值
maxclients  10000		# redis最大连接客户端并发量，默认值10000
maxmemory   8388608		# redis最大使用内存，单位为字节，0为不限制，建议设为物理内存的一般；
LRU	# 表示最近最少使用
LFU # 表示最不常用

redis-cli
auth 123456							# 认证
config get requirepass				# config执行指令前缀，比如这个就是查看requirepass配置；
config set port 8888				# 修改端口号（临时的），改完立即生效；
config set requirepass 123123		# 修改密码（临时的），这个修改完不需要重启服务就可以生效；

telnet 10.0.0.100 6379
time bash redis_ceshi.sh			# 执行脚本，查看执行所需时间

config set showlog-log-slower-than 1
set a 1
get a
slowlog get

```

![image-20251027170108721](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20251027170108721.png)

文件

- 程序
  - 多实例复用；
- 配置文件
  - 多实例独立；
  - 位置：  /apps/redis/etc/redis.conf	   -
- 数据
  - 多实例独立；
- service
  - 多实例独立；
- 用户账户
  - 多实例复用；
- 日志
  - 多实例独立；

###### 慢查询

> 慢查询发生在第三阶段；
>
> 客户端超时不一定慢查询，但是慢查询是客户端超时的一个可能原因；

判断标准，超过10毫秒redis就判定为慢查询；

- 为什么需要关注？
  - 一条执行缓慢的 SQL 语句，会长时间占用数据库资源（CPU、内存、IO），可能导致整个系统瓶颈，甚至拖垮数据库，影响数据服务的可用性和一致性。

- 怎么做？
  - 开启慢查询日志：记录执行时间超过指定阈值的 SQL
  - 略



###### redis持久化

两种数据持久化的保存方法：

- RDB
  - 类似与快照备份
  - save # 立即备份内存中的数据，但它是前台并阻塞性，占用用户请求的线程，不推荐在生产环境使用；
  - bgsave # 后台执行并且开一个新的线程单独执行这个任务；
  - 备份策略是或的关系（默认） save 3600 1 300 100 60 10000

- AOF
  - 类似与二进制日志，将增删改变化的数据以二进制的格式备份
- RDB + AOF (混合持久化)——对于大多数生产环境，**推荐的策略是同时开启RDB和AOF（混合持久化）**。
  - 结合了RDB和AOF的优点，**恢复速度快**（先加载RDB部分）。
  - **数据安全性高**（AOF部分保证了增量数据不丢失）。
  - 文件大小比纯AOF小，比纯RDB大，是一个很好的平衡。
  - 当启用 `aof-use-rdb-preamble yes` 后，生成的AOF文件是一个“杂交”文件：
    - **文件开头部分**：是一个完整的**RDB二进制格式**的数据快照。
    - **文件末尾部分**：是后续写操作的**AOF协议格式**的增量命令。


| 特性           | RDB                      | AOF                            |
| :------------- | :----------------------- | :----------------------------- |
| **数据安全性** | 低，可能丢失数分钟的数据 | 高，根据配置最多丢失1秒数据    |
| **恢复速度**   | **快**（直接加载数据）   | **慢**（需重放所有命令）       |
| **文件大小**   | **小**（二进制压缩）     | **大**（日志文本，可重写压缩） |
| **对性能影响** | 小（fork子进程）         | 小到中（取决于同步策略）       |
| **灾难恢复**   | 优秀（单一文件）         | 良好（日志可修复）             |





- **volatile-lru**：从**设置了过期时间的 key** 中，用近似 LRU 算法淘汰最近最少使用的。
- **allkeys-lru**：从**所有 key** 中用近似 LRU 淘汰。
- **volatile-lfu**：从**设置了过期时间的 key** 中，用近似 LFU 算法淘汰最不频繁使用的。
- **allkeys-lfu**：从**所有 key** 中用近似 LFU 淘汰。
- **volatile-random**：从**设置了过期时间的 key** 中随机删除。
- **allkeys-random**：从**所有 key** 中随机删除。
- **volatile-ttl**：从**设置了过期时间的 key** 中，优先删除 TTL 较小的（即将过期的）。
- **noeviction**：不删除，新写入操作直接报错（默认）。













## ubuntu2404-安装

#### 编译安装

> 官网地址：https://redis.io/docs/latest/operate/oss_and_stack/install/build-stack/ubuntu-noble/

```powershell
依赖工具包和软件工具：
apt update && apt install -y --no-install-recommends gcc make ca-certificates wget dpkg-dev g++ libc6-dev libssl-dev git cmake build-essential libstdc++-10-dev python3 python3-pip python3-venv python3-dev unzip rsync clang automake autoconf libtool pkg-config libsystemd-dev
```

```powershell
设置变量：（根据自己的版本设定）
version=8.2.2
export BUILD_TLS=no
export BUILD_WITH_MODULES=no
export INSTALL_RUST_TOOLCHAIN=no
export DISABLE_WERRORS=yes
```

```powershell
下载安装包：
wget -O redis-$version.tar.gz https://githubfast.com/redis/redis/archive/refs/tags/$version.tar.gz
解压：
tar xvf redis-$version.tar.gz
```

```powershell
在 Redis 源码目录中执行编译：
cd redis-$version
make -j "$(nproc)" USE_SYSTEMD=yes PREFIX=/apps/redis install
查看编译文件：
ls  /apps/redis/bin/
验证：
./src/redis-server --version
./src/redis-cli --version
```

```powershell
创建日志和数据目录:
mkdir -p /apps/redis/{logs,data,etc}
复制reids.conf配置文件:
cd redis-$versioncp redis.conf  /apps/redis/etc
```

```powershell
创建系统账户并设置文件目录权限：
useradd -r -s /sbin/nologin redis
chown -R redis:redis /apps/redis/
编译后清理源码：
make clean
```

```powershell
配置 systemd 服务
vim /etc/systemd/system/redis.service

[Unit]
Description=Redis persistent key-value database
After=network.target

[Service]
ExecStart=/apps/redis/bin/redis-server /apps/redis/etc/redis.conf --supervised systemd
# ExecStop=/bin/kill -s QUIT $MAINPID
Type=notify
User=redis
Group=redis
RuntimeDirectory=redis
RuntimeDirectoryMode=0755
LimitNOFILE=1000000

[Install]
WantedBy=multi-user.target
```

```powershell
修改redis配置
# 编辑配置文件
vim /apps/redis/etc/redis.conf
# 建议修改：
# bind 0.0.0.0  # 允许远程连接
# dir /apps/redis/data  # 数据目录
# logfile "/apps/redis/logs/redis.log"  # 日志文件

systemctl daemon-reload
systemctl start redis
systemctl status redis

添加变量或者创建链接符号
export PATH=/apps/redis/bin:$PATH		# 临时
echo 'export PATH=/apps/redis/bin:$PATH' >> ~/.bashrc && source ~/.bashrc			# 添加到当前用户的 .bashrc （永久）
echo 'export PATH=/apps/redis/bin:$PATH' >> /etc/profile  && source /etc/profile	# 或者添加到系统全局配置
&
ln -s /apps/redis/bin/redis-cli /usr/local/bin/redis-cli
ln -s /apps/redis/bin/redis-server /usr/local/bin/redis-server
```

##### 优化

```powershell
修复 PID 文件权限问题
echo 'pidfile /apps/redis/redis.pid' >> /apps/redis/etc/redis.conf
chown redis:redis /apps/redis/redis.pid
# PID 文件应该由守护进程 在启动时自动创建，并在关闭时自动删除。
# 永远不要手工创建PID文件：让服务进程自己管理它。
```

```powershell
编辑配置文件——安全
vim /apps/redis/etc/redis.conf
# 设置密码（取消注释并修改）
requirepass 123123

# 重命名危险命令
rename-command FLUSHDB ""
rename-command FLUSHALL ""
rename-command CONFIG ""
rename-command SHUTDOWN ""

# 限制内存使用
maxmemory 1gb					# 默认是字节单位，不限制
maxmemory-policy allkeys-lru

# 保护模式（默认开启）
protected-mode yes
```

```powershell
编辑配置文件——性能优化
# 启用 AOF 持久化
appendonly yes
appendfsync everysec

# 内存优化
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2

# 连接优化
tcp-keepalive 300
timeout 300

# 客户端限制
maxclients 10000

日志和监控优化
略
```

> systemd 服务优化--(仅供参考)

```powershell
vim /usr/lib/systemd/system/redis.service
[Service]
# 增加超时时间
TimeoutStartSec=30
TimeoutStopSec=30

# 内存和资源限制
MemoryMax=2G
MemoryLimit=2G

# 重启策略
Restart=always
RestartSec=10

# 安全设置
NoNewPrivileges=yes
PrivateTmp=yes
ProtectSystem=strict
ProtectHome=yes
ReadWritePaths=/apps/redis/data /apps/redis/logs
```

###### 登陆

 ```powershell
 在对端服务器上检查 Redis 配置
 grep -E "^(bind|protected-mode)" /apps/redis/etc/redis.con
 bind 0.0.0.0			# 允许所有 IP 连接（或指定 IP）
 protected-mode yes		# 关闭保护模式（允许远程连接）
 requirepass 密码			# 设置密码 （可选）
 重新加载配置或者重启服务
 systemctl  restart redis
 查看端口是否能监听自己的地址
 ss -tlnp | grep 6379
 ```


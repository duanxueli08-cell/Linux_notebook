昨日内容回顾:
	- ES的原理
		- 文档的读取流程:
		- 文档的写入流程:
			hash(文档ID) % 主分片数量 ——--》 计算出数据存储的分片。
		- 文档的底层存储逻辑:
			
	- ES加密配置
		- filebeat对接
		- logstash对接
		- kibana对接
		- es-head对接
		- postman对接
		- curl对接
		
	- RBAC

	- zookeeper集群的搭建
	
	
今日内容预告：
	- zookeeper集群的增删改查
	- zookeeper的leader选举流程
	- zookeeper集群调优
	- kafka集群环境搭建
	- kafka常用的脚本
	- kafka的调优
	- kafka对接ELFK架构;
	
	



- zookeeper集群的常用命令增删改查实战
	1.查看zookeeper node列表
[zk: 10.0.0.93:2181(CONNECTED) 1] ls /
[zookeeper]
[zk: 10.0.0.93:2181(CONNECTED) 2] 


	2.创建zookeeper node并存储数据
[zk: 10.0.0.93:2181(CONNECTED) 2] create /oldboyedu xixi
Created /oldboyedu
[zk: 10.0.0.93:2181(CONNECTED) 3] 
[zk: 10.0.0.93:2181(CONNECTED) 3] ls /
[oldboyedu, zookeeper]
[zk: 10.0.0.93:2181(CONNECTED) 4] 
[zk: 10.0.0.93:2181(CONNECTED) 4] ls /oldboyedu 
[]
[zk: 10.0.0.93:2181(CONNECTED) 5] 

	3.创建zookeeper node不存储数据
[zk: 10.0.0.93:2181(CONNECTED) 5] create /oldboyedu/linux92
Created /oldboyedu/linux92
[zk: 10.0.0.93:2181(CONNECTED) 6] 
[zk: 10.0.0.93:2181(CONNECTED) 6] get /oldboyedu 
xixi
[zk: 10.0.0.93:2181(CONNECTED) 7] 
[zk: 10.0.0.93:2181(CONNECTED) 7] get /oldboyedu/linux92
null
[zk: 10.0.0.93:2181(CONNECTED) 8] 


	4.修改zookeeper node的数据
[zk: 10.0.0.93:2181(CONNECTED) 8] get /oldboyedu/linux92
null
[zk: 10.0.0.93:2181(CONNECTED) 9] 
[zk: 10.0.0.93:2181(CONNECTED) 9] set /oldboyedu/linux92 haha
[zk: 10.0.0.93:2181(CONNECTED) 10] 
[zk: 10.0.0.93:2181(CONNECTED) 10] get /oldboyedu/linux92
haha
[zk: 10.0.0.93:2181(CONNECTED) 11] 


	5.删除zookeeper node(必须为空，换句话说，没有子目录)
[zk: 10.0.0.93:2181(CONNECTED) 18] ls /oldboyedu/linux92 
[1, 2, 3]
[zk: 10.0.0.93:2181(CONNECTED) 19] 
[zk: 10.0.0.93:2181(CONNECTED) 19] 
[zk: 10.0.0.93:2181(CONNECTED) 19] ls /oldboyedu/linux92/3 
[]
[zk: 10.0.0.93:2181(CONNECTED) 20] 
[zk: 10.0.0.93:2181(CONNECTED) 20] delete /oldboyedu/linux92/3 
[zk: 10.0.0.93:2181(CONNECTED) 21] 
[zk: 10.0.0.93:2181(CONNECTED) 21] ls /oldboyedu/linux92 
[1, 2]
[zk: 10.0.0.93:2181(CONNECTED) 22] 


	6.删除zookeeper node(递归删除，换句话说，有子目录也可以被删除)
[zk: 10.0.0.93:2181(CONNECTED) 22] ls /oldboyedu/linux92 
[1, 2]
[zk: 10.0.0.93:2181(CONNECTED) 23] 
[zk: 10.0.0.93:2181(CONNECTED) 23] 
[zk: 10.0.0.93:2181(CONNECTED) 23] delete /oldboyedu/linux92 
Node not empty: /oldboyedu/linux92
[zk: 10.0.0.93:2181(CONNECTED) 24] 
[zk: 10.0.0.93:2181(CONNECTED) 24] ls /oldboyedu/linux92 
[1, 2]
[zk: 10.0.0.93:2181(CONNECTED) 25] 
[zk: 10.0.0.93:2181(CONNECTED) 25] deleteall /oldboyedu/linux92 
[zk: 10.0.0.93:2181(CONNECTED) 26] 
[zk: 10.0.0.93:2181(CONNECTED) 26] ls /oldboyedu/linux92 
Node does not exist: /oldboyedu/linux92
[zk: 10.0.0.93:2181(CONNECTED) 27]  



- zookeeper集群的zookeeper node类型
	1.zookeeper node类型 
- 临时zookeeper node
	当客户端链接断开时，超出了一定的时间范围（默认30s），则自动删除该zookeeper node。

- 永久zookeeper node 
	当客户端断开链接时，zookeeper node并不会被删除，除非手动删除。
	
	2.创建临时zookeeper node
[zk: 10.0.0.93:2181(CONNECTED) 31] create /oldboyedu/linux92
Created /oldboyedu/linux92
[zk: 10.0.0.93:2181(CONNECTED) 32] 
[zk: 10.0.0.93:2181(CONNECTED) 32] create -e /oldboyedu/linux93
Created /oldboyedu/linux93
[zk: 10.0.0.93:2181(CONNECTED) 33] 
[zk: 10.0.0.93:2181(CONNECTED) 33] ls /oldboyedu 
[linux92, linux93]
[zk: 10.0.0.93:2181(CONNECTED) 34] 

	3.查看zookeeper node的状态信息
[zk: 10.0.0.93:2181(CONNECTED) 35] stat /oldboyedu/linux92 
cZxid = 0x40000000f
ctime = Thu Jul 18 10:10:45 CST 2024
mZxid = 0x40000000f
mtime = Thu Jul 18 10:10:45 CST 2024
pZxid = 0x40000000f
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 0
numChildren = 0
[zk: 10.0.0.93:2181(CONNECTED) 36] 
[zk: 10.0.0.93:2181(CONNECTED) 36] stat /oldboyedu/linux93
cZxid = 0x400000010
ctime = Thu Jul 18 10:10:49 CST 2024
mZxid = 0x400000010
mtime = Thu Jul 18 10:10:49 CST 2024
pZxid = 0x400000010
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x5d000f8b5a410000
dataLength = 0
numChildren = 0
[zk: 10.0.0.93:2181(CONNECTED) 37] 


	4.断开会话
略。


	5.新建一个会话
不难发现，临时的zookeeper node(简称"znode")默认会在30s内自动删除。



- zookeeper集群的watch机制
	1.watch机制
客户端可以监控znode状态，一旦发生变化，就立刻通知客户端。watch事件是一次性的。


	2.案例
[zk: 10.0.0.92:2181(CONNECTED) 43] get -w /oldboyedu 

[zk: 10.0.0.92:2181(CONNECTED) 44] ls -w /oldboyedu 
	
	
	
- 以图形化的方式管理zk集群
	1.下载jdk
[root@elk91 ~]# wget http://192.168.16.253/Linux92/ElasticStack/day07-/softwares/jdk-8u291-linux-x64.tar.gz


	2.解压jdk软件包
[root@elk91 ~]# tar xf jdk-8u291-linux-x64.tar.gz -C /oldboyedu/softwares/


	3.验证JDK版本 
[root@elk91 ~]# /oldboyedu/softwares/jdk1.8.0_291/bin/java -version
java version "1.8.0_291"
Java(TM) SE Runtime Environment (build 1.8.0_291-b10)
Java HotSpot(TM) 64-Bit Server VM (build 25.291-b10, mixed mode)
[root@elk91 ~]# 

	4.下载zkWeb
[root@elk91 ~]# wget http://192.168.16.253/Linux92/ElasticStack/day07-/softwares/zkWeb-v1.2.1.jar


	5.运行jar包
[root@elk91 ~]# /oldboyedu/softwares/jdk1.8.0_291/bin/java -jar zkWeb-v1.2.1.jar 

	6.访问zkWeb UI界面
http://10.0.0.91:8099/#
	
	
	
- zookeeper的四字监控命令
echo srvr | nc 10.0.0.93 2181
echo ruok | nc 10.0.0.93 2181
echo conf | nc 10.0.0.93 2181

 
- zookeeper的leader选举流程
见视频。

- zookeeper集群调优
	1.所有节点修改JVM的堆(heap)内存大小
[root@elk91 ~]# grep ^ZK_SERVER_HEAP /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
ZK_SERVER_HEAP="${ZK_SERVER_HEAP:-1000}"
[root@elk91 ~]# 
[root@elk91 ~]# 
[root@elk91 ~]# sed -i '/^ZK_SERVER_HEAP/s#1000#128#' /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
[root@elk91 ~]# 
[root@elk91 ~]# grep ^ZK_SERVER_HEAP /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
ZK_SERVER_HEAP="${ZK_SERVER_HEAP:-128}"
[root@elk91 ~]# 


[root@elk92 ~]# sed -i '/^ZK_SERVER_HEAP/s#1000#128#' /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
[root@elk92 ~]# 
[root@elk92 ~]# grep ^ZK_SERVER_HEAP /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
ZK_SERVER_HEAP="${ZK_SERVER_HEAP:-128}"
[root@elk92 ~]# 


[root@elk93 ~]# sed -i '/^ZK_SERVER_HEAP/s#1000#128#' /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
[root@elk93 ~]# 
[root@elk93 ~]# grep ^ZK_SERVER_HEAP /oldboyedu/softwares/apache-zookeeper-3.8.4-bin/bin/zkEnv.sh 
ZK_SERVER_HEAP="${ZK_SERVER_HEAP:-128}"
[root@elk93 ~]# 
 
 
	2.重启zookeeper集群 
[root@elk91 ~]# systemctl restart zk.service

[root@elk92 ~]# systemctl restart zk.service

[root@elk93 ~]# systemctl restart zk.service
	
	
	3.查看堆内存是否修改成功
[root@elk91 ~]# ps -ef | grep zookeeper | grep -i xmx

	
	
	温馨提示:
		生产环境中，建议2-4GB即可，因为数据并不会大量存储在zookeeper集群。实际工作中，zookeeper主要是用于配置中心，注册中心。




- kafka单点环境部署:
	1.下载kafka软件包
	
wget https://downloads.apache.org/kafka/3.7.1/kafka_2.13-3.7.1.tgz


svip

[root@elk91 ~]# wget http://192.168.16.253/Linux92/ElasticStack/day07-/softwares/kafka_2.13-3.7.1.tgz


	2.解压软件包
[root@elk91 ~]# tar xf kafka_2.13-3.7.1.tgz  -C /oldboyedu/softwares/


	3.修改kafka的配置文件
[root@elk91 ~]# vim  /oldboyedu/softwares/kafka_2.13-3.7.1/config/server.properties 
...
# 指定节点的唯一标识
broker.id=91
# 指定数据存储路径
log.dirs=/oldboyedu/data/kafka-logs
# 指定zookeeper集群存储的路径
zookeeper.connect=10.0.0.91:2181,10.0.0.92:2181,10.0.0.93:2181/oldboyedu-kafka371


	4.配置环境变量
[root@elk91 ~]# cat /etc/profile.d/kafka.sh
#!/bin/bash

export KAFKA_HOME=/oldboyedu/softwares/kafka_2.13-3.7.1
export PATH=$PATH:${KAFKA_HOME}/bin
[root@elk91 ~]# 
[root@elk91 ~]# source /etc/profile.d/kafka.sh
[root@elk91 ~]# 

	
	5.启动kafka节点
[root@elk91 ~]# kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties 


	6.检查kafka在zookeeper集群的初始化信息
查看"/oldboyedu-kafka371/brokers/ids/91"路径即可

发现"91"的znode是一个临时的zookeeper node。

	
	7.停止kafka服务
[root@elk91 ~]# kafka-server-stop.sh 
	
	8.再次检查kafka在zookeeper集群的初始化信息
查看"/oldboyedu-kafka371/brokers/ids/91"路径即可

发现"91"的znode是一个临时的zookeeper node消失了。


	
- kafka集群环境搭建
	1.91节点同步配置到其他节点
[root@elk91 ~]# scp -r /oldboyedu/softwares/kafka_2.13-3.7.1/ elk92:/oldboyedu/softwares/

[root@elk91 ~]# scp -r /oldboyedu/softwares/kafka_2.13-3.7.1/ elk93:/oldboyedu/softwares/

[root@elk91 ~]# scp /etc/profile.d/kafka.sh elk92:/etc/profile.d/

[root@elk91 ~]# scp /etc/profile.d/kafka.sh elk93:/etc/profile.d/


	2.92节点操作
[root@elk92 ~]# source /etc/profile.d/kafka.sh 
[root@elk92 ~]# 
[root@elk92 ~]# grep "^broker.id" $KAFKA_HOME/config/server.properties 
broker.id=91
[root@elk92 ~]# 
[root@elk92 ~]# sed -i '/^broker.id/s#91#92#' $KAFKA_HOME/config/server.properties 
[root@elk92 ~]# 
[root@elk92 ~]# grep "^broker.id" $KAFKA_HOME/config/server.properties 
broker.id=92
[root@elk92 ~]# 


	3.93节点操作
[root@elk93 ~]# grep "^broker.id" $KAFKA_HOME/config/server.properties 
broker.id=91
[root@elk93 ~]#  
[root@elk93 ~]# sed -i '/^broker.id/s#91#93#' $KAFKA_HOME/config/server.properties 
[root@elk93 ~]# 
[root@elk93 ~]# grep "^broker.id" $KAFKA_HOME/config/server.properties 
broker.id=93
[root@elk93 ~]# 

	4.启动kafka集群
[root@elk91 ~]# kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties 


[root@elk92 ~]# kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties 


[root@elk93 ~]# kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties 

	5.检查zookeeper的信息
请看"/oldboyedu-kafka371/brokers/ids/"目录即可。




- kafka的相关术语:
	- kafka cluster:
		kafka集群，也可以称为:"broker list"。

	- kafka server:
		也称为"broker",kafka集群的每一个kafka服务器实例。
		
	- producer:
		生产者，表示往kafka写入数据的一方。
			
	- consumer:
		从kafka读取数据的一方。
		
	- topic:
		是kafka的逻辑概念，是producer和consumer进行数据读写的媒介。
		
		可以类比ES的索引。
		
	- partition:
		分区，分区也是逻辑概念，每个topic最少有一个或多个分区，数据分布式存储在不同的分区中，每个分区可以分散的存储到各个broker。
		
	- replica:
		副本，每个分区最少有一个或者多个副本，是实际存储数据的媒介。
		当副本数量大于1时，则会区分leader 副本和follower副本，producer和consumer都只能基于leader副本进行数据读写。
		换句话说，producer和consumer根本就不会发现follow副本的存在，follow只是负责备份leader数据，当leader挂掉时，取而代之。
	 

		
kafka常用的脚本之topic管理
	0.同步主机解析
[root@elk91 ~]# scp /etc/hosts elk92:/etc/
hosts                                                                                                100%  274   319.8KB/s   00:00    
[root@elk91 ~]# 
[root@elk91 ~]# scp /etc/hosts elk93:/etc/
hosts                                                                                                100%  274   176.8KB/s   00:00    
[root@elk91 ~]# 


	1.查看现有的topic列表
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --list

[root@elk91 ~]# 


	2.创建topic
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --create --topic oldboyedu-linux92 --partitions 3 --replication-factor 2
Created topic oldboyedu-linux92.
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --create --topic oldboyedu-linux92-001 --partitions 3 --replication-factor 2
Created topic oldboyedu-linux92-001.
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --list
oldboyedu-linux92
oldboyedu-linux92-001
[root@elk91 ~]# 
 
 
温馨提示:
	创建topic时，副本数量不能大于存活的broker节点数量。因为同一个分区的副本不能同时在同一个broker节点上存储。
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --create --topic oldboyedu-linux92-002 --partitions 3 --replication-factor 5
Error while executing topic command : Replication factor: 5 larger than available brokers: 3.
[2024-07-18 15:12:47,643] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 5 larger than available brokers: 3.
 (org.apache.kafka.tools.TopicCommand)
[root@elk91 ~]# 
	
	3.查看topic的详细信息
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --describe   # 默认查看所有的topic信息
Topic: oldboyedu-linux92	TopicId: v3h4QOctS7G-bI5NB_n5zA	PartitionCount: 3	ReplicationFactor: 2	Configs: 
	Topic: oldboyedu-linux92	Partition: 0	Leader: 92	Replicas: 92,91	Isr: 92,91
	Topic: oldboyedu-linux92	Partition: 1	Leader: 93	Replicas: 93,92	Isr: 93,92
	Topic: oldboyedu-linux92	Partition: 2	Leader: 91	Replicas: 91,93	Isr: 91,93
Topic: oldboyedu-linux92-001	TopicId: 4_JKBk96RRCIaFfoYDy6rg	PartitionCount: 3	ReplicationFactor: 2	Configs: 
	Topic: oldboyedu-linux92-001	Partition: 0	Leader: 92	Replicas: 92,91	Isr: 92,91
	Topic: oldboyedu-linux92-001	Partition: 1	Leader: 93	Replicas: 93,92	Isr: 93,92
	Topic: oldboyedu-linux92-001	Partition: 2	Leader: 91	Replicas: 91,93	Isr: 91,93
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --describe --topic oldboyedu-linux92  # 查看指定的topic信息
Topic: oldboyedu-linux92	TopicId: v3h4QOctS7G-bI5NB_n5zA	PartitionCount: 3	ReplicationFactor: 2	Configs: 
	Topic: oldboyedu-linux92	Partition: 0	Leader: 92	Replicas: 92,91	Isr: 92,91
	Topic: oldboyedu-linux92	Partition: 1	Leader: 93	Replicas: 93,92	Isr: 93,92
	Topic: oldboyedu-linux92	Partition: 2	Leader: 91	Replicas: 91,93	Isr: 91,93
[root@elk91 ~]# 


	4.修改topic
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --describe --topic oldboyedu-linux92
Topic: oldboyedu-linux92	TopicId: v3h4QOctS7G-bI5NB_n5zA	PartitionCount: 3	ReplicationFactor: 2	Configs: 
	Topic: oldboyedu-linux92	Partition: 0	Leader: 92	Replicas: 92,91	Isr: 92,91
	Topic: oldboyedu-linux92	Partition: 1	Leader: 93	Replicas: 93,92	Isr: 93,92
	Topic: oldboyedu-linux92	Partition: 2	Leader: 91	Replicas: 91,93	Isr: 91,93
[root@elk91 ~]# 
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --alter --topic oldboyedu-linux92 --partitions 5
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --describe --topic oldboyedu-linux92
Topic: oldboyedu-linux92	TopicId: v3h4QOctS7G-bI5NB_n5zA	PartitionCount: 5	ReplicationFactor: 2	Configs: 
	Topic: oldboyedu-linux92	Partition: 0	Leader: 92	Replicas: 92,91	Isr: 92,91
	Topic: oldboyedu-linux92	Partition: 1	Leader: 93	Replicas: 93,92	Isr: 93,92
	Topic: oldboyedu-linux92	Partition: 2	Leader: 91	Replicas: 91,93	Isr: 91,93
	Topic: oldboyedu-linux92	Partition: 3	Leader: 92	Replicas: 92,93	Isr: 92,93
	Topic: oldboyedu-linux92	Partition: 4	Leader: 93	Replicas: 93,91	Isr: 93,91
[root@elk91 ~]# 
[root@elk91 ~]# 


温馨提示：
	分区数量只能调大，不能调小！因此生产环境注意，不要设置太大的分区数量。
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --alter --topic oldboyedu-linux92 --partitions 3
Error while executing topic command : Topic currently has 5 partitions, which is higher than the requested 3.
[2024-07-18 15:08:58,956] ERROR org.apache.kafka.common.errors.InvalidPartitionsException: Topic currently has 5 partitions, which is higher than the requested 3.
 (org.apache.kafka.tools.TopicCommand)
[root@elk91 ~]# 


	5.删除topic
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --list
oldboyedu-linux92
oldboyedu-linux92-001
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --delete --topic oldboyedu-linux92
[root@elk91 ~]# 
[root@elk91 ~]# kafka-topics.sh --bootstrap-server 10.0.0.92:9092 --list
oldboyedu-linux92-001
[root@elk91 ~]# 


温馨提示:
	删除topic时，数据会延迟"log.segment.delete.delay.ms"(默认一分钟)后删除。
	
	


kafka常用的脚本之生产者和消费者
	1.启动生产者
[root@elk91 ~]# kafka-console-producer.sh --bootstrap-server 10.0.0.92:9092 --topic oldboyedu-linux92-001
>1111111111111111
>2222222222222222222
>333333333333333333333333333
>

	
	2.启动消费者
		2.1 启动消费者从最新(最后的流位置)的位置拉取数据
[root@elk92 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.92:9092 --topic oldboyedu-linux92-001


		2.2 在生产者终端输入数据
aaaaaaaaaaaaaaaaaaaaaa
bbbbbbbbbbbbbbbbbbbbbbbbb
cccccccccccccccccccccccccc
dddddddddddddddddddddddddddddd


		2.3 消费者能出现数据		
但无法将消费者启动前的数据拿到手。


		2.4 启动消费者时从头拉取数据
[root@elk93 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001 --from-beginning   
1111111111111111
2222222222222222222
333333333333333333333333333
aaaaaaaaaaaaaaaaaaaaaa
bbbbbbbbbbbbbbbbbbbbbbbbb
cccccccccccccccccccccccccc
dddddddddddddddddddddddddddddd


温馨提示：
	当我们启动了一个消费者时，会自动产生一个新的topic，名称为"__consumer_offsets"，该topic存储的是消费者的消费数据记录，也就是offset。
	
	
- kafka集群起不来的解决思路
	1.检查jdk环境是否部署
[root@elk91 ~]# java --version
openjdk 22.0.1 2024-04-16
OpenJDK Runtime Environment (build 22.0.1+8-16)
OpenJDK 64-Bit Server VM (build 22.0.1+8-16, mixed mode, sharing)
[root@elk91 ~]# 


	2.检查zookeeper集群是否启动
http://10.0.0.91:8099/#

[root@elk91 ~]# zkServer.sh status

[root@elk92 ~]# zkServer.sh status

[root@elk93 ~]# zkServer.sh status


	3.检查kafka的配置文件
[root@elk91 ~]# vim  /oldboyedu/softwares/kafka_2.13-3.7.1/config/server.properties 
...
# 指定节点的唯一标识
broker.id=91
# 指定数据存储路径
log.dirs=/oldboyedu/data/kafka-logs
# 指定zookeeper集群存储的路径
zookeeper.connect=10.0.0.91:2181,10.0.0.92:2181,10.0.0.93:2181/oldboyedu-kafka371


	4.前台启动kafka
kafka-server-start.sh $KAFKA_HOME/config/server.properties 

在前台运行kafka服务，观察报错信息。


如果是后台运行的kafka也可以看日志，如下所示:
[root@elk91 ~]# tail -100f /oldboyedu/softwares/kafka_2.13-3.7.1/logs/server.log

根据错误信息解决问题即可。


	5.重新安装一下KAFKA
		5.1 删除zookeeper的元数据;
deleteall /oldboyedu-kafka371

		5.2 删除kafka的数据
rm -rf /oldboyedu/data/kafka-logs

		5.3 重新启动kafka测试
略。
	
	
	

------------->
	offset：
		记录消费者组在paritition中消费的偏移量。
		
	consumer group：
		消费者组，任何一个消费者都隶属于一个消费者组。换句话说，一个消费者组可以有多个消费者。
		
		提示：
			- 同一个分区不能“同时”被同一个消费者组的两个消费者进行消费;
			
	
	Rebalance：
		重平衡，指的是分区分配给消费者组的消费者的过程。
		
		提示:
			- 1.当一个消费者组的数量发生变化时会触发Rebalance;
			- 2.当topic的分区数量发生变化时，也会触发Rebalance;
			- 3.消费者组的消费者过多时，可能会有部分消费者无法消费，因为其无法分配到分区;
		
		面试题:
			kafka有20个分区，现在消费者组有5个消费者，请问将消费者数量提升到20有变化吗？提升到50有变化吗？
			


- kafka常用的脚本之消费者组案例
	1.基于配置文件指定消费者组
		1.1 修改配置文件
[root@elk93 ~]# grep "^group.id" ${KAFKA_HOME}/config/consumer.properties 
group.id=linux92
[root@elk93 ~]# 


		1.2 启动消费者加载配置文件
[root@elk93 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001 --from-beginning   --consumer.config  ${KAFKA_HOME}/config/consumer.properties 
1111111111111111
2222222222222222222
333333333333333333333333333
aaaaaaaaaaaaaaaaaaaaaa
bbbbbbbbbbbbbbbbbbbbbbbbb
cccccccccccccccccccccccccc
dddddddddddddddddddddddddddddd


	2.查看消费者消费的列表
[root@elk91 ~]# kafka-consumer-groups.sh --bootstrap-server 10.0.0.91:9092 --list  
...
linux92
[root@elk91 ~]# 


	3.查看指定消费者组消费分区的offset
[root@elk91 ~]# kafka-consumer-groups.sh --bootstrap-server 10.0.0.91:9092 --describe --group linux92

GROUP           TOPIC                 PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID
linux92         oldboyedu-linux92-001 0          7               7               0               console-consumer-7f16fc43-d380-43b4-9926-b9e3f3b5343d /10.0.0.93      console-consumer
linux92         oldboyedu-linux92-001 1          0               0               0               console-consumer-7f16fc43-d380-43b4-9926-b9e3f3b5343d /10.0.0.93      console-consumer
linux92         oldboyedu-linux92-001 2          0               0               0               console-consumer-7f16fc43-d380-43b4-9926-b9e3f3b5343d /10.0.0.93      console-consumer
[root@elk91 ~]# 



	4.启动一个生产者
[root@elk91 ~]# kafka-console-producer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001
>111111111111
>222222222222
>33333333333


	5.观察消费者的界面
[root@elk93 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001 --from-beginning   --consumer.config  ${KAFKA_HOME}/config/consumer.properties 
...
111111111111
222222222222
33333333333


温馨提示:
	此时终止消费者的界面。
	
	
	6.再次使用生产者写入测试数据
[root@elk91 ~]# kafka-console-producer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001
>AAAAAAAAAAAAAAA
>BBBBBBBBBBBBBBBB



	7.再次查看消费者组的信息数据是有延迟的
[root@elk91 ~]# kafka-consumer-groups.sh --bootstrap-server 10.0.0.91:9092 --describe --group linux92

Consumer group 'linux92' has no active members.

GROUP           TOPIC                 PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
linux92         oldboyedu-linux92-001 0          7               7               0               -               -               -
linux92         oldboyedu-linux92-001 1          0               0               0               -               -               -
linux92         oldboyedu-linux92-001 2          3               5               2               -               -               -
[root@elk91 ~]# 


	8.同时启动多个消费者
		8.1 基于配置文件指定消费者组
[root@elk93 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001 --from-beginning   --consumer.config  ${KAFKA_HOME}/config/consumer.properties 
AAAAAAAAAAAAAAA
BBBBBBBBBBBBBBBB

		8.2 基于命令行方式启动消费者组
[root@elk92 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-001 --consumer-property group.id=linux92


		8.3 观察消费者信息
[root@elk91 ~]# kafka-consumer-groups.sh --bootstrap-server 10.0.0.91:9092 --describe --group linux92

GROUP           TOPIC                 PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID
linux92         oldboyedu-linux92-001 0          7               7               0               console-consumer-fd00695c-5aa1-4573-925a-68101917d799 /10.0.0.93      console-consumer
linux92         oldboyedu-linux92-001 1          0               0               0               console-consumer-fd00695c-5aa1-4573-925a-68101917d799 /10.0.0.93      console-consumer
linux92         oldboyedu-linux92-001 2          5               5               0               console-consumer-fe4a5f5f-1b19-40c6-a1c6-17d76f0ce61c /10.0.0.92      console-consumer
[root@elk91 ~]# 


		8.4 生产者继续生产数据
略。
		
		8.5 观察输出
略。

		

	
- filebeat写入数据到kafka集群
	1.编写配置文件
[root@elk91 filebeat]# cat config/18-tcp-to-kafka.yaml
filebeat.inputs:
- type: tcp
  host: "0.0.0.0:9000"

output.kafka:
  # 指定kafka的集群地址
  hosts: ["elk91:9092", "elk92:9092", "elk93:9092"]

  # 指定存储的topic
  topic: 'oldboyedu-linux92-kafka'
[root@elk91 filebeat]# 
[root@elk91 filebeat]# filebeat -e -c config/18-tcp-to-kafka.yaml


	2.发送测试数据
[root@elk91 ~]# echo "www.oldboyedu.com" | nc 10.0.0.91 9000

	
	3.检查数据是否写入kafka
[root@elk92 ~]# kafka-console-consumer.sh --bootstrap-server 10.0.0.91:9092 --topic oldboyedu-linux92-kafka --from-beginning 
{"@timestamp":"2024-07-18T09:25:32.910Z","@metadata":{"beat":"filebeat","type":"_doc","version":"7.17.22"},"agent":{"id":"820a1640-0d04-41a8-9c72-f5164ac8cfdf","name":"elk91","type":"filebeat","version":"7.17.22","hostname":"elk91","ephemeral_id":"1f779cb7-29f7-4ef6-9c2a-eea7049295be"},"message":"www.oldboyedu.com","log":{"source":{"address":"10.0.0.91:37842"}},"input":{"type":"tcp"},"ecs":{"version":"1.12.0"},"host":{"name":"elk91"}}



	
- logstash从kafka读取数据到ES集群
	1.编写配置文件 
[root@elk93 logstash]# cat config/09-kafka-to-es.conf
input {
  kafka {
     # 指定kafka集群地址
     bootstrap_servers => "10.0.0.91:9092,10.0.0.92:9092,10.0.0.93:9092"
     # 读取的kafka列表
     topics => ["oldboyedu-linux92-kafka"]
     # 指定消费者组
     group_id => "linux92-001"
     # 指定消费者组第一次从kakfka拉取数据的位置，常用值: earliest, latest
     auto_offset_reset => "earliest"
  }

}

filter {
  json {
    # 对message字段做json格式解析
    source => "message"
  }

  mutate {
     remove_field => [ "input","agent","@version","ecs","log" ]
  }
}

output {
  stdout {}

  elasticsearch {
     hosts => ["http://10.0.0.91:9200","http://10.0.0.92:9200","http://10.0.0.93:9200"]
     index => "oldboyedu-linux92-kafka-%{+yyyy.MM.dd}"
     user => "elastic"
     password => "123456"
  }
}
[root@elk93 logstash]# 
[root@elk93 logstash]# logstash -rf config/09-kafka-to-es.conf

	
	2.kibana查看数据
略。


- zookeeper和kafka的关系是啥?
	1.zk用于实现kafka集群各节点发现彼此;
	2.zk用于实现kafka的controller选举;
	3.zk用于同步kafka分区的leader信息；
	4.zk用于同步指令信息，比如删除topic，修改分区数量;
	5.zk用于记录kafka的集群ID等;
	
	

- 今日内容回顾:
	- zookeeper的增删改查		*****
	- zookeeper的watch机制
	- zookeeper node类型 
	- zookeeper 监控
	- zookeeper的leader选举流程
	- 以图形化方式管理zookeeper集群
	- kafka集群搭建 		*****
	- kafka的术语:			**
		- topic:
		- partition:
		- replica:
		- producer:
		- consumer:
		- consumer group 
		- offset：
		- rebanlance
		- broker list: (kafka cluster ) 
		
	- kafka常用的脚本:		*****
		- topic的增删改查;
		- producer和consumer实现数据的读写;
	
	- ELFK对接kafka集群		*****
	
	- zookeeper在kafka集群中的作用(配置中心，注册中心，...)
	
	
	
今日作业:
	- 1.完成课堂的所有练习并整理思维导图;
	- 2.使用ELFK架构分析nginx日志，要求数据filebeat写入到kafka，logstash从kafka拉取数据写入ES，kibana出图展示;
	
扩展作业:
	- 1.使用zabbix监控zookeeper集群,leader,follower，连接数,zookeeper node数量，发送和接受的数据大小.
	- 2.使用zabbix监控kafka集群，topic的数量，数据是否有延迟，每个分区的副本数量，消费者组的信息监控;
	- 3.使用ansible一键部署ELFK+ZK+KAFKA集群环境;
	
	
	
明日环境准备:
	- 关闭ELK集群，准备2台Ubuntu系统，2c4GB;
		10.0.0.101 docker101
		10.0.0.102 docker102